{"pages":[{"title":"archives","text":"","link":"/AngelNI.github.io/archives/index.html"},{"title":"about","text":"About my blog访客查看 💖This is a simple record of learning bits and pieces , so that each step of learning into an unforgettable memory. 💖To improve my writing skills 💖The future is promising❤️ About me 👦 Hui Ning 😃 A HPU‘s student 🔥 Skills ： python , C 🙈 QQ: 1476879474 🙈 Wechat: 13333350047 📧 QQ-Email : 1476879474@qq.com 📧 G-Email : ninghuiangel@gmail.com 📕 Github :https://github.com/DL-Metaphysics/DL-AngelNI 📱 Phone : 13333350047 or 18339189296 Mottor ​ ❤️ 成熟是一种明亮而不刺眼的光辉,一种圆润而不腻耳的声响,一种不再需要对别人察言观色的从容,一种终于停止向周围申诉求告的大气,一种不理会哄闹的微笑,一种洗刷了偏激的淡漠,一种无需声张的厚实,一种并不陡峭的高度. ❤️ 我不去想是否能够成功,既然选择了远方,便只顾风雨兼程 —汪国真 ❤️ 天生有才必有用，千金散尽还复来。 —李太白. ❤️ 天行健，君子以自强不息；地势坤，君子以厚德载物。 —《周易》 ❤️ 爱——不仅爱你伟岸的身躯，也爱你坚持的位置，足下的土地。 —舒婷 ❤️ 我放下过天地，却从未放下过你。 —仓央嘉措 ❤️ 人生若只如初见，何事秋风悲画扇 。 —纳兰性德 ❤️ 万事应为开心法，愿以随缘度浮生。 Relax 🕹️ 扫雷 点我哦 🕹️ 俄罗斯方块 我在这 🕹️ 推箱子 就是我 🕹️ 2048 快来呀 🕹️超级玛丽 就差你了","link":"/AngelNI.github.io/about/index.html"},{"title":"categories","text":"","link":"/AngelNI.github.io/categories/index.html"},{"title":"tags","text":"","link":"/AngelNI.github.io/tags/index.html"}],"posts":[{"title":"CET4","text":"COME ON !!! 很高兴有这次机会提前考四级，希望要过呀，好好学英语，下学期六级要过啊。 在这里简单介绍一下四级。 一 、四级题型1.作文（15%） 2.听力（35%） （1）听力对话（15%） （2）听力短文（20%） 3.阅读理解（35%） （1）词汇理解（5%） （2）长篇阅读（10%） （3）仔细阅读（20%） 4.汉译英（15%） 总分 ：710，及格线：425 二、考前准备1.词汇英语单词是学习英语的基础，基础不牢，地动山摇，好好买一本英语四级的词汇书很重要（我买的是新东方的），要背单词哦。现在有很多背单词的APP，比如百词斩，有道词典，我认为不靠谱，看着看着，就看别的了（都懂的吧），还有个人认为纸质的书拿起来有感觉。 2.听力最头疼的就是听力了，占了很大的分值，听力就多听吧。还有就是要知道他可能会考什么，猜。 3.阅读理解做阅读理解，一定要多做题，买一本近几年的四级考试卷子每周一套（整个上半年我们老师是这样要求的），找到自己的做题感觉和方法很重要。 4.翻译多背一些固定搭配，多背一些词组，还有就是单词~ 三、考试时间安排 注意：答题卡分为两张1和2，先写作文，听力，听力结束后开始收答题卡1。 最后要预祝考四级的小伙伴，考的全会，蒙的全对。","link":"/AngelNI.github.io/CET4/"},{"title":"A New Start","text":"This is a nice day!!! After half a day’s hard work, my blog is successfully included by baidu and google,and I add some new features to my blog for attracting more people to visit. As we all know,photo is a good way to look back our experience,so I specially add Photo to my blog.I change the background of my blog,making it not monotonous.The big change is that my blog language is changed to Engelish and I begin to write blog in English ,thanks to my classmate Uncle_drew’s idea,and thanks for his blog ,I learn a lot from it. Thank you @ https://cndrew.cn/ Lastly,I sincerely hope that I can insist writing blog .","link":"/AngelNI.github.io/A-New-Start/"},{"title":"Appreciation of Novels(1)","text":"1.我因车祸而失明，所以我从不知女友长什么样。那年，她得了胃癌，临终前她将眼角膜移植给了我。我恢复光明后的第一件事就是找她的照片，然而我只找到她留给我的一封信，信里有一张空白照片，照片上写有一句话：“别再想我长什么样，下一个你爱上的人，就是我的模样。” 2.外婆离开人世的那个黄昏，外公在病房里陪伴着她走完了她生命的最后一段旅程。外婆临去前对外公说‘放学了’。一直假装平静的外公听完这句话后像个孩子似的大哭起来。葬礼结束后我问起外公这三个字的含义，外公告诉我说这是从前他和外婆还在上小学时外婆常说的一句话：放学了，我们一起回家吧。 3.她车祸去世后，他思念万分，利用时光机回到过去，阻止惨剧发生。机器出了差错，比预定时间早了几分钟。他拿出钥匙开门，听见卧室传出她的娇喘和男人的声音。她手机响了，他记得这是他打来的。“我得走了，我男人催我呢。”。他听着，惹羞成怒，出门偷了一辆车，看着急匆匆的她，一脚踩下油门。 4.妈妈你看！”小女孩开心地递过来一张写满字的纸。“我听见一个哥哥问姐姐怎么才会爱他，姐姐说只要每天在纸上写1000遍她的名字…”“傻孩子！”女人抱住小女孩：那宝贝是怎么知道爸爸名字的？“这里！”小女孩打开抽屉：上次爸爸把名字签在上面了！女人顺眼望去，里面躺着一张离婚协议书 5.他看着桌子上忙碌的蚂蚁，伸出手指，一下捏死一只。蚂蚁们大惊，四下乱窜。稍停，又排成一字继续工作。他又伸出手，再捏死一只。蚂蚁大乱，稍顷还是排一字。等到第10次时，蚂蚁们已经熟视无睹。当他向第11只下手时，轰隆一声，巨大的天花板砸了下来。他最后一眼，只看到推倒他房子的那只怪手。 6.他和她青梅竹马，相约为百姓杀贪官，仗剑天涯。一次刺杀失败被俘，他竟被招安，无数同仁被杀。她含泪发誓要刃叛徒，遂色诱贪官纳她为妾。十年后，他成平反大将。酒宴上，她起身献舞，刺中他手臂。他深情说，你之后，我再无爱过。她心软刃落，他抽刀刺死她，心想，真好骗。 7.他大她快二十岁，他对她很好，百般呵护，他们认识不到一年，他就执意要娶她。朋友都很羡慕她，她却犹豫不决，因为小时候一场手术意外造成她不孕，他是独子，庞大的家族事业等他继承，她不想耽误他。终於她鼓起勇气向他坦诚不孕的事实，他说我知道，当年那刀是我开的，这些年来我一直在找你！ 8.5岁“妈妈，烧红烧肉吧”“行，烧”15岁“妈妈，别烧红烧肉了，换换味道” “行，买别的菜” 35岁“儿子，啥时候回家吃一顿啊？妈给做红烧肉” “不行，最近忙” 50岁“妈妈今天路过你家，给你带红烧肉” “不行，今不在家” 70岁“妈，我想吃红烧肉” 那边，已经没有了妈妈的声音 9.就要做心脏移植手术了，他深情地望着躺在床上的妻子，拿签字表的手有点抖。“快签吧，你个窝囊废、穷鬼！”妻骂。手术很成功，她没有一点排异反应。“我那没心肝的丈夫哪？”她问护士。护士递过一张纸，上面画一颗鲜红的心和一行小字：“这是我最后能给你的了，我爱你。” 10.他与爸爸相依至大。他常问：为什么不给他找个后妈？爸爸总是笑说：此生只爱妈妈一个！后来他长大成家，爸爸说要结婚，他愤怒地打了那女人一耳光，骂爸爸是个骗子。从此，爸爸再未提及此事。多年后爸爸去世，他整理遗物时发现了一张自己婴儿时的照片，背面是沧桑的字迹：战友之子，当如吾儿！","link":"/AngelNI.github.io/Appreciation of Novels/"},{"title":"DFS_Practice","text":"DFS——exercise.I learned DFS last month,I almost forgot how to use it,so that I can’t solve a problem in a practice competition. So I require to review it,and review carefully! Question在这里你有一个 6*3 的一个数组，每行有1 ， 2 ， 3 三个数，并且每行按照六种顺序分别排列。当每一行都取一个数时，求出6个数之和最大的值。 这里有一个非常笨的方法，就是用六重For循环，是不是很惊讶。没错，当我的小伙伴告诉我时,我的内心是WTF的。 这不是重点，重点是想通过这个简单的题练习一下DFS的思想。 这仅仅是个简单的开始， Code12345678910111213141516171819202122232425#include&lt;iostream&gt;using namespace std;int a[10][5];int res;void dfs(int x,int sum = 0){ if(x&gt;5) { //printf(\"%d\",res); res = max(res,sum); return; } dfs(x+1,sum+a[x][0]); //dfs(x+1,sum+a[x][1]); //dfs(x+1,sum+a[x][2]);}int main（）{ for(int i=0;i&lt;6;i++) for(int j =0;j&lt;3;j++) cin&gt;&gt;a[i][j]; dfs(0); cout&lt;&lt;res&lt;&lt;endl; return 0; } FIRST第一次我控制只输入第一列，输出结果为六。 仔细想想，这个跟递归求n的阶乘有异曲同工之妙，不断的调用自己递归，直到满足条件回归。 SECOND这次我输入了6*2的数据，并将每次的相加求和的结果打印出来，算了算一共64种，也就是说一共有64种组合方法。 THIRD最后我将所有的数据输入得到了正确的结果18。 LAST仔细想想还是挺有趣的，想想那个yong FOR循环写的，一共729种可能，想想就可怕. TE,TE,TE,TE……. DFS模板介绍DFS问题的解决有一个dfs的套用模板，自我感觉挺有用的，如果你有更好的办法，留评论呦！！！ 123456789101112131415void dfs(step)`{ if(num==end) { /*do something*/ return ;} /*尝试每一种可能，和遍历数组差不多*/ for(int i =0;i&lt;end;i++) { do something; dfs(step+1); undo something; }rerun 0;`} 回溯问题Q这里拿棋盘问题举个栗子。 POJ1321 请点击这里 在一个给定形状的棋盘（形状可能是不规则的）上面摆放棋子，棋子没有区别。要求摆放时任意的两个棋子不能放在棋盘中的同一行或者同一列，请编程求解对于给定形状和大小的棋盘，摆放k个棋子的所有可行的摆放方案C。 INPUT 输入含有多组测试数据。每组数据的第一行是两个正整数，n k，用一个空格隔开，表示了将在一个n*n的矩阵内描述棋盘，以及摆放棋子的数目。 n &lt;= 8 , k &lt;= n当为-1 -1时表示输入结束。随后的n行描述了棋盘的形状：每行有n个字符，其中 # 表示棋盘区域， . 表示空白区域（数据保证不出现多余的空白行或者空白列）。 OUTPUT 对于每一组数据，给出一行输出，输出摆放的方案数目C （数据保证C&lt;2^31）。 SOLVE1234567891011121314151617181920212223int DFS(int x,int y) { if(y&gt;=k） { ans++; return 0; } for(int i=x;i&lt;n;i++) { for(int j=0;j&lt;n;j++) { if(!visit[j]&amp;&amp;mp[i][j]=='#')//回溯 { visit[j]=1; DFS(i+1,y+1); visit[j]=0; } } } return 0; }在这里menset（visit，0，sizeof（visit））； DFS过程中，你要退一步，就必然需要保存你走过每个点的所有信息，而在退一步的过程中，你需要从当前状态回到之前的状态，那么这步操作就是回溯，回溯是递归的时候一定会产生的很自然的操作，只不过大部分情况下不需要回溯。","link":"/AngelNI.github.io/DFS-自我练习/"},{"title":"Appreciation of Novels(2)","text":"“不要忘记你曾经是怎样的小孩”，“不要忘记你曾希望变成怎样的大人”。 1.她对他很满意。走吧。好。他起身买单，腿却一拐一拐的。难怪他才华横溢，事业有成，却还是单身。趁着他买单，她赶紧悄悄走了。又是一年，她又遇到了他，他正牵着孩子的手，走的飞快。你的腿？她有些诧异。腿？我的腿怎么了？他更诧异。后来，她才知道他的腿，那天只是坐麻了而已。 2.失明后他脾气暴躁。妈妈呵斥道，你这样自暴自弃，从今后我只喊你起床吃饭睡觉，不再管你。果然，从那以后妈妈每天只跟他说这三句话。这让他很愧疚，也渐渐平静下来配合治疗。一年后，他终于复明了，却没看到妈妈。家人告诉他：妈妈一年前就去世了，去世之前录下那三句话，不想影响你的治疗… 3.她花了一周的晚上给他织好了这条围巾，从小娇生惯养，这是她的第一条围巾，她幻想着他惊喜的表情。在他生日的那个晚上，她刚幸福地把围巾给他围上，他却厌倦地取了下来“我不喜欢围巾”！心，瞬间冰凉！爸爸来了，以为是给自己的，自顾地围上，满脸都是幸福的笑容。她转过身来，泪流满面… 4.世界突然爆发一种健忘流行病。我和你都不幸被传染，并且越来越严重。第一天，我们都忘记带钥匙出门，于是只能半夜叫锁匠；第二天，一起做饭结果做出了咖喱牛排，其实我爱吃的是咖喱饭，而你爱菲力牛排；第三天，商场拒绝我的付款，因为我在信用卡的回执上，不管怎么回忆，都只签得出你的名字。 5.“今晚要开会，不用等我了.”“哦，知道了。”挂掉电话，她看着精心准备的一桌子菜发呆.总是忙，连我生日都忘了。门铃响了，“保安，有人看到你家阳台进了窃贼.”“啊?”她惊讶的看着保安鱼贯而入，很快听见阳台传来熟悉的声音：“谁是小偷?我是这房子的业主！喂干什么！别弄坏我蛋糕…” 6.他这一辈子都是默默无闻的在拍戏，演的永远是他的敌人，出镜率不高，并不出名。但他每天最开心的事情就是在公司看到他被粉丝里三层外三层的围住要求签名、合影，他总是微笑着站在一边静静等待，等他摆脱了粉丝走到自己身边对他说：走吧，迟到了导演会骂。据说，他叫奥特曼，他叫小怪兽。 7.儿子怀揣四万块冲进病房，对弥留的老父激动地大喊：“爸！我终于借到钱了！你可以动手术了！！”父亲嘴唇濡动。儿子问：“妈，爸在说什么？咱快叫医生啊！” 母逼近丈夫的脸颊，倾听片刻，对儿子泣道，“你爸想求你个事。你小时候，他常抱你，现在他要走了，你能不能抱一抱他？” 8.情人节，老年痴呆的外公失踪。晚间，医院来电说有位衣服上缝这个电话的老人站在某病房里不肯离去。去接外公时妈妈一进病房便哭了，外婆就是在这间病房去世的。当我看到傻傻的外公手里那支不知从哪里拣来的玫瑰时，忽然想到几年前情人节，我问外公咋不送外婆玫瑰时，外公说傻老太太衬不上玫瑰。 9.她车祸去世后，他思念万分，利用时光机回到过去，阻止惨剧发生。机器出了差错，比预定时间早了几分钟。他拿出钥匙开门，听见卧室传出她的娇喘和男人的声音。她手机响了，他记得这是他打来的。“我得走了，我男人催我呢。”他听着，惹羞成怒，出门偷了一辆车，看着急匆匆的她，一脚踩下油门… 10.这是他从医30年来第一起医疗事故，其实这种手术他做过不知道多少了.当患者死在手术台上的时候，他才意识到自己犯了多大的错误，这把曾经的“神刀”就此成为历史.回家后他异常疲惫，倒在沙发上一言不发.妻子很兴奋的冲出来，“女儿有救了，有个刚死的捐了肾。”“哦。”他握刀的手依旧在抖。 11.他在大街上遇见她，她带着孩子.他问：你还好吗。“挺好的，你呢。”“我也挺好的”，他摸摸小孩儿的头，软软的自来卷，“孩子真可爱，多大了？”“3岁.” 他沉默了一下，“原来我们分手那年你就结婚了.”她没说话，看着他的光头，他攥了下手里的化疗单“我那头自来卷太难打理，剃了.” 12.外人眼里，他们是可爱的龙凤胎。事实上，哥哥是克隆人，他不过是她的备用器官库，他这一生注定为她而活。十六岁那年，妹妹心脏出问题，这意味着哥哥的生命到了尽头。可她不愿意他替她去死，偷跑出去，晕死街头，他背她回来。等她醒来，他不在了，看到一张纸条：“放心，克隆人没有喜悲。” 13.为了庆祝分手后他的第一个生日，她低价卖掉了他往年送给她的每一样生日礼物。然后拿着卖来的钱她去了蛋糕房为他订了一份四层的大蛋糕，和一百根白色的生日蜡烛。他生日那天，随蛋糕一起寄给他的生日贺卡上她用红色的墨水一笔一划地写着：祝你孤独，并且长命百岁。 14.退休在家后，老伴最爱从早到晚数落我又老又胖好吃懒做。今早起床我突然咳嗽并吐出一口鲜血，他看到后整个上午没有说出一句话，闷闷地抽着烟。中午拉我去了医院，最后得知那是我牙龈发炎口腔出的血，他立马就站在医院怒骂我：“你这个没用的胖老太婆…”只是还没骂完，他眼眶里已满是泪水…","link":"/AngelNI.github.io/Appreciation-of-Novels-2/"},{"title":"C++初学","text":"C++ 初学（一）在一次解决排序问题时，初步接触C++中的sort（）函数，在问题解决上非常好用，不用自己再写排序的代码，就像python中 import 函数库一样，因为懒嘛，所以更懒，嘿嘿！！所以想接触一下C++，简单学习一下子。 C++C++是C语言的继承，它既可以进行C语言的过程化程序设计，又可以进行以抽象数据类型为特点的基于对象的程序设计，还可以进行以继承和多态为特点的面向对象的程序设计。C++擅长面向对象程序设计的同时，还可以进行基于过程的程序设计，因而C++就适应的问题规模而论，大小由之。 C++ 是一种静态类型的、编译式的、通用的、大小写敏感的、不规则的编程语言，支持过程化编程、面向对象编程和泛型编程。 C++ 被认为是一种中级语言，它综合了高级语言和低级语言的特点。 C++ 是由 Bjarne Stroustrup 于 1979 年在新泽西州美利山贝尔实验室开始设计开发的。C++ 进一步扩充和完善了 C 语言，最初命名为带类的C，后来在 1983 年更名为 C++。 C++ 是 C 的一个超集，事实上，任何合法的 C 程序都是合法的 C++ 程序。 好了废话不多说，开始！ Hello world12345678910#include &lt;iostream&gt;using namespace std;// // main() 是程序开始执行的地方 int main(){ cout &lt;&lt; \"Hello World\"; // 输出 Hello World return 0;} 接下来我们讲解一下上面这段程序： C++ 语言定义了一些头文件，这些头文件包含了程序中必需的或有用的信息。上面这段程序中，包含了头文件 。 下一行 using namespace std; 告诉编译器使用 std 命名空间。命名空间是 C++ 中一个相对新的概念。 下一行 // main() 是程序开始执行的地方 是一个单行注释。单行注释以 // 开头，在行末结束。 下一行 int main() 是主函数，程序从这里开始执行。 下一行 cout &lt;&lt; “Hello World”; 会在屏幕上显示消息 “Hello World”。 下一行 return 0; 终止 main( )函数，并向调用进程返回值 0。 输入、输出C++的输出和输入是用“流”(stream)的方式实现的｡有关流对象cin､cout和流运算符的定义等信息是存放在C++的输入输出流库中的,因此如果在程序中使用cin､cout和流运算符,就必须使用预处理命令把头文件stream包含到本文件中:#include &lt;iostream&gt;尽管cin和cout不是C++本身提供的语句,但是在不致混淆的情况下,为了叙述方便,常常把由cin和流提取运算符“&gt;&gt;”实现输入的语句称为输入语句或cin语句,把由cout和流插入运算符“&lt;&lt;”实现输出的语句称为输出语句或cout语句｡根据C++的语法,凡是能实现某种操作而且最后以分号结束的都是语句｡ 1234567891011121314151617181920212223#include&lt;cstdio&gt;#include&lt;iostream&gt;#include &lt;iomanip&gt; //格式化输出的头文件，注意这里不要加.husing namespace std;int main(){ int a,b,c; cin&gt;&gt;a&gt;&gt;b&gt;&gt;c; cout&lt;&lt;a&lt;&lt;setw(2)&lt;&lt;b&lt;&lt;setw(2)&lt;&lt;c&lt;&lt;endl; float num1 = 123.456f,num2 = 563.1f,num3 = 1.30f; float num4 = 123456.4444f; cout &lt;&lt; setprecision(4); cout &lt;&lt; \"第一个数：\" &lt;&lt; num1 &lt;&lt; endl; cout &lt;&lt; \"第二个数：\" &lt;&lt; num2 &lt;&lt; endl; cout &lt;&lt; \"第三个数：\" &lt;&lt; num3 &lt;&lt; endl; cout &lt;&lt; \"第四个数：\" &lt;&lt; num4 &lt;&lt; endl;//endl 英语意思是end of line,即一行输出结束，然后输出下一行。 return 0; } 头文件#include&lt;iomanip&gt;是格式化输出的头文件，注意后面不加 .h， 使用setw()来控制占位宽度。注意事项 setw() 虽然带有括号，但是其实是一个操作符，并不是函数。 setw() 主要引用头文件 iomanip 才能使用。 如果setw() 所约束的输出超过了限制，不会被截断。是多少位就输出多少位。 如果输出是浮点数，小数点也会占一个位。 如果输出是字符串，空格有段有效字符，占一个位。从上面的输出结果也可以看出来。 setw() 只能约束住跟自己相邻的一个输出。也就是说 使用setprecision()控制浮点数有效位注意事项： setprecision() 同样是一个操作符，需要包含头文件 iomanip。 如果输出浮点数不足位，不会在其后面补0。 如果末尾有0，默认是不输出的。后面我们有其他方法可以输出末尾的0。 setprecision() 不同于setw()，setprecision() 设置之后，在下次设置之前都是有效的。从程序结果中可以看出来。 如果要输出的位数过多，则用科学计数法表示，10为基数。 setfioflags() 控制定点输出12345678910111213141516#include &lt;iostream&gt;#include &lt;iomanip&gt; using namespace std; int main(){ float num1 = 13.000f,num2 = 14.568f,num3 = 1.2f; cout &lt;&lt; setiosflags(ios::fixed|ios::showpoint); cout &lt;&lt; setprecision(4); cout &lt;&lt; \"第一个数：\" &lt;&lt; num1 &lt;&lt; endl; cout &lt;&lt; \"第三个数：\" &lt;&lt; num2 &lt;&lt; endl; cout &lt;&lt; \"第二个数：\" &lt;&lt; num3 &lt;&lt; endl; return 0; } setiosflags() 是通过状态标志来实现对输出的控制的。状态标志功能如下表 状态标志 功能 ios::left 左对齐，右边填空格 ios::dec 所有整数以十进制输出 ios::right 右对齐，左边填空格 ios::scientific 以科学计数法形式输出浮点数 ios::hex 所有整数以十六进制输出 ios::fixed 以定点形式输出浮点数 ios::oct 所有整数以八进制输出 ios::showpoint 显示小数点和尾部的零 ios::showpos 在正数前面输出+ ios::uppercase 对于十六进制输出，使用大写字母表示 setiosflags() 需要与 setprecision() 一起使用。如果状态标志设为 ios::fixed，那么setprecision()设置的数字，就表示小数位的个数，不足补零。","link":"/AngelNI.github.io/C-初学/"},{"title":"DFS","text":"DFS深度优先搜索算法（Depth-First-Search），是搜索算法的一种。是沿着树的深度遍历树的节点，尽可能深的搜索树的分支。当节点v的所有边都己被探寻过，搜索将回溯到发现节点v的那条边的起始节点。这一过程一直进行到已发现从源节点可达的所有节点为止。如果还存在未被发现的节点，则选择其中一个作为源节点并重复以上过程，整个进程反复进行直到所有节点都被访问为止（属于盲目搜索）。 “一路走到头，不撞墙不回头” 深度优先搜索属于图算法的一种，是一个针对图和树的遍历算法，英文缩写为DFS即Depth First Search。深度优先搜索是图论中的经典算法，利用深度优先搜索算法可以产生目标图的相应拓扑排序表，利用拓扑排序表可以方便的解决很多相关的图论问题，如最大路径问题等等。一般用堆数据结构来辅助实现DFS算法。其过程简要来说是对每一个可能的分支路径深入到不能再深入为止，而且每个节点只能访问一次。 树状图图解例如，想要从1到9，每到一个岔路口你有两种选择，你可以选择左枝，或者右枝，共两种可能，但是当你走到死胡同时，你只能原路返回，走到这个死胡同的上一个路口，走另一条路，依次类推，直到走到终点，也就是九。你可能会问，这不明摆着呢吗，直接从1经过8到9不就行了。没错，这是最直接的办法，但计算机傻啊，没有你聪明啊，它只会，一次一次的尝试，直到最终结果。 下面是图解 例题给定整数a1、a2、…….an，判断是否可以从中选出若干数，使它们的和恰好为K。 输入 首先，n和k，n表示数的个数，k表示数的和。接着一行n个数。（1&lt;=n&lt;=20,保证不超int范围） 输出 如果和恰好可以为k，输出“YES”，否则“NO” 样例输入 1234 131 2 4 7 样例输出 1YES 思路每一个数有加与不加两种可能，从树的一枝不加到尾，然后，再从叶末返回上一层叶节点，走另一个分支，也就是加上最后一个，与所求的和比较，不符再重复上述操作。直到找到与所求和相等返回Yes 实现1234567891011121314151617181920212223242526#include&lt;iostream&gt;#include&lt;stdio.h&gt;using namespace std;int n,k,a[50];int dfs(int i,int sum){ if(i==n) return sum==k; if(dfs(i+1,sum)) return 1; if(dfs(i+1,sum+=a[i])) return 1; return 0; }int main(){ cin&gt;&gt;n&gt;&gt;k; for(int i=0;i&lt;n;i++) cin&gt;&gt;a[i]; if(dfs(0,0)) cout&lt;&lt;\"YES\"&lt;&lt;endl; else cout&lt;&lt;\"No!\"&lt;&lt;endl; return 0; }","link":"/AngelNI.github.io/DFS/"},{"title":"CNN--tensorflow--code-learning","text":"不知道未来如何变化，总有人相信童话。 这是以tensorflow为框架，写的关于MNIST数据识别的卷积神经网络的python代码，这个代码是自己一点一点把别人的代码打印到Calab，修改，运行，再修改，再运行，我是代码的生产者，也是代码的搬运工，哈哈~ 发到博客上，也很方便看，啊哈哈哈。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283import tensorflow as tf import tensorflow.examples.tutorials.mnist.input_data as input_datamnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True) #下载并加载mnist数据x = tf.placeholder(tf.float32, [None, 784]) #输入的数据占位符y_actual = tf.placeholder(tf.float32, shape=[None, 10]) #输入的标签占位符#定义一个函数，用于初始化所有的权值 Wdef weight_variable(shape): initial = tf.truncated_normal(shape, stddev=0.1) return tf.Variable(initial)#定义一个函数，用于初始化所有的偏置项 bdef bias_variable(shape): initial = tf.constant(0.1, shape=shape) return tf.Variable(initial) #定义一个函数，用于构建卷积层def conv2d(x, W): return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')#定义一个函数，用于构建池化层def max_pool(x): return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],strides=[1, 2, 2, 1], padding='SAME')#定义一个函数，用于初始化所有的权值 Wdef weight_variable(shape): initial = tf.truncated_normal(shape, stddev=0.1) return tf.Variable(initial)#定义一个函数，用于初始化所有的偏置项 bdef bias_variable(shape): initial = tf.constant(0.1, shape=shape) return tf.Variable(initial) #定义一个函数，用于构建卷积层def conv2d(x, W): return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')#定义一个函数，用于构建池化层def max_pool(x): return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],strides=[1, 2, 2, 1], padding='SAME')#构建网络x_image = tf.reshape(x, [-1,28,28,1]) #转换输入数据shape,以便于用于网络中W_conv1 = weight_variable([5, 5, 1, 32]) b_conv1 = bias_variable([32]) h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1) #第一个卷积层h_pool1 = max_pool(h_conv1) #第一个池化层W_conv2 = weight_variable([5, 5, 32, 64])b_conv2 = bias_variable([64])h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2) #第二个卷积层h_pool2 = max_pool(h_conv2) #第二个池化层W_fc1 = weight_variable([7 * 7 * 64, 1024])b_fc1 = bias_variable([1024])h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64]) #reshape成向量h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1) #第一个全连接层keep_prob = tf.placeholder(\"float\") h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob) #dropout层W_fc2 = weight_variable([1024, 10])b_fc2 = bias_variable([10])y_predict=tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2) + b_fc2) #softmax层cross_entropy = -tf.reduce_sum(y_actual*tf.log(y_predict)) #交叉熵train_step = tf.train.GradientDescentOptimizer(1e-3).minimize(cross_entropy) #梯度下降法correct_prediction = tf.equal(tf.argmax(y_predict,1), tf.argmax(y_actual,1)) accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\")) #精确度计算sess=tf.InteractiveSession() sess.run(tf.initialize_all_variables())for i in range(20000): batch = mnist.train.next_batch(50) if i%100 == 0: #训练100次，验证一次 train_acc = accuracy.eval(feed_dict={x:batch[0], y_actual: batch[1], keep_prob: 1.0}) print('step %d, training accuracy %g'%(i,train_acc)) train_step.run(feed_dict={x: batch[0], y_actual: batch[1], keep_prob: 0.5})test_acc=accuracy.eval(feed_dict={x: mnist.test.images, y_actual: mnist.test.labels, keep_prob: 1.0})print(\"test accuracy %g\"%test_acc) 博文参考：https://morvanzhou.github.io/tutorials/machine-learning/tensorflow/5-03-CNN1/","link":"/AngelNI.github.io/CNN--tensorflow-code-learn/"},{"title":"Fermat's Last Theorem","text":"QuestionDescription 对于输入的n,判断这个一个三元方程xn+yn=znx^n+y^n=z^nx**n+y**n=z*n*是否有整数解 Input 单组输入 第一行一个整数TTT,代表输入的数据个数 接下来T行，每行一个正整数n。 1≤T≤100 1≤n≤100000 Output 输出T行，对于每个输入的n,如果有整数解输出”YES”,否则输出”NO”. Analyse费马大定理，又被称为“费马最后的定理”，由17世纪法国数学家皮耶·德·费玛提出。 他断言当整数n &gt;2时，关于x, y, z的方程 x^n + y^n = z^n 没有正整数解。 费马达定理的证明有一个非常巧妙的方法证明，自己去领悟精髓吧。 code12345678910111213141516#include&lt;bits/stdc++.h&gt;using namespace std;const int N = 1e6+100;typedef long long ll;int main(){int n,t;cin&gt;&gt;t;for(int i=1;i&lt;=t;i++){cin&gt;&gt;n;if(n&lt;=2) cout&lt;&lt;\"YES\"&lt;&lt;endl;else cout&lt;&lt;\"NO\"&lt;&lt;endl;}return 0;}","link":"/AngelNI.github.io/Fermat-s-Last-Theorem/"},{"title":"生活随笔","text":"不妨先做出点成绩，然后再去强调你的感受，否则，生命中只有唧唧歪歪，怎么看都是矫情。 可以确切的说这个暑假是颇丰的一个暑假，学习了机器学习的知识，提升了自己的代码编程能力，增强了自己的动手能力，还有与同伴交流研讨，这些都是难忘的。更重要的是对身心的锻炼，在这个炎热的夏天，38摄氏度是常事，顶着高温。学习也是比较枯燥的，自己上网学习机器学习的内容，做笔记，枯燥的环境有人离开，也有人留下来，真的是对身心的一个极大的挑战。这让我想起，天将降大任于斯人也，必先苦其心志，劳其筋骨，饿其体肤，空乏其身，行拂乱其所为，所以动心忍性，曾益其所不能。虽说蜀道之难难于上青天，但风雨过后的彩虹却有人见证过。也许我们缺少的是恒心吧，但在学习的道路上，没有了毅力怎能攀登知识的顶峰，不用知识武装自己怎么能克服人生的艰难。虽然在你看来只是一些空话，但是只有经历过才会懂得，恒心，毅力是必不可少的，更多的时候用言语表达只是证明，你说过，只是空话，只有实践，只有自己眼睛瞅着前方的目标，手里做着小事情才能证明你自己。不止说过，做过才最重要啊。这是我一暑假的体会吧，这才是这个暑假的宝贵的精神财富吧。","link":"/AngelNI.github.io/Essay/"},{"title":"Gradient Descent","text":"最美的等待是，我们——未来可期。 场景引入梯度下降法的基本思想可以类比为一个下山的过程。假设这样一个场景：一个人被困在山上，需要从山上下来(i.e. 找到山的最低点，也就是山谷)。但此时山上的浓雾很大，导致可视度很低。因此，下山的路径就无法确定，他必须利用自己周围的信息去找到下山的路径。这个时候，他就可以利用梯度下降算法来帮助自己下山。具体来说就是，以他当前的所处的位置为基准，寻找这个位置最陡峭的地方，然后朝着山的高度下降的地方走，同理，如果我们的目标是上山，也就是爬到山顶，那么此时应该是朝着最陡峭的方向往上走。然后每走一段距离，都反复采用同一个方法，最后就能成功的抵达山谷。 我们同时可以假设这座山最陡峭的地方是无法通过肉眼立马观察出来的，而是需要一个复杂的工具来测量，同时，这个人此时正好拥有测量出最陡峭方向的能力。所以，此人每走一段距离，都需要一段时间来测量所在位置最陡峭的方向，这是比较耗时的。那么为了在太阳下山之前到达山底，就要尽可能的减少测量方向的次数。这是一个两难的选择，如果测量的频繁，可以保证下山的方向是绝对正确的，但又非常耗时，如果测量的过少，又有偏离轨道的风险。所以需要找到一个合适的测量方向的频率，来确保下山的方向不错误，同时又不至于耗时太多！ Gradient Descent相关概念1.步长或学习效率(learning rare)：步长决定在梯度下降过程中，每一步沿梯度负方向前进的距离。 2.假设函数(hppothesis function)：也就是我们的模型学习到的函数 记为 h_θ(x) = θ0x0+θ1+x1+θ2x2+…=θTX 3.损失函数(loss function): 损失函数是用来评估模型h_θ(x)的好坏，通常用损失函数来度量拟合的程度，线性回归中损失函数通常为label和假设函数输出的差的平方。自己理解为（实际值-真实值）的平方。 损失函数梯度下降的基本过程就和下山的场景很类似。 首先，我们有一个可微分的函数。这个函数就代表着一座山。我们的目标就是找到这个函数的最小值，也就是山底。根据之前的场景假设，最快的下山的方式就是找到当前位置最陡峭的方向，然后沿着此方向向下走，对应到函数中，就是找到给定点的梯度 ，然后朝着梯度相反的方向，就能让函数值下降的最快！因为梯度的方向就是函数之变化最快的方向(在后面会详细解释) 所以，我们重复利用这个方法，反复求取梯度，最后就能到达局部的最小值，这就类似于我们下山的过程。而求取梯度就确定了最陡峭的方向，也就是场景中测量方向的手段。那么为什么梯度的方向就是最陡峭的方向呢？接下来，我们从微分开始讲起 微分看待微分的意义，可以有不同的角度，最常用的两种是： 函数图像中，某点的切线的斜率 函数的变化率 几个微分的例子： 梯度梯度实际上就是多变量微分的一般化。 下面这个例子： 算法过程1.先决条件：确认优化模型的假设函数h_θ(x)和损失函数J_(θ) 2.参数的初始化: 初始化假设函数的参数θ(注：θ是一个向量），算法中止距离ϵ以及步长α 3.确定当前位置的损失函数的梯度，对于θ_j,梯度如下 4.确定是否所有的θ_j,梯度下降的距离都小于ϵ，如果小于则算法中止，当前为最后结果，否则，则重复步骤（3） 5.更新所有的θ，对于θ_j（其更新的表达式如下 梯度下降的形式BGD、SGD、以及MBGD三种算法中文名分别为 批量梯度下降（Batch gradient descent） 批量梯度下降法（Batch Gradient Descent，简称BGD）是梯度下降法最原始的形式，它的具体思路是在更新每一参数时都使用所有的样本来进行更新 优点：全局最优解；易于并行实现； 缺点：当样本数目很多时，训练过程会很慢。 随机梯度下降（Stochastic gradient descent） 随机梯度下降是通过每个样本来迭代更新一次， 如果样本量很大的情况（例如几十万），那么可能只用其中几万条或者几千条的样本，就已经将theta迭代到最优解了，对比上面的批量梯度下降，迭代一次需要用到十几万训练样本，一次迭代不可能最优，如果迭代10次的话就需要遍历训练样本10次。但是，SGD伴随的一个问题是噪音较BGD要多，使得SGD并不是每次迭代都向着整体最优化方向。 优点：训练速度快； 缺点：准确度下降，并不是全局最优；不易于并行实现。 小批量梯度下降（Mini-batch gradient descent） 有上述的两种梯度下降法可以看出，其各自均有优缺点，那么能不能在两种方法的性能之间取得一个折衷呢？即，算法的训练过程比较快，而且也要保证最终参数训练的准确率，而这正是小批量梯度下降法（Mini-batch Gradient Descent，简称MBGD）的初衷。MBGD在每次更新参数时使用b个样本（b一般为10） 不过都叫梯度下降算法，可见他们的核心是没有变的，变化的只是取训练集的方式，而梯度下降最核心的就是对函数求偏导，这个是在高等数学里有的。 Practice1234567891011121314151617181920212223242526272829303132333435363738394041424344454647import numpy as npfrom scipy import statsimport matplotlib.pyplot as plt#构造训练数据 h（x）x = np.arange(0.,10.,0.2)m = len(x)x0=np.full(m,1.0)train_data = np.vstack([x0,x]).T #通过矩阵变化得到测试集【x0，x1】y = 4*x+1+np.random.randn(m)#构造“标准”答案def BGD(alpha,loops,epsilon): ''' alpha:步长 loops:循环次数 epsilon:收敛精度 ''' count=0#loop次数 thata = np.random.randn(2)#随机thata向量初始的值也就是起点位置 err = np.zeros(2)#上次thata的值，初始化为0的向量 finish=0#完成标志位 result = [] while count&lt;loops: count+=1 #所有训练数据的期望更新一次thata sum = np.zeros(2)#初始化thata更次年总和 for i in range(m): cost = (np.dot(thata,train_data[i])-y[i])*train_data[i] sum+=cost thata = thata-alpha*sum result.append(np.linalg.norm(thata-err)) if np.linalg.norm(thata-err)&lt;epsilon:#判断是否收敛 finish = 1 break else: err=thata#没有则将当前thata向量赋值给err，作为下次判断参数 print (f'SGD结果:\\tloop——counts： [%d]\\tthata[%f,%f]'%(count,thata[0],thata[1])) return thata,resultif __name__=='__main__': result=[] thata,result=BGD(0.00009,10000,1e-4) slope,intercept,r_value,p_value,slope_std_error=stats.linregress(x,y) print(f'Stata结果:\\tintercept(截距)：[%s]\\tslope(斜率)：[%s]'%(intercept,slope)) for i in range(len(result)): plt.scatter(i,result[i]) #plt.plot(x,y,'k+') #plt.plot(x,thata[1]*x+thata[0],'r') plt.show() 结果如下","link":"/AngelNI.github.io/Gradient-Descent/"},{"title":"Fleury 算法","text":"Fleury 算法Fleury算法是从离散书上看到的，书上详细的写了算法的操作。在这里用主要用C语言实现。在这里隆重感谢曹老板的鼎力支持。膜拜~ 伪代码输入 ：欧拉图 任取 v0∈V(G),令P0 = v0 ，i = 0. 设 Pi = v0e0v1e1……eivi, 1如果E（G） - {e1,e2……ei}中没有与vi关联的边则计算停止；否则按下述条件从E（G） -{e1，e2，……ei}中任取一条边ei+1： （a） ei+1与vi相关联； （b） 除非无别的边可提供，否则ei+1不应该为Gi = G-{e1，e2，……ei}中的桥。 设ei+1=（vi,vi+1）,把ei+1,vi+1加入pi得到pi+1. 令i=i+1，返回2. 实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117#include&lt;stdio.h&gt;void fleury ();int Bridge (int m, int k);int eulertu[10000][10000] = 0;int V,E;int main (){printf(“顶点数：”);scanf(“%d”,&amp;V);printf(“边数：”);scanf(“%d”,&amp;E); //输入几个点，几条边int i,j;int m,n;int count;int o=1;printf(“输入有边的俩个点:\\n”);for (i = 0; i &lt; E; i++){scanf(\"%d %d\",&amp;m,&amp;n); //输入有边的俩个点 eulertu[m][n] = eulertu[n][m] = 1; }for (i = 0; i &lt; V; i++) //判断是否为欧拉图 { count = 0; for (j = 0; j &lt; V; j++) { if (eulertu[i][j]==1) count++; } if (count%2!=0) { printf(\"不是欧拉图\"); o=0; break; } if(o==0) break; }if(o==1){ fleury(); printf(\"end\");} return 0;}void fleury (){int a[10000] ={0};int i,j;int k = 0;int bridge = 1;int t;printf(“%d—&gt;”,a[0]);for (i = 0; i &lt; E; i++){for (j = 0; j &lt; V; j++){if(eulertu[a[k]][j]==1){eulertu[a[k]][j] = eulertu[j][a[k]] = 0;if(Bridge(a[k],j)){t = j;eulertu[a[k]][j] = eulertu[j][a[k]] = 1;}else{k++;a[k] = j;printf(“%d—&gt;”,j);bridge = 0;break;} } } if (bridge) { eulertu[a[k]][t] = eulertu[t][a[k]] = 0; k++; a[k] = t; printf(\"%d---&gt;\",t); } bridge = 1;}}int Bridge (int m, int k){int a[10000];int i = 0;int t = 0;int n = 0;int p = 0;for(i=0;i&lt;10000;i++)a[i]=-1;a[t] = m;for (t = 0; a[t] != -1; t++ ){for (i = 0; i &lt; V; i++){if (eulertu[a[t]][i] == 1 &amp;&amp; i == k)return 0;if (eulertu[a[t]][i] == 1){ p=0; while(a[p]==-1) { p++; n++; a[n] = i; } } }}return 1;} ​","link":"/AngelNI.github.io/Fleury-算法/"},{"title":"HTML学习","text":"HTNL——BeginHyper Text Markup Language ，short for HTML ,is a standard markup language for creating web pages.The web pages which we usually scan are written by it.I want to learn a fewer about it because of writing blog and modifying my blog’s framework. I need it. The simply example1234567891011&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt;&lt;meta charset=\"utf-8\"&gt;&lt;title&gt;this is a title&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;h1&gt;First level title&lt;/h1&gt; &lt;p&gt;paragraph&lt;/p&gt;&lt;/body&gt;&lt;/html&gt; explanation 12345678&lt;!DOCTYPE html&gt; 声明HTML5文档&lt;html&gt; 元素是HTML页面的根元素&lt;head&gt; 元素包含了文档的元数据&lt;title&gt; 文档的标题&lt;body&gt; 可见的页面内容&lt;h1&gt; 一级标题&lt;p&gt; 段落&lt;meta charset = \"utf-8\"&gt; 声明编码utf-8 Others1.HTML link1&lt;a href=\"http://baidu.com\"&gt;This is baidu link&lt;/a&gt; 2.picture1&lt;imag scr=\"(url)\" width=\"258\" height=\"39\" /&gt; 3.lind feed1&lt;br/&gt; 4.level1&lt;hr&gt; 5.notes1&lt;!--notes--&gt; 6.bold1&lt;b&gt; bold &lt;/b&gt; I simply learned basics of HTML.Maybe it is very simply ,but it’s a new stduy.Come on !!!","link":"/AngelNI.github.io/HTML学习/"},{"title":"Just do it!","text":"放假了哈，啊哈哈哈啊哈哈~🤣🤣 今天，7月11日，考完了最后一科大学物理，结束了大一一年的学习生活，话说匆匆，也来不及挥手。 大一这一年，自我感觉收获还是蛮多的，参加过青年志愿者志愿活动❤️，去支过教❤️，参加过社团学习，学过硬件的一些东西，在宿舍焊过电路板😱，做过变压器（这个是基础，没啥高大上的），只是，后来没坚持下来，自我解释到毕竟不是学电气专业的😑😑。作为一个计算机专业的，学好编程才对嘛，现在简单的掌握了C语言和Python，入门级别，还有许多要深入。其实，在这个学期，一直想进算法协会ACM，第一次选拔也没如愿，还好在第二次选拔靠运气进了。兴致冲冲的准备好好学习算法，好好打比赛，拿个奖还能炫耀一下（白日做梦中ing🙃🙃），临期末的突转，跑去学AI😵，还好有数据挖掘的基础，入门的机器学习的算法还是能理解，能简单用Python实现 （学习笔记在GitHub我的仓库中有😎）。希望在这个暑期培训中，能有收获🙏🙏，之后的一年中好好学习AI，希望能有个比较好的成果。当然，算法也要学的，AI的老师也是我们下学期的数据结构的老师😮😮，算法，灵魂啊，除了书本知识，会实际实践才是最重要的。大学，自我学习才是最重要的。比如博客我真是一点不懂，只是按照百度上的教程，查找教程，向同学问，开始搭建，一开始，折腾了三四天，才看起来比较像样。还是比较有感触的，从没有到有，今天，我才能在这里 b b😂😂。 大一的一年至此结束了，还有两个月就大二了，好慌好慌真的好慌。 没有暑假，有了第一次，还差第二次吗？","link":"/AngelNI.github.io/Just-do-it/"},{"title":"KNN-Self-practice","text":"有一天我结婚了，你一定要来哦，因为没有新娘，那该有多尴尬. 这是我的自己写的第一个KNN比较简单的练习案例，有关于KNN的介绍请参考我的上篇博文 This is my first simple exercise case of KNN written by myself. For an introduction to KNN, please refer to my last blog post. 我在这里 123456789101112131415161718192021222324252627#导包import numpy as npfrom matplotlib import pyplot as pltimport operator%matplotlib inline#自我创建数据集data=[ [0.8,1.8], [0.9,2.1], [1.0,1.5], [1.2,1.9], [1.3,2.0], [2.5,1.7], [2.8,1.5], [2.5,1.4], [2.7,1.9], [2.6,1.8], [1.9,3.3], [2.0,2.9], [2.2,2.8], [2.1,2.9], [1.8,3.0],]label=['a','a','a','a','a','b','b','b','b','b','c','c','c','c','c']print(label)train_data = np.array(data)print(train_data) 12345678910111213141516171819202122232425262728293031x_1=[]y_1=[]x_2=[]y_2=[]x_3=[]y_3=[]for i in range(5): x_1.append(data[i][0]) y_1.append(data[i][1]) x_2.append(data[i+5][0]) y_2.append(data[i+5][1]) x_3.append(data[i+10][0]) y_3.append(data[i+10][1])x = []y = []for j in range(15): x.append(data[j][0]) y.append(data[j][1])plt.scatter(x,y)print(f'{x_1} \\n {y_1}\\n{x_2} \\n {y_2}\\n{x_3}\\n {y_3} ')f,ax=plt.subplots(1,1,figsize=(10,10))for i in range (5): ax.scatter(x_1[i],y_1[i],label='skitcat',color='r',marker='o') ax.scatter(x_2[i],y_2[i],label='skitcat',color='b',marker='o') ax.scatter(x_3[i],y_3[i],label='skitcat',color='g',marker='o')test = [[1.5,2.85]]##自定义点，从图中可以看出，很明显属于第三类x_test=1.5y_test=2.85ax.scatter(test[0][0],test[0][1],label='skitcat',color='m',marker = 'x')test = np.array(test) 从图中可以看出，很明显属于第三类 1234#定义距离公式def d_euc(x, y):#欧式距离 d = np.sqrt(np.sum(np.square(x- y))) return d 123456789101112131415161718192021def KNN(train_data,test,label,k): distance=[] for i in train_data: distance.append(d_euc(i,train_data)) distance = np.array(distance) index = distance.argsort() # 获取按距离大小排序后的索引 #print(index) sort_dis = np.sort(distance) count={} o=0 print(label) for i in index: o=o+1 label_vote=label[i] count[label_vote] = count.get(label_vote,0)+1 ##返回特定的键值，否则返回 0 if o&gt;k: break print(label_vote) print(count) final_outcome=majory_vote(count) return final_outcome 12345#定义决策方案——多数表决法def majory_vote(count): sorted_class_count = sorted( count.items(), key=operator.itemgetter(1), reverse=True) return sorted_class_count 12345label=['a','a','a','a','a','b','b','b','b','b','c','c','c','c','c']test=[3.0,2.0]test = np.array(test)final_label = KNN(train_data,test,label, 6)final_label 最后结果 )) 可以发现最初我们看到的真实结果一样属于c类。","link":"/AngelNI.github.io/KNN-Practice/"},{"title":"KNN——k-Nearest Neighbor","text":"海绵宝宝：“派大星，你为什么叫派大星” 派大星：“因为我是上帝拍下来保护你的大星星” 一、Concept1.1Language DescriptionK最近邻(k-Nearest Neighbor，KNN)分类算法，是一个理论上比较成熟的方法，也是最简单的机器学习算法之一。该方法的思路是：如果一个样本在特征空间中的k个最相似(即特征空间中最邻近)的样本中的大多数属于某一个类别，则该样本也属于这个类别。即是给定一个训练数据集，对新的输入实例，在训练数据集中找到与该实例最邻近的K个实例（也就是所说的K个邻居）， 这K个实例的多数属于某个类，就把该输入实例分类到这个类中。 KNN 算法的核心思想和最近邻算法思想相似，都是通过寻找和未知样本相似的类别进行分类。但 NN 算法中只依赖 1 个样本进行决策，在分类时过于绝对，会造成分类效果差的情况，为解决 NN 算法的缺陷，KNN 算法采用 K 个相邻样本的方式共同决策未知样本的类别,这样在决策中容错率相对于 NN 算法就要高很多，分类效果也会更好。 1.2 graphic例子：要区分“猫”和“狗”，通过“claws”和“sound”两个feature来判断的话，圆形和三角形是已知分类的了，那么这个“star”代表的是哪一类呢？ k＝3时，这三条线链接的点就是最近的三个点，那么圆形多一些，所以这个star就是属于猫。 二、Algorithmic Description1.pseudo code 2.steps 初始化距离为最大值 计算未知样本和每个训练样本的距离dist 得到目前K个最邻近样本中的最大距离maxdist 如果dist小于maxdist，则将该训练样本作为K-最近邻样本 重复步骤2,3,4，直到未知样本和所有训练样本的距离都算完 统计K个最近邻样本中每个类别出现的次数 选择出现频率最大的类别作为未知样本的类别 三、KNN‘s three elements of model1.Distance measure距离度量，说白了就是距离计算公式。 常见的距离计算公式有如下： 1.欧氏距离 2.曼哈顿距离 3.余弦距离 4.皮尔逊系数 5.杰卡德距离 6.闵可夫斯基距离 7.切比雪夫距离 8.汉明距离 9.莱文斯坦距离1.1Euclidean distance欧氏距离是最常见的两点之间或多点之间的距离表示法，又称之为欧几里得度量，它定义于欧几里得空间中，是闵可夫斯基距离=2特殊情形. def d_euc(x, y): d = np.sqrt(np.sum(square(x - y))) return d1.2Manhattan Distance 12345def d_man(x, y): d = np.sum(abs(x - y)) return d 2.Selection of K Value不要小看了这个K值选择问题，因为它对K近邻算法的结果会产生重大影响。 1. 如果选择较小的K值，就相当于用较小的领域中的训练实例进行预测，“学习”近似误差会减小，只有与输入实例较近或相似的训练实例才会对预测结果起作用，与此同时带来的问题是“学习”的估计误差会增大，换句话说，K值的减小就意味着整体模型变得复杂，容易发生过拟合； 2. 如果选择较大的K值，就相当于用较大领域中的训练实例进行预测，其优点是可以减少学习的估计误差，但缺点是学习的近似误差会增大。这时候，与输入实例较远（不相似的）训练实例也会对预测器作用，使预测发生错误，且K值的增大就意味着整体的模型变得简单。 3. K=N，则完全不足取，因为此时无论输入实例是什么，都只是简单的预测它属于在训练实例中最多的累，模型过于简单，忽略了训练实例中大量有用信息。 3.Classification Decision Rules1.多数表决法 多数表决法类似于投票的过程，也就是在 K 个邻居中选择类别最多的种类作为测试样本的类别。 2.加权表决法 根据距离的远近，对近邻的投票进行加权，距离越近则权重越大，通过权重计算结果最大值的类为测试样本的类别。","link":"/AngelNI.github.io/KNN——k-Nearest-Neighbor/"},{"title":"K-means","text":"天空在高又怎样，抬起脚尖就可以离太阳就更近一点。 聚类对于”监督学习”(supervised learning)，其训练样本是带有标记信息的，并且监督学习的目的是：对带有标记的数据集进行模型学习，从而便于对新的样本进行分类。而在“无监督学习”(unsupervised learning)中，训练样本的标记信息是未知的，目标是通过对无标记训练样本的学习来揭示数据的内在性质及规律，为进一步的数据分析提供基础。对于无监督学习，应用最广的便是”聚类”(clustering)。 聚类是一种无监督的学习，它将相似的对象归到同一簇中。聚类的方法几乎可以应用所有对象，簇内的对象越相似，聚类的效果就越好。K-means算法中的k表示的是聚类为k个簇，means代表取每一个聚类中数据值的均值作为该簇的中心，或者称为质心，即用每一个的类的质心对该簇进行描述。 聚类和分类最大的不同在于，分类的目标是事先已知的，而聚类则不一样，聚类事先不知道目标变量是什么，类别没有像分类那样被预先定义出来，所以，聚类有时也叫无监督学习。 聚类分析试图将相似的对象归入同一簇，将不相似的对象归为不同簇，那么，显然需要一种合适的相似度计算方法，我们已知的有很多相似度的计算方法，比如欧氏距离，余弦距离，汉明距离等。事实上，我们应该根据具体的应用来选取合适的相似度计算方法。 “聚类算法”试图将数据集中的样本划分为若干个通常是不相交的子集，每个子集称为一个“簇”(cluster)，通过这样的划分，每个簇可能对应于一些潜在的概念或类别。 图解 上图是未做标记的样本集，通过他们的分布，我们很容易对上图中的样本做出以下几种划分。 当需要将其划分为两个簇时，即 k=2 时： 当需要将其划分为四个簇时，即 k=4 时： 聚类方法 1.K-means 2.DBSCAN聚类 3.DBSCAN笑脸聚类 k-means (无监督)概念理解kmeans算法又名k均值算法。其算法思想大致为：先从样本集中随机选取 k 个样本作为簇中心，并计算所有样本与这 k 个“簇中心”的距离，对于每一个样本，将其划分到与其距离最近的“簇中心”所在的簇中，对于新的簇计算各个簇的新的“簇中心”。 根据以上描述，我们大致可以猜测到实现kmeans算法的主要三点： （1）簇个数 k 的选择 （2）各个样本点到“簇中心”的距离 （3）根据新划分的簇，更新“簇中心” 前提准备（1）K值的选择 k 的选择一般是按照实际需求进行决定，或在实现算法时直接给定 k 值。 （2）距离的度量 距离的度量的方法有以下几种 1.有序性距离度量 1234（1）闵科夫斯基距离（2）欧式距离（3）曼哈顿距离（4）皮尔逊系数 2.无序属性距离度量 3.混合属性距离度量 算法步骤1、为中心向量c1, c2, …, ck初始化k个种子 2、分组: 12（1）将样本分配给距离其最近的中心向量（2）由这些样本构造不相交（ non-overlapping ）的聚类 3、确定中心: 用各个聚类的中心向量作为新的中心 4、重复分组和确定中心的步骤，直至算法收敛。 3、算法 k-means算法 输入：簇的数目k和包含n个对象的数据库。 输出：k个簇，使平方误差准则最小。 算法步骤： 123451.为每个聚类确定一个初始聚类中心，这样就有K 个初始聚类中心。2.将样本集中的样本按照最小距离原则分配到最邻近聚类3.使用每个聚类中的样本均值作为新的聚类中心。4.重复步骤2.3直到聚类中心不再变化。5.结束，得到K个聚类 伪代码 为避免运行时间过长，通常设置一个最大运行轮数或最小调整幅度阈值，若达到最大轮数或调整幅度小于阈值，则停止运行。 K-means算法分析1、k-means算法的性能分析 主要优点： 是解决聚类问题的一种经典算法，简单、快速。 对处理大数据集，该算法是相对可伸缩和高效率的。因为它的复杂度是0 (n k t ) , 其中, n 是所有对象的数目, k 是簇的数目, t 是迭代的次数。通常k &lt; &lt;n 且t &lt; &lt;n 。 当结果簇是密集的，而簇与簇之间区别明显时, 它的效果较好。 主要缺点 (1)、在簇的平均值可被定义的情况下才能使用，这对于处理符号属性的数据不适用。 (2)、在 K-means 算法中 K 是事先给定的，这个 K 值的选定是非常难以估计的。很多时候，事先并不知道给定的数据集应该分成多少个类别才最合适； (3)、在 K-means 算法中，首先需要根据初始聚类中心来确定一个初始划分，然后对初始划分进行优化。这个初始聚类中心的选择对聚类结果有较大的影响，一旦初始值选择的不好，可能无法得到有效的聚类结果； (4)、该算法需要不断地进行样本分类调整，不断地计算调整后的新的聚类中心，因此当数据量非常大时，算法的时间开销是非常大的； (5)、若簇中含有异常点，将导致均值偏离严重（即:对噪声和孤立点数据敏感）； (6)、不适用于发现非凸形状的簇或者大小差别很大的簇。 K-Means算法对于不同的初始值，可能会导致不同结果。解决方法： 121.多设置一些不同的初值，对比最后的运算结果）一直到结果趋于稳定结束，比较耗时和浪费资源2.很多时候，事先并不知道给定的数据集应该分成多少个类别才最合适。这也是 K-means 算法的一个不足。有的算法是通过类的自动合并和分裂，得到较为合理的类型数目 K. 2、k-means算法的改进方法——k-prototype算法 k-Prototype算法：可以对离散与数值属性两种混合的数据进行聚类，在k-prototype中定义了一个对数值与离散属性都计算的相异性度量标准。 K-Prototype算法是结合K-Means与K-modes算法，针对混合属性的，解决2个核心问题如下： 123451.度量具有混合属性的方法是，数值属性采用K-means方法得到P1，分类属性采用K-modes方法P2，那么D=P1+a*P2，a是权重，如果觉得分类属性重要，则增加a，否则减少a，a=0时即只有数值属性2.更新一个簇的中心的方法，方法是结合K-Means与K-modes的更新方法。3、k-means算法的改进方法——k-中心点算法 k-中心点算法：k -means算法对于孤立点是敏感的。为了解决这个问题，不采用簇中的平均值作为参照点，可以选用簇中位置最中心的对象，即中心点作为参照点。这样划分方法仍然是基于最小化所有对象与其参照点之间的相异度之和的原则来执行的。 实例 由上可以看出，第一次迭代后，总体平均误差值52.25~25.65，显著减小。由于在两次迭代中，簇中心不变，所以停止迭代过程，算法停止。 12345678910111213data = [ [0,2], [0,0], [1,0], [5,0], [5,2]]import numpy as npimport matplotlib.pyplot as plt%matplotlib inlinefor i in range(len(data)): plt.scatter(data[i][0],data[i][1],color='r')plt.show() 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162data_n= np.mat(data)def center(data ,k): dim = np.shape(data)[1] cen_M = np.mat(np.zeros((k,dim))) for i in range(dim): minJ = min(data[:,i]) rangeJ = float(max(data[:,i])-minJ) #print() #print('\\n') #print(minJ) cen_M[:,i] = np.mat(minJ + rangeJ * np.random.rand(k,1)) #print(data) return cen_M#center(data_n,k)def kmeans(data,k): m = np.shape(data)[0]#列的大小 classassment = np.mat(np.zeros((m,2))) centerpoint = center(data,k) Flag = True conut = 0 while Flag: Flag = False for i in range(m): mindis=np.inf ; minindex=-1 for j in range(k): disJ = np.linalg.norm(np.array(centerpoint[j,:])-np.array(data[i,:])) if disJ &lt; mindis: mindis = disJ; minindex = j; if classassment[i,0] !=minindex: Flag = True classassment[i,:] = minindex,mindis**2 #print(classassment) for cent in range(k): ptsInClust = data[np.nonzero(classassment[:,0].A==cent)[0]]#get all the point in this cluster centerpoint[cent,:] = np.mean(ptsInClust, axis=0)#get all the point in this cluster return centerpoint,classassment centerpoint,classassment=kmeans(data_n,k) def showCluster(dataSet, k, centroids, clusterAssment): ''' 数据可视化,只能画二维的图（若是三维的坐标图则直接返回1） ''' numSamples, dim = dataSet.shape mark = ['or', 'ob', 'og', 'ok','oy','om','oc', '^r', '+r', 'sr', 'dr', '&lt;r', 'pr'] # draw all samples for i in range(numSamples): markIndex = int(clusterAssment[i, 0]) plt.plot(dataSet[i, 0], dataSet[i, 1], mark[markIndex]) mark = ['Pr', 'Pb', 'Pg', 'Pk','Py','Pm','Pc','^b', '+b', 'sb', 'db', '&lt;b', 'pb'] # draw the centroids for i in range(k): plt.plot(centroids[i, 0], centroids[i, 1], mark[i], markersize = 12) plt.show()showCluster(data_n,2,centerpoint,classassment)print(data_n) knn k-means 对比","link":"/AngelNI.github.io/K-means/"},{"title":"Hello world","text":"记一次过程经历 最近，自己在搭一个博客，用 hexo+github，一开始按照网上的教程下载相应的软件，cmd安装，git bash 安装hexo，最开始可是在自己的本地可以预览，效果不错，直接就上传到github上的我的repo，结果cmd出错，由于对hexo 文件的位置不清，和出现的错误，我直接就删除了hexo，但是不是直接的卸载，有些文件还在（找不到啊 呜呜~），我用重新npm安装，发现还是不行，当时头大到想要格式化电脑了（还好没有，要不然就要重新慢慢下载了），然后我去找baidu，简书，发现自己的许多错误操作。好吧，我又从新开始。还是有error，我就按个所错误，发现自己有许多的本地配置没有设置，我就一条一条的修改（可气人了，一步踩一个坑，一步填一个坑），花了两天才把本地配置好（上课没时间啊）。 又因为，默认的主题很low（只是个人而言），不怎么喜欢，想换个主题，hexo上面有好多的主题，一个一个翻看，也没有喜欢的，现在比较流行的是NEXT主题（没错我找了度娘），就在网上下载NEXT主题包，一开始的主题内容，没设计的，所以我又找了度娘，还在CSDN上搜搜，发现许多大佬掉了许多的坑，也有填坑的方法(坑和经验，傻傻分不清），就开始一步一步自己搭，终于，经过一天多的自己的骚操作，在清明节的下午本地可以看到比较好的主题设置（还有点不满意，后续会修改）。 感受 （真是不作死不会死，谁TM知道我为什么突然想到建博客呢！） 经过三天多自己的摸索，我这个小小白终于把自己的blog建成了（~~热烈欢迎大家访问）。在建博客的过程中，真是有点头大了，因为自己对命令行操作一点不了解，完全是两眼一模黑，在黑暗中摸索（哈哈，有点夸张），出现错误也不知道哪里的问题，真的很感谢度娘的帮助（说白了，多谢大佬们的坑啊）。 这篇文章的标题是printf(“Hello,world”),学C语言的都知道这是入门的基础程序，我想用这个标题想说，当你去接触一个陌生不懂的东西时，不是一帆风顺的，总会有大波小浪，不过，经过自己的一步一步的摸索总会找到自己的___（你懂的哈），不管如何都不要放弃，既然已经迈开了重要的第一步，就要坚持走到终点。 对了，还有还有，“生命在于运动，电脑在于折腾啊”，不管会不会，先折腾折腾吧（坏了我可不管~~) . . . . . . . . 度娘，真帅！！！","link":"/AngelNI.github.io/Hello-world-0/"},{"title":"Keras-learn-note(1)","text":"越努力，越幸运。 一些基本概念在开始学习Keras之前，一些基础知识是必备的，关于深度学习的基本概念和技术，在使用Keras之前大体了解一下基础知识，这将减少你学习中的困惑。 1.符号计算Keras的底层库使用Theano或TensorFlow，这两个库也称为Keras的后端。无论是Theano还是TensorFlow，都是一个“符号式”的库。 因此，这也使得Keras的编程与传统的Python代码有所差别。笼统的说，符号主义的计算首先定义各种变量，然后建立一个“计算图”，计算图规定了各个变量之间的计算关系。建立好的计算图需要编译以确定其内部细节，然而，此时的计算图还是一个“空壳子”，里面没有任何实际的数据，只有当你把需要运算的输入放进去后，才能在整个模型中形成数据流，从而形成输出值。 就像用管道搭建供水系统，当你在拼水管的时候，里面是没有水的。只有所有的管子都接完了，才能送水。 Keras的模型搭建形式就是这种方法，在你搭建Keras模型完毕后，你的模型就是一个空壳子，只有实际生成可调用的函数后（K.function），输入数据，才会形成真正的数据流。 2.张量张量是什么，一上来我也一脸懵逼，看了解释之后，嗯嗯。 张量可以看作是向量、矩阵的自然推广，用张量来表示广泛的数据类型。 规模最小的张量是0阶张量，即标量，也就是一个数。 当我们把一些数有序的排列起来，就形成了1阶张量，也就是一个向量 如果我们继续把一组向量有序的排列起来，就形成了2阶张量，也就是一个矩阵 把矩阵摞起来，就是3阶张量，我们可以称为一个立方体，具有3个颜色通道的彩色图片就是一个这样的立方体 把立方体摞起来，好吧这次我们真的没有给它起别名了，就叫4阶张量了，不要去试图想像4阶张量是什么样子，它就是个数学上的概念。 张量的阶数有时候也称为维度，或者轴，轴这个词翻译自英文axis。譬如一个矩阵[[1,2],[3,4]]，是一个2阶张量，有两个维度或轴，沿着第0个轴（为了与python的计数方式一致，本文档维度和轴从0算起）你看到的是[1,2]，[3,4]两个向量，沿着第1个轴你看到的是[1,3]，[2,4]两个向量。 要理解“沿着某个轴”是什么意思，不妨看下下面的代码： 12345678import numpy as npa = np.array([[1,2],[3,4]])sum0 = np.sum(a, axis=0)sum1 = np.sum(a, axis=1)print(sum0)print(sum1) 如果从坐标系的角度看二维矩阵，所谓的0轴就是沿y轴负方向，1轴沿x轴正方向。 3.data_format这是一个无可奈何的问题，在如何表示一组彩色图片的问题上，Theano和TensorFlow发生了分歧，’th’模式，也即Theano模式会把100张RGB三通道的16×32（高为16宽为32）彩色图表示为下面这种形式（100,3,16,32），Caffe采取的也是这种方式。第0个维度是样本维，代表样本的数目，第1个维度是通道维，代表颜色通道数。后面两个就是高和宽了。这种theano风格的数据组织方法，称为“channels_first”，即通道维靠前。 而TensorFlow，的表达形式是（100,16,32,3），即把通道维放在了最后，这种数据组织方式称为“channels_last”。 Keras默认的数据组织形式在~/.keras/keras.json中规定，可查看该文件的image_data_format一项查看，也可在代码中通过K.image_data_format()函数返回，请在网络的训练和测试中保持维度顺序一致。 4.函数式模型函数式模型，这个词很新鲜，好像是官方文档自己创造的。 在Keras 0.x中，模型其实有两种，一种叫Sequential，称为序贯模型，也就是单输入单输出，一条路通到底，层与层之间只有相邻关系，跨层连接统统没有。这种模型编译速度快，操作上也比较简单。第二种模型称为Graph，即图模型，这个模型支持多输入多输出，层与层之间想怎么连怎么连，但是编译速度慢。可以看到，Sequential其实是Graph的一个特殊情况。 在Keras1和Keras2中，图模型被移除，而增加了了“functional model API”，这个东西，更加强调了Sequential是特殊情况这一点。一般的模型就称为Model，然后如果你要用简单的Sequential，OK，那还有一个快捷方式Sequential。 由于functional model API在使用时利用的是“函数式编程”的风格，我们这里将其译为函数式模型。总而言之，只要这个东西接收一个或一些张量作为输入，然后输出的也是一个或一些张量，那不管它是什么鬼，统统都称作“模型”。 5.batch深度学习的优化算法，说白了就是梯度下降。每次的参数更新有两种方式。（我也不知道这个词为神魔出现在这里） 第一种，遍历全部数据集算一次损失函数，然后算函数对各个参数的梯度，更新梯度。这种方法每更新一次参数都要把数据集里的所有样本都看一遍，计算量开销大，计算速度慢，不支持在线学习，这称为Batch gradient descent，批梯度下降。 另一种，每看一个数据就算一下损失函数，然后求梯度更新参数，这个称为随机梯度下降，stochastic gradient descent。这个方法速度比较快，但是收敛性能不太好，可能在最优点附近晃来晃去，hit不到最优点。两次参数的更新也有可能互相抵消掉，造成目标函数震荡的比较剧烈。 为了克服两种方法的缺点，现在一般采用的是一种折中手段，mini-batch gradient decent，小批的梯度下降，这种方法把数据分为若干个批，按批来更新参数，这样，一个批中的一组数据共同决定了本次梯度的方向，下降起来就不容易跑偏，减少了随机性。另一方面因为批的样本数与整个数据集相比小了很多，计算量也不是很大。 基本上现在的梯度下降都是基于mini-batch的，所以Keras的模块中经常会出现batch_size，就是指这个。 顺便说一句，Keras中用的优化器SGD是stochastic gradient descent的缩写，但不代表是一个样本就更新一回，还是基于mini-batch的。 6.epochs这个词不想多说。epochs就是训练过程中数据将被“轮”多少次。","link":"/AngelNI.github.io/Keras-note-1/"},{"title":"Keras-learn-note(2)","text":"要么出众，要么出局，乾坤未定，你我都是黑马。 1 Keras后端😉Keras是一个模型级的库，提供了快速构建深度学习网络的模块。Keras并不处理如张量乘法、卷积等底层操作。这些操作依赖于某种特定的、优化良好的张量操作库。Keras依赖于处理张量的库就称为“后端引擎”。Keras提供了三种后端引擎Theano/Tensorflow/CNTK，并将其函数统一封装，使得用户可以以同一个接口调用不同后端引擎的函数 Theano是一个开源的符号主义张量操作框架，由蒙特利尔大学LISA/MILA实验室开发。 TensorFlow是一个符号主义的张量操作框架，由Google开发。 CNTK是一个由微软开发的商业级工具包。 1.1 切换后端如果你至少运行过一次Keras，你将在下面的目录下找到Keras的配置文件： c:/user/.keras/keras.json 如果该目录下没有该文件，你可以手动创建一个 文件的默认配置如下： 123456{ &quot;image_data_format&quot;: &quot;channels_last&quot;, &quot;epsilon&quot;: 1e-07, &quot;floatx&quot;: &quot;float32&quot;, &quot;backend&quot;: &quot;tensorflow&quot;} 将backend字段的值改写为你需要使用的后端：theano或tensorflow或者CNTK，即可完成后端的切换 2 第一个模型：全连接网络🤩12345678910111213141516171819202122232425262728293031import tensorflow as tffrom keras.layers import Input, Densefrom keras.models import Model# this returns a tensorinputs = Input(shape=(784,))# a layer instance is callable on a tensor, and returns a tensorx = Dense(64, activation='relu')(inputs)x = Dense(64, activation='relu')(x)predictions = Dense(10, activation=softmax)(x)# this creates a model that includes# the Input layer and three Dense layersmodel = Model(input=inputs, output=predictions)model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])model.fit(data, labels) # starts trainingdef softmax(x, axis=-1): \"\"\"Softmax of a tensor. # Arguments x: A tensor or variable. axis: The dimension softmax would be performed on. The default is -1 which indicates the last dimension. # Returns A tensor. \"\"\" return tf.nn.softmax(x, dim=axis) 2.1 函数介绍2.1.1 Inputnput(shape=None,batch_shape=None,name=None,dtype=K.floatx(),sparse=False,tensor=None) shape: 形状元组（整型） batch_shape: 形状元组（整型） name: 对于该层是可选的名字字符串 dtype: 预期的输入数据类型 sparse: 特定的布尔值，占位符是否为sparse tensor: 可选的存在的向量包装到Input层，如果设置了，该层将不会创建一个占位张量。 返回值：一个张量 2.1.2 Densekeras.layers.core.Dense(output_dim, init=’glorot_uniform’, activation=’linear’, weights=None, W_regularizer=None, b_regularizer=None, activity_regularizer=None, W_constraint=None, b_constraint=None, bias=True, input_dim=None) Dense层就是全链接层 output_dim：大于0的整数，代表该层的输出维度。模型中非首层的全连接层其输入维度可以自动推断，因此非首层的全连接定义时不需要指定输入维度。 init：初始化方法，为预定义初始化方法名的字符串，或用于初始化权重的Theano函数。该参数仅在不传递weights参数时才有意义。 activation：激活函数， weights：权值，为numpy array的list。该list应含有一个形如（input_dim,output_dim）的权重矩阵和一个形如(output_dim,)的偏置向量 W_regularizer：施加在权重上的正则项，为WeightRegularizer对象 b_regularizer：施加在偏置向量上的正则项，为WeightRegularizer对象 activity_regularizer：施加在输出上的正则项，为ActivityRegularizer对象 W_constraints：施加在权重上的约束项，为Constraints对象 b_constraints：施加在偏置上的约束项，为Constraints对象 bias：布尔值，是否包含偏置向量（即层对输入做线性变换还是仿射变换） input_dim：整数，输入数据的维度。当Dense层作为网络的第一层时，必须指定该参数或input_shape参数。 2.1.3 Model函数式模型 常用Model属性 model.layers：组成模型图的各个层 model.inputs：模型的输入张量列表 model.outputs：模型的输出张量列表 2.1.4 Model模型方法compile compile(self, optimizer, loss, metrics=None, loss_weights=None, sample_weight_mode=None, weighted_metrics=None, target_tensors=None) loss=’目标函数’ optimizer：优化器 metrics=[‘accuracy’])metrics: 列表，包含评估模型在训练和测试时的性能的指标 其他，我这个菜鸡用的的比较少，这里不一一列举 fit fit(self, x=None, y=None, batch_size=None, epochs=1, verbose=1, callbacks=None, validation_split=0.0, validation_data=None, shuffle=True, class_weight=None, sample_weight=None, initial_epoch=0, steps_per_epoch=None, validation_steps=None) model.fit（）向模型中输入训练集，验证集，迭代次数 fit()用于使用给定输入训练模型. evaluate evaluate(self, x, y, batch_size=32, verbose=1, sample_weight=None) model.evaluate():就像他的名字一样，主要对模型进行评估 Keras中model.evaluate（）返回的是 损失值和你选定的指标值（例如，精度accuracy） predict predict(self, x, batch_size=32, verbose=0) predict()用于实际预测.它为输入样本生成输出预测. Embedding Embedding(input_dim, output_dim, embeddings_initializer=’uniform’, embeddings_regularizer=None, activity_regularizer=None, embeddings_constraint=None, mask_zero=False, input_length=None) 嵌入层将正整数（下标）转换为具有固定大小的向量，如[[4],[20]]-&gt;[[0.25,0.1],[0.6,-0.2]] Embedding层只能作为模型的第一层 input_dim：大或等于0的整数，字典长度，即输入数据最大下标+1 output_dim：大于0的整数，代表全连接嵌入的维度 embeddings_initializer: 嵌入矩阵的初始化方法，为预定义初始化方法名的字符串，或用于初始化权重的初始化器。参考initializers embeddings_regularizer: 嵌入矩阵的正则项，为Regularizer对象 embeddings_constraint: 嵌入矩阵的约束项，为Constraints对象 mask_zero：布尔值，确定是否将输入中的‘0’看作是应该被忽略的‘填充’（padding）值，该参数在使用递归层处理变长输入时有用。设置为True的话，模型中后续的层必须都支持masking，否则会抛出异常。如果该值为True，则下标0在字典中不可用，input_dim应设置为|vocabulary| + 1。 input_length：当输入序列的长度固定时，该值为其长度。如果要在该层后接Flatten层，然后接Dense层，则必须指定该参数，否则Dense层的输出维度无法自动推断。 3 Keras 实现手写数字识别🤪下载数据.外网，要翻墙，下载速度快赶上蜗牛了 12345import kerasfrom keras.datasets import mnistimport matplotlib.pyplot as plt %matplotlib inline(train_images,train_labels),(test_images,test_labels) = mnist.load_data() 查看一下数据集大小 123456print(\"shape og train images is \",train_images.shape)print(\"shape of train label is \",train_labels.shape)print(\"train labels is \",train_labels)print('shape of test images is ',test_labels.shape)print('shape of test labels is ',test_labels.shape)print(\"test labels is \",test_labels) 想不想看看手写数字长啥样？？几行代码轻松搞定。 12345plt.figure()plt.imshow(train_images[0])plt.colorbar()plt.grid(False)plt.show() 为什么会有颜色呢？让我们变为灰度图片再看看 12345678910train_images= train_images / 255.0test_images= test_images / 255.0plt.figure(figsize=(10,10))for i in range(25): plt.subplot(5,5,i+1) plt.xticks([]) plt.yticks([]) plt.grid(False) plt.imshow(train_images[i], cmap=plt.cm.binary)plt.show() 好了数据大小也有了，手写数字也看了，接下来就让我们建立神经网络模型了。 建立模型 123456789101112def softmax(x, axis=-1): \"\"\"Softmax of a tensor. # Arguments x: A tensor or variable. axis: The dimension softmax would be performed on. The default is -1 which indicates the last dimension. # Returns A tensor. \"\"\" return tf.nn.softmax(x, dim=axis) 12345678# 设计网络from keras import modelsfrom keras.layers import Denseimport tensorflow as tfnetwork = models.Sequential()network.add(Dense(512,activation = \"relu\",input_shape=(28*28,)))network.add(Dense(10,activation = softmax)) 训练模型 12345678910111213141516#编译网络network.compile( optimizer = 'rmsprop',loss='categorical_crossentropy',metrics = ['accuracy'])#数据处理train_images = train_images.reshape((60000,28*28))train_images = train_images.astype('float32')/255test_images = test_images.reshape((10000,28*28))test_images = test_images.astype('float32')/255#处理标签from keras.utils import to_categoricaltrain_labels = to_categorical(train_labels)test_labels = to_categorical(test_labels)#训练模型network.fit(train_images,train_labels,epochs = 5,batch_size = 10) 测试模型 123test_loss,test_acc = network.evaluate(test_images,test_labels)print(f'test_loss : {test_loss}')print(f'test_acc :{test_acc}') 4.总结💪以上就简单的实现了用keras实现手写数据的识别，代码简短，但老记不住，忘记该用啥，该怎么拼写😅😅😅，理论基础还是要背牢的，还要多多使用啊，熟能生巧","link":"/AngelNI.github.io/Keras-note-2/"},{"title":"Keras-learn-note(3)","text":"May you be faithful to yourself, live earnestly and laugh freel. Keras 实现矩阵分解推荐系统算法简介这里简单介绍下推荐系统中最为主要的协同过滤算法，大致分为如下几类： 基于用户的协同过滤（给用户推荐与他相似的人购买的物品） 基于商品的协同过滤（给用户推荐和他之前喜欢的物品相似的物品） 基于模型的协同过滤：关联算法，聚类算法，分类算法，回归算法，矩阵分解，神经网络,图模型以及隐语义模型都属于这个范畴。 之前用了python来写矩阵分解，现在换种写法，用keras来实现矩阵分解。 导入数据123456import pandas as pdimport numpy as nprating = pd.read_csv('data/ratings.csv',sep=',')num_user = np.max(rating['userId'])num_movie = np.max(rating['movieId'])print(num_user,num_movie,len(rating)) 123#计算用户电影组合的R矩阵填充率R = len(rating)/(num_user*num_movie)print(f\"矩阵填充率:{R}\") 矩阵的填充率为：0.000853805025622708 搭建模型12345678910111213141516171819from keras import Modelimport keras.backend as Kfrom keras.layers import Embedding ,Reshape,Input,DotK.clear_session()def Recomand_model(num_user,num_movie,k): input_user = Input(shape=[None,],dtype='int32') model_user = Embedding(num_user+1,k,input_length = 1)(input_user) model_user = Reshape((k,))(model_user) input_moive = Input(shape=[None,],dtype=\"int32\") model_moive = Embedding(num_movie+1,k,input_length = 1)(input_moive) model_moive = Reshape((k,))(model_moive) out = Dot(1)([model_user,model_moive]) model = Model(input=[input_user,input_moive],outputs = out) model.compile(loss = 'mse',optimizer = 'Adam') model.summary() return model 1model =Recomand_model(num_user,num_movie,100) 注 model.summary()输出模型各层的参数状况 model.layers.Reshape() :将输出调整为特定的形状 数据处理1234train_u = rating['userId'].valuestrain_i = rating['movieId'].valuestrain_x = [train_u,train_i]train_y = rating[\"rating\"].values 训练模型1model.fit(train_x,train_y,batch_size = 100,epochs = 10) 预测1model.predict([[1],[2]]) 1array([[ 3.76612234]], dtype=float32)","link":"/AngelNI.github.io/Keras-note-3/"},{"title":"Learning makes me happy","text":"SharingThere are many interesting things waiting to be discovered by us . It’s never too late to learn. Don’t indulge yourself , don’t let yourself regret . 图灵机器人在线聊天这是一个基于图灵机器人和微信公众号相结合推出的微信在线聊天系统。 如果你对这个感兴趣这里有实现的操作 –&gt;&gt; It’s me 百度云下载 It’s me 提取码: ejuh 程序员的暖心话 to who?我们虽然不是浪漫的产生者，但我们可以做浪漫的搬运工。 项目：everywechat 功能：定时给朋友发送天气，提醒，每日一句，也可以智能自动回复好友，基于图灵机器人 项目地址：who is me QQ木马的简单实现，核心编程Finding from D的个人博客 QQ总是被盗怎么办？ 作为一个程序猿，对底层的代码还是了解一下子。只供参考，技术交流，后果自负。 百度云不限速下载器Baidu Netdisk Downloader是一款图形界面的百度网盘不限速下载器，支持 Windows、Linux、Mac。 在线工具，程序员的工具箱光说不能表达，附图一张 我在这呢！ python3 教程这个是最近发现的，里面有很多有关python的教程，还有一些实战项目。 没错又是我 经典技术书籍分享我又来喽","link":"/AngelNI.github.io/Learning-makes-me-happy/"},{"title":"暑假（补）-3","text":"不疯不魔，难以成佛。 学完了vector，接下来就开始学习其他容器了。这些都是C++ STL中的比较好用的方法，让你的编程变得简单。 迭代器iterator在这几天的使用来看，自认为迭代器是为了访问容器的元素。 123初始化： &lt; 容器类型 &gt;&lt; 数据类型 &gt; :: iterator &lt;名称&gt;例如：vector&lt;int&gt;::iterator iter; //这就定义了一个可以访问vector int型数据的 名为iter的迭代器 还有如下的迭代器初始化方法： 正向迭代器：容器类型：：iterator 名称 常量迭代器：容器类型：：const_iterator 名称 反向迭代器：容器类型：：reverse_iterator 名称 常量反向迭代器： 容器类型：：const_reverse_iterator 名称 下面就以一个实例来学习迭代器的使用方法。 123456789101112131415#include&lt;iostream&gt;#include&lt;vector&gt;using namespace std;int main(){ int a[10]={1,2,3,4,5,6,7,8,9,0}; vector&lt;int&gt; ve(a,a+10); vector&lt;int&gt;::iterator it; //正向迭代器与反向迭代器 for(it = ve.begin();it!=ve.end();++it)//听说 ++i 比 i++执行速度快 cout&lt;&lt;(*ve)&lt;&lt;endl; for(it = ve.rbegin();it!=ve.rend();++it)//听说 ++i 比 i++执行速度快 cout&lt;&lt;(*ve)&lt;&lt;endl; return 0;} 还有操作迭代器的三个函数 包含于头文件&lt; algorithm &gt; advance(p,n) 向前移动 n 个元素 distance(p,q) 计算两个迭代器的长度，在同一个容器内 iter_swap(p,q) 用于交换两个迭代器p，q 指向的值 集合set头文件&lt; set &gt; 其实，只要掌握了一个容器的操作方法，其他容器的方法都可以类比。 值得注意一点的是：集合内的容器不能重复，并且他会默认从小到大排序。 1234567891011#include&lt;set&gt;set&lt;int&gt; st;st.insert() //插入元素st.begin() // 返回第一个元素的迭代器st.end() //返回最后一个元素之后的迭代器，不是最后一个迭代器stclear() //清空所有元素st.count() //判断元素是否存在，返回bool类型st.empty() //判断是否为空 ，空则truest.erase() //删除集合中元素st.find() //返回一个被查找到的元素的迭代器，没有则返回end（），find(开始地址，尾地址，查找元素)st.size() //集合的大小 栈stack头文件&lt; stack &gt; 1234567//初始化stack&lt;int&gt; a;a.push() // 压入栈a.pop() //移除最顶端元素a.top() //访问最顶端元素a.size() //栈的大小a.empty() //判断是否为空 队列queue头文件&lt; queue &gt; 123456queue&lt;int &gt; q;q.push() //加入对列q.front() //队首元素q.pop（） //移除队首元素q.empty() //判断是否为空q.size() //队列大小 字典map头文件&lt; map &gt; 12345678910111213map&lt;int,int&gt; mp;mp.clear() //清空mpmp.size() //mp大小mp.empty() //判断是否为空mp.count(key) //判断key是否存在map&lt;int,int &gt;::iterator it;mp[0] =4;mp[1] = 2;mp[2] = 3;it = mp.find(1) //key，返回一个地址（*it）.first() //返回所指地址的key值（*it）.second() //返回所指地址的value值mp.insert(pair&lt;int,int&gt;(4,5)) //插入键值对","link":"/AngelNI.github.io/Learn-3/"},{"title":"仰望，仰望？","text":"Live a good life meet slowly. 临近开学的前几天，跑去郑州去玩 天气不算太热，下着稀稀疏疏小雨， 坐火车到了郑州，坐地铁去了郑大， 行走在郑大的校园，看着别样的风景， 新生军训的大队伍，举伞疾走零星的小哥哥小姐姐， 如花绽放的喷泉水，雨中静默含苞的粉荷花绿藕叶， 低吼着，等待着 雨中矗立的钟楼，远远遥望的图书馆 换上新衣的院楼，人来人往的校门口 庄严，稳重，高调，朴素 仰望，仰望吗？ 只有那些从不仰望星空的人，才不会掉进坑中 只有那些从不掉进坑中的人，就只会居高自乐 虫儿告诉我，今晚的星星好亮， 哈哈哈， 我被骗进坑里了","link":"/AngelNI.github.io/Looking-at-the-stars/"},{"title":"Makedown","text":"最近经过几天的奋斗，自己的博客基本框架终于搭建成功，接下来就是开始写文章了，不过上来就碰上个头疼的问题，就是怎么写的问题，我就想度娘请教（度娘，真帅），说是用Markdown语法写，最近在Notebook上写Python的学习笔记，老师说过要自学Markdown语法，说是非常简单（没错，就是很简单），下面就是Markdown的语法介绍啦，要好好学哟。 在编写 Markdown 时，强烈的推荐给大家一款简洁易用的 Markdown 编辑器 —— Typora 按照官方的说法就是 简单而强大，它不仅支持原生的语法，也支持对应的快捷键，更重要的是它还可以 实时预览 这里附上 Typora 的下载地址：点击这里 , 有兴趣的朋友可以下载来试试 好，下面开始进入正题，介绍一些常用的 Markdown 语法 (1) 标题Markdown语法：1234567891011#一级标题``##二级标题``###三级标题``####四级标题``#####五级标题``######六级标题 Typora快捷键：1234567891011Ctrl + 1：一级标题Ctrl + 2：二级标题Ctrl + 3：三级标题Ctrl + 4：四级标题Ctrl + 5：五级标题Ctrl + 6：六级标题 (2)粗体、斜体、删除线Markdown语法：1234567*斜体*``**粗体**``***加粗斜线***``~~删除线~~ Typora快捷键：1234567Ctrl+l ：斜体Ctrl+B：粗体Ctrl+U：下划线Alt + Shift + 5 ：删除线 (3) 引用块Markdown语法：1&gt; 文字引用 Typora快捷键：1Ctrl + Shift + Q (4)代码块Markdown语法：12&apos; 行内代码&apos;&apos;&apos;&apos; 多行代码&apos;&apos;&apos; Typora快捷键：123行内代码： Ctrl + Shift + `多行代码：Ctrl + Shift +K (5)公式块Markdown语法：1$$数学公式$$ Typora快捷键：1Ctrl + Shift + M (6)分割线Markdown 语法：12345方法1：---``方法2：+++``方法3：*** (7)列表Markdown语法：12341.有序列表项2. * 无序列表项3. + 无序列表项4. - 无序列表项 Typora快捷键：有序列表项：Ctrl+Shift+[ 有序列表项：Ctrl+Shift+] (8) 表格Markdown语法：12341. 表头1|表头2-|-|-内容11|内容12内容21|内容22 Typora 快捷键：Ctrl+T (9)超链接Markdown语法：1234方法一：[链接文字](链接地址 &quot;链接描述&quot;)例如：[示例链接](https://www.example.com/ &quot;示例链接&quot;)方法二：&lt;链接地址&gt;例如：&lt;https://www.example.com/&gt; Typora快捷键：Ctrl+K (10)图片Markdown语法：12![图片文字](图片地址 &quot;图片描述&quot;)例如：![示例图片](https://www.example.com/example.PNG &quot;示例图片&quot;) Typora快捷键：Ctrl+Shift+I","link":"/AngelNI.github.io/Makedown/"},{"title":"Gobang？","text":"时间带着明显的恶意，缓缓在我的身上流逝 向大家介绍一款游戏，就是五子棋。 什么，五子棋？？？ 没错，就是高大上的五子棋，这是一个基于神经网络用Python写的小游戏五子棋，经过大量的训练，已经很优秀了呢！！！不知道你敢不敢与他战斗啊. Introduce to you a game, that is gobang.What, Gobang???Yes, it’s Gobang in Gaoda. It’s a small game written by Python based on neural network. After a lot of training, it’s already excellent!!! I wonder if you dare to fight him. Github项目地址","link":"/AngelNI.github.io/Gobang？/"},{"title":"My-World","text":"我叫MC~~ 最近喜欢上玩我的世界，有没有一起的。 光影，不敢开，我怕我的显卡被拎去烤鸡蛋，以至于自己搭的和想象中的有点不一样，emmm，就那么一点点点。","link":"/AngelNI.github.io/My-World/"},{"title":"NCF Data Processing","text":"左眼永远见不到右眼，只能陪她一起哭泣。 NCF数据处理是对论文neural_collaborative_filtering作者所提出的神经网络协同过滤源代码的运行结果，不过在源代码的基础上做了一些更改，运行环境是 python3.6，keras1.2.2，tensorflow1.3.0 ，电脑本地运行约7个小时。 数据处理前言 GMF batch_size=256, dataset=’ml-1m’, epochs=100, learner=’adam’, lr=0.001, num_factors=8, num_neg=4, out=1, path=’Data/‘, regs=’[0,0]’, verbose=1 MLP batch_size=256, dataset=’ml-1m’, epochs=100, layers=’[64,32,16,8]’, learner=’adam’, lr=0.001, num_neg=4, out=1, path=’Data/‘, reg_layers=’[0,0,0,0]’, verbose=1 NeuMF batch_size=256, dataset=’ml-1m’, epochs=100, layers=’[64,32,16,8]’, learner=’adam’, lr=0.001, mf_pretrain=’’, mlp_pretrain=’’, num_factors=8, num_neg=4, out=1, path=’Data/‘, reg_layers=’[0,0,0,0]’, reg_mf=0, verbose=1 #user=6040, #item=3706, #train=994169, #test=6040 评估 leave-one-out 命中率（HR） 归一化折扣累积增益（NDCG） 读取数据123456import pandas as pdimport matplotlib.pyplot as plt%matplotlib inlineGMF = pd.read_table('GMF.txt',header=None, encoding='gb2312', sep=',')MLP = pd.read_table('MLP.txt',header=None, encoding='gb2312', sep=',')NeuMF = pd.read_table('NEUMF.txt',header=None, encoding='gb2312', sep=',') 查看数据 获取数据获取HR数据123456789GMF_HR = []MLP_HR = []NeuMF_HR = []for i in GMF[0]: GMF_HR.append(eval(i[-6:]))for i in MLP[0]: MLP_HR.append(eval(i[-6:]))for i in NeuMF[0]: NeuMF_HR.append(eval(i[-6:])) 获取NDGC123456789GMF_NDGC= []MLP_NDGC = []NeuMF_NDGC = []for i in GMF[1]: GMF_NDGC.append(eval(i[-6:]))for i in MLP[1]: MLP_NDGC.append(eval(i[-6:]))for i in NeuMF[1]: NeuMF_NDGC.append(eval(i[-6:])) 获取loss123456789GMF_loss= []MLP_loss = []NeuMF_loss = []for i in GMF[2]: GMF_loss.append(eval(i[-14:-8]))for i in MLP[2]: MLP_loss.append(eval(i[-14:-8]))for i in NeuMF[2]: NeuMF_loss.append(eval(i[-14:-8])) 图表表示HR对比123456789101112131415f=plt.figure(figsize=(12,10))plt.rcParams['font.sans-serif'] = ['SimHei']plt.title(\"GMF-MLP-NeuMF HR 对比图\",fontsize = 20)plt.xlabel(\"Iteration\",fontsize = 20)plt.ylabel(\"HR\",fontsize = 20)plt.plot(range(100),GMF_HR,label = \"GMF\")#,linestyle='--')plt.plot(range(100),MLP_HR,label = \"MLP\")#,linestyle='-.')plt.plot(range(100),NeuMF_HR,label =\"NeuMF\")plt.scatter(98,0.6437,marker='^',color = 'black')plt.scatter(29,0.6763,marker='^',color = 'black')plt.scatter(35,0.6848,marker='^',color = 'black')plt.legend()plt.grid(c=\"w\")plt.show() NDGC 对比1234567891011121314f=plt.figure(figsize=(12,10))plt.rcParams['font.sans-serif'] = ['SimHei']plt.title(\"GMF-MLP-NeuMF NDGC 对比图\",fontsize = 20)plt.xlabel(\"Iteration\",fontsize = 20)plt.ylabel(\"NDGC\",fontsize = 20)plt.plot(range(100),GMF_NDGC,label = \"GMF\")plt.plot(range(100),MLP_NDGC,label = \"MLP\")plt.plot(range(100),NeuMF_NDGC,label =\"NeuMF\")plt.scatter(98,0.3749,marker='^',color = 'black')plt.scatter(29,0.3988,marker='^',color = 'black')plt.scatter(35,0.4095,marker='^',color = 'black')plt.legend()plt.grid(c=\"w\")plt.show() LOSS 对比1234567891011f=plt.figure(figsize=(12,10))plt.rcParams['font.sans-serif'] = ['SimHei']plt.title(\"GMF-MLP-NeuMF loss 对比图\",fontsize = 20)plt.xlabel(\"Iteration\",fontsize = 20)plt.ylabel(\"Loss\",fontsize = 20)plt.plot(range(100),GMF_loss,label = \"GMF\")plt.plot(range(100),MLP_loss,label = \"MLP\")plt.plot(range(100),NeuMF_loss,label =\"NeuMF\")plt.legend()plt.grid(c =\"w\")plt.show()","link":"/AngelNI.github.io/NCF-Data-Processing/"},{"title":"Python command","text":"不是 ,有钱才善良，而是善良才富足。 pip升级pip show pippython -m pip install –upgrade pip 列出已安装的包 pip list pip安装包pip install 安装包名 pip查看是否已安装pip show [–files] 安装包名 pip检查哪些包需要更新pip list –outdated pip升级包pip install –upgrade 要升级的包名 pip卸载包pip uninstall 要卸载的包名 pip搜索包 pip search SomePackage pip参数解释 12345678910111213141516171819202122232425262728293031323334353637383940pip --helpUsage: pip &lt;command&gt; [options]Commands: install Install packages. download Download packages. uninstall Uninstall packages. freeze Output installed packages in requirements format. list List installed packages. show Show information about installed packages. check Verify installed packages have compatible dependencies. config Manage local and global configuration. search Search PyPI for packages. wheel Build wheels from your requirements. hash Compute hashes of package archives. completion A helper command used for command completion. help Show help for commands.General Options: -h, --help Show help. --isolated Run pip in an isolated mode, ignoring environment variables and user configuration. -v, --verbose Give more output. Option is additive, and can be used up to 3 times. -V, --version Show version and exit. -q, --quiet Give less output. Option is additive, and can be used up to 3 times (corresponding to WARNING, ERROR, and CRITICAL logging levels). --log &lt;path&gt; Path to a verbose appending log. --proxy &lt;proxy&gt; Specify a proxy in the form [user:passwd@]proxy.server:port. --retries &lt;retries&gt; Maximum number of retries each connection should attempt (default 5 times). --timeout &lt;sec&gt; Set the socket timeout (default 15 seconds). --exists-action &lt;action&gt; Default action when a path already exists: (s)witch, (i)gnore, (w)ipe, (b)ackup, (a)bort. --trusted-host &lt;hostname&gt; Mark this host as trusted, even though it does not have valid or any HTTPS. --cert &lt;path&gt; Path to alternate CA bundle. --client-cert &lt;path&gt; Path to SSL client certificate, a single file containing the private key and the certificate in PEM format. --cache-dir &lt;dir&gt; Store the cache data in &lt;dir&gt;. --no-cache-dir Disable the cache. --disable-pip-version-check Don&apos;t periodically check PyPI to determine whether a new version of pip is available for download. Implied with --no-index. --no-color Suppress colored output 将pip源更换到国内镜像 123456常用的国内镜像包括：（1）阿里云 http://mirrors.aliyun.com/pypi/simple/（2）豆瓣http://pypi.douban.com/simple/（3）清华大学 https://pypi.tuna.tsinghua.edu.cn/simple/（4）中国科学技术大学 http://pypi.mirrors.ustc.edu.cn/simple/（5）华中科技大学http://pypi.hustunique.com/ (1) 临时使用：可以在使用pip的时候，加上参数-i和镜像地址(如https://pypi.tuna.tsinghua.edu.cn/simple)。例如：pip install -i https://pypi.tuna.tsinghua.edu.cn/simple pandas，这样就会从清华镜像安装pandas库。 (2) 永久修改，一劳永逸： windows下，直接在user目录中创建一个pip目录，如：C:\\Users\\xx\\pip，然后新建文件pip.ini，即 %HOMEPATH%\\pip\\pip.ini，在pip.ini文件中输入以下内容（以豆瓣镜像为例）： 1234[global]index-url = http://pypi.douban.com/simple[install]trusted-host = pypi.douban.com","link":"/AngelNI.github.io/Pip-command/"},{"title":"Network App Recommend","text":"你知道吗，有些人，会以各种你情愿或不情愿的方式，留在你的记忆里，比如我。 Hosting PlatformGithub Gitlab Coding Bitbucket Bitballon 这五个比较常用的托管平台，当然了，这里，Github是全球最大的托管平台，我的博客也是在上面托管。但由于对国内限速，很是难受。其他的四个是我最近发现比较好用的，推荐给大家。 Cloud storageGoole云端硬盘 百度网盘 坚果云 Goole云端硬盘是我比较好用的，能关联许多应用，并且我的Colab的代码在上面，执行代码直接调用就可以了。百度网盘，是我第一个使用储存App，但是在下载上限速，非常_，不过幸好有百度云不限速的破解软件。坚果云，正尝试着去用。至于，其他的云储存，没怎末用过，要是用比较好的，留言推荐给我哦。 Search磁力猫 秘迹搜索 微软bing 鸠摩搜索 除了我们常用的百度谷歌搜狐等搜索引擎外，还有很多好玩的搜索。磁力猫是一个资源搜索引擎，在全网范围内搜索你想要的资源。秘迹搜索，是一个不追踪你位置的良心搜索。微软bing，嗯嗯。鸠摩搜索，是一个搜书的引擎，如果你喜欢看书，可是试试啊。 O JHDU POJ 51 Nod 牛客 洛谷 …… 对于一个计算机爱好者，ACM是最好的检验编程能力的平台，但不是每个人都可以参加ACM比赛的，现在有许多在线的OJ平台来练习你的算法编程能力，有好多，就不一一列举了。","link":"/AngelNI.github.io/Network-App-Recommend/"},{"title":"Poetry Appreciation","text":"I think poetry is a kind of life experience,a kind of inner sublimation.Cultivate sentiment and enrich oneself. 木兰花令——纳兰性德 人生若只如初见，何事秋风悲画扇?等闲变却故人心，却道故人心易变。 骊山语罢清宵半，泪雨零铃终不怨。何如薄幸锦衣郎，比翼连枝当日愿。 仓央嘉措《四》好多年了 你一直在我的伤口中幽居 我放下过天地 却从未放下过你 我生命中的千山万水 任你一一告别 世间事 除了生死 哪一件不是闲事 谁的隐私不被回光返照 殉葬的花朵开合有度 菩提的果实奏响了空山 告诉我 你藏在落叶下的那些脚印 暗示着多少祭日 专供我在法外逍遥 致橡树——舒婷 我如果爱你——绝不像攀援的凌霄花，借你的高枝炫耀自己； 我如果爱你——绝不学痴情的鸟儿，为绿荫重复单调的歌曲； 也不止像泉源，常年送来清凉的慰藉； 也不止像险峰，增加你的高度，衬托你的威仪。甚至日光，甚至春雨。 不，这些都还不够！ 我必须是你近旁的一株木棉，作为树的形象和你站在一起。 根，紧握在地下；叶，相触在云里。 每一阵风过，我们都互相致意，但没有人，听懂我们的言语。 你有你的铜枝铁干，像刀，像剑，也像戟；我有我红硕的花朵，像沉重的叹息，又像英勇的火炬。 我们分担寒潮、风雷、霹雳；我们共享雾霭、流岚、虹霓。 仿佛永远分离，却又终身相依。 这才是伟大的爱情，坚贞就在这里： 爱——不仅爱你伟岸的身躯，也爱你坚持的位置，足下的土地。 一棵开花的树——席慕蓉 如何让你遇见我 在我最美丽的时刻 为这 我已在佛前求了五百年 求佛让我们结一段尘缘 佛於是把我化做一棵树 长在你必经的路旁 阳光下 慎重地开满了花 朵朵都是我前世的盼望 当你走近 请你细听 那颤抖的叶 是我等待的热情 而当你终於无视地走过 在你身後落了一地的 朋友啊 那不是花瓣 那是我凋零的心 热爱生命——汪国真 我不去想是否能够成功 既然选择了远方 便只顾风雨兼程 我不去想能否赢得爱情 既然钟情于玫瑰 就勇敢地吐露真诚 我不去想身后会不会袭来寒风冷雨 既然目标是地平线 留给世界的只能是背影 我不去想未来是平坦还是泥泞 只要热爱生命 一切，都在意料之中","link":"/AngelNI.github.io/Poetry-Appreciation/"},{"title":"Python_Operation on Excel","text":"====This my mood now==== I recently solve the problem of Excel ‘ data , it is hard to process Excel data because of huge amount of it.However, there is a better tool to process–Python.I simply write 34 lines to operation on Excel’s data to count th number of the key word. Just for recording. code12345678910111213141516171819202122232425262728293031323334import xlrdimport xlwtimport reimport numpy as npimport pandas as pd#import openpyxldata = xlrd.open_workbook('C:\\\\Users\\\\hp\\\\Desktop\\\\数据信息3.xlsx')table = data.sheets()[0]ncols = table.col_values(12)a = len(ncols)pattern = re.compile(r'\\d+')d=[]for i in range(1,a): #print(pattern.findall(ncols[i])) # print(\"\\n\") b = len(pattern.findall(ncols[i])) c=[] for j in range(0,b): if eval(pattern.findall(ncols[i])[j] )&lt; 10 : c.append(pattern.findall(ncols[i])[j]) #print(c) d.append(len(c)) #print(d) f = xlwt.Workbook() #创建工作簿sheet1 = f.add_sheet(u'sheet1',cell_overwrite_ok=True) #创建sheetfor i in range(0,len(d)): sheet1.write(i+1,0,d[i])f.save(\"C:\\\\Users\\\\hp\\\\Desktop\\\\2.xls\")print(\"结束\")","link":"/AngelNI.github.io/Python-Operation-on-Excel/"},{"title":"Matrix Factorization For Recommendation System","text":"云是雨的梦，雨是云的前生。 Concept矩阵分解是将矩阵分解为数个矩阵的乘积，用矩阵分解做协同过滤是广泛使用的方法 常见的有三种： 1.三角分解法 2.QR分解法 3.奇异值分解法 Matrix Decomposition Method奇异值分解SVD原始的SVD又名奇异值分解，如果是用户评分矩阵，首先需要对缺失值进行简单的不全，比如用全局平均，然后用SVD进行分解 其中，R为原始的评分矩阵，维度是mn，U和V分贝是一个km和kn的正交矩阵，S为kk的对角矩阵，对角线上的每一个元素都是矩阵的奇异值。这种纯数学的方法计算量特别大，实际应用中的数据根本处理不了。Simon Funk的Funk-SVD方法解决了这个问题，思想很简单：直接通过训练集的观察值利用最小化RMSE学习P、Q矩阵，这就是机器学习的思想了。 SVD++SVD矩阵分解非常成功，有很多的迭代的方法，最有名的就是SVD++了。提SVD++之前，我们先看一个简单的BiasSVD： u 为训练集中所有记录的平均全局数 b_u 为用户的偏置项，表示用户的评分偏好 b_i 为物品的偏置项，表示物品的本身质量 如果将用户历史行为对用户评分预测影响考虑进来就是SVD++算法： SVD++的核心思想是把基于领域的itemCF算法用矩阵分解的方法实现，转换的方法是这样的： Others1.FM 2.隐式反馈矩阵分解 3.基于特征的矩阵分解 MF For Recommendation System对于推荐系统来说存在两大场景即评分预测（rating prediction）与Top-N推荐（item recommendation，item ranking）。评分预测场景主要用于评价网站，比如用户给自己看过的电影评多少分（MovieLens），或者用户给自己看过的书籍评价多少分（Douban）。其中矩阵分解技术主要应用于该场景。Top-N推荐场景主要用于购物网站或者一般拿不到显式评分信息的网站，即通过用户的隐式反馈信息来给用户推荐一个可能感兴趣的列表以供其参考。 有如下R（5，4）的打分矩阵：（“-”表示用户没有打分），其中打分矩阵R（n，m）是n行和m列，n表示user个数，m表示iten个数 那么，如何根据目前的矩阵R（5,4）如何对未打分的商品进行评分的预测（如何得到分值为0的用户的打分值）？ ——矩阵分解的思想可以解决这个问题，其实这种思想可以看作是有监督的机器学习问题（回归问题）。 矩阵R可以近似表示为P与Q的乘积：R（n,m）≈ P(n,K)*Q(K,m) 矩阵分解的过程中，将原始的评分矩阵分解成两个矩阵和的乘积： 矩阵P(n,K)表示n个user和K个特征之间的关系矩阵，这K个特征是一个中间变量，矩阵Q(K,m)的转置是矩阵Q(m,K)，矩阵Q(m,K)表示m个item和K个特征之间的关系矩阵，这里的K值是自己控制的，可以使用交叉验证的方法获得最佳的K值。为了得到近似的R(n,m)，必须求出矩阵P和Q，如何求它们呢？ 步骤 1.首先令 2.损失函数： 使用原始的评分矩阵与重新构建的评分矩阵之间的误差的平方作为损失函数。 如果R（i，j）已知，则R（i，j）的误差平方和为 最终，需要求解所有的非“-”项的损失之和最小值： 3.使用梯度下降法获得修正的p和q分量： 根据梯度方向更新变量 4.不停迭代直至算法最终收敛（直到sum（e^2）&lt;=阈值 加入正则项 1.第一步同上 2.在通常求解过程中，为了能够有较好的泛化能力，会在损失函数中加入正则项对参数进行约束 也就是 3.使用梯度下降法获得修正的p和q 4.不停迭代直至算法最终收敛（直到sum（e^2）&lt;=阈值 【预测】利用上述的过程，我们可以得到矩阵，这样便可以为用户 i 对商品 j 进行打分 代码实现1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859#导包import numpy as npimport matplotlib.pyplot as plt%matplotlib inline#参数设置alph = 0.00049step = 9000beta = 0.05K = 3# MFdef MF(r,p,q,alph,step,beta): result = [] count = 0 while(count&lt;step): count+=1 for i in range(len(r)): for j in range(len(r)): #构建损失函数 if r[i][j]&gt;0: eij = r[i][j] - np.dot(p[i,:],q[:,j]) for k in range(K): pd_p = -2*eij*q[k][j]+beta * p[i][k] pd_q = -2*eij*p[i][k]+beta * q[k][j] p[i][k] -= alph*pd_p q[k][j] -= alph*pd_q e = 0 for i in range(len(r)): for j in range(len(r)): if r[i][j]&gt;0 : eij = r[i][j] - np.dot(p[i,:],q[:,j]) e += eij**2 for n in range(K): e += (beta/2)*(p[i][k]**2+q[k][j]**2) result.append(e) # print(e) return p , q , result #原始矩阵r = [ [1,0,3,0,4], [0,2,1,4,0], [1,0,0,2,3], [2,0,1,0,0], [0,0,2,0,0]]r = np.array(r)print(f\"输入矩阵为\\n{r}\")p = np.random.rand(5,K)q = np.random.rand(K,5)new_p,new_q,result = MF(r,p,q,alph,step,beta)print(f'输出矩阵为\\n{np.dot(new_p,new_q)}' )plt.plot(range(len(result)),result) 最后结果如图","link":"/AngelNI.github.io/MF/"},{"title":"Stanford-Machine-Learning-camp","text":"曾经沧海难为水，却见巫山不是云。 Stanford-Machine-Learning-camp课程资料 课程主页 课程笔记 课程视频 环境配置Anaconda 作业介绍 比赛环境推荐使用Linux或者Mac系统，以下环境搭建方法皆适用: Docker环境配置 本地环境配置 重要一些的资源： Dr.Wu 博客71篇(机器学习、深度学习、强化学习、对抗网络) Dr.Wu 本人知乎 深度学习经典论文 深度学习斯坦福教程 廖雪峰python3教程 github教程 莫烦机器学习教程 深度学习经典论文 机器学习代码修行100天 吴恩达机器学习新书：machine learning yearning 本人博客(机器学习基础算法专题) 本人博客(深度学习专题) 自上而下的学习路线: 软件工程师的机器学习 1. 前言这门课的宗旨就是：*“手把手推导机器学习理论，行对行练习徒手代码过程” *吴恩达在斯坦福的机器学习课，是很多人最初入门机器学习的课，10年有余，目前仍然是最经典的机器学习课程之一。当时因为这门课太火爆，吴恩达不得不弄了个超大的网络课程来授课，结果一不小心从斯坦福火遍全球，而后来的事情大家都知道了。吴恩达这些年，从谷歌大脑项目到创立Coursera再到百度首席科学家再再到最新开设了深度学习deeplearning.ai，辗转多年依然对CS229不离不弃。 个人认为：吴恩达的机器学习课程在机器学习入门的贡献相当于牛顿、莱布尼茨对于微积分的贡献。区别在于，吴恩达影响了10年，牛顿影响了200年。(个人观点) 本课程提供了一个广泛的介绍机器学习、数据挖掘、统计模式识别的课程。主题包括： （一）监督学习（参数/非参数算法，支持向量机，核函数，神经网络）。 （二）无监督学习（聚类，降维，推荐系统，深入学习推荐）。 （三）在机器学习的最佳实践（偏差/方差理论；在机器学习和人工智能创新过程）。本课程还将使用大量的案例研究，您还将学习如何运用学习算法构建智能机器人（感知，控制），文本的理解（Web搜索，反垃圾邮件），计算机视觉，医疗信息，音频，数据挖掘，和其他领域。 本课程相对以前的机器学习视频cs229(2008)，这个视频更加清晰，而且每课都有课件，推荐学习。 2.数学知识复习1.线性代数2.概率论3.凸函数优化4.随机梯度下降算法 中文资料： 机器学习中的数学基本知识 统计学习方法 大学数学课本（从故纸堆里翻出来^_^） 3.编程工具斯坦福资料： Python复习 4. 中文书籍推荐： 《机器学习》周志华 《统计学习方法》李航 《机器学习课》邹博 5. 学习安排本课程需要11周共18节课，每周具体时间划分为4个部分: 1部分安排周一到周二 2部分安排在周四到周五 3部分安排在周日 4部分作业是本周任何时候空余时间 周日晚上提交作业运行截图 周三、周六休息^_^ 6.作业提交指南： 训练营的作业自检系统已经正式上线啦！只需将作业发送到训练营公共邮箱即可，知识星球以打卡为主，不用提交作业。以下为注意事项:&lt;1&gt; 训练营代码公共邮箱：cs229@163.com&lt;2&gt; 查询自己成绩:&lt;3&gt; 将每周作业压缩成zip文件，文件名为“学号+作业编号”，例如：”CS229-010037-01.zip”&lt;4&gt; 注意不要改变作业中的《方法名》《类名》不然会检测失败！！ 7.学习安排week 1学习组队比赛观摩 作业 Week1：:制定自己的学习计划 week 2第一节： 引言(Introduction)课件：lecture1笔记：lecture1-note1视频： 1.1欢迎:Welcome to Machine Learning 1.2机器学习是什么？:Welcome 1.3监督学习:What is Machine Learning 1.4无监督学习:Supervised Learning 第二节： 单变量线性回归(Linear Regression with One Variable)课件：lecture2笔记：lecture2-note2视频： 2.1模型表示:Unsupervised Learning 2.2代价函数:Model Representation 2.3代价函数的直观理解I:Cost Function 2.4代价函数的直观理解II:Cost Function - Intuition I 2.5梯度下降:Cost Function - Intuition II 2.6梯度下降的直观理解:Gradient Descent 2.7梯度下降的线性回归:Gradient Descent Intuition 2.8接下来的内容:GradientDescentForLinearRegression 作业 Week2：:1.环境配置2.开学习博客和github week 3第三节： 线性代数回顾(Linear Algebra Review)课件：lecture3笔记：lecture3-note3视频： 3.1矩阵和向量:Matrices and Vectors 3.2加法和标量乘法:Addition and Scalar Multiplication 3.3矩阵向量乘法:Matrix Vector Multiplication 3.4矩阵乘法:Matrix Matrix Multiplication 3.5矩阵乘法的性质:Matrix Multiplication Properties 3.6逆、转置:Inverse and Transpose 第四节： 多变量线性回归(Linear Regression with Multiple Variables)课件：lecture4笔记：lecture4-note4视频： 4.1多维特征:Multiple Features 4.2多变量梯度下降:Gradient Descent for Multiple Variables 4.3梯度下降法实践1-特征缩放:Gradient Descent in Practice I - Feature Scaling 4.4梯度下降法实践2-学习率:Gradient Descent in Practice II - Learning Rate 4.5特征和多项式回归:Features and Polynomial Regression 4.6正规方程:Normal Equation 4.7正规方程及不可逆性（选修）:Normal Equation Noninvertibility (Optional)作业 Week3：: 作业链接1.线性回归 Linear Regression2.多远线性回归 Linear Regression with multiple variables Week 4第五节：Octave教程(Octave Tutorial 选修)（有Python基础可以忽略）课件：lecture5笔记：lecture5-note5视频： 5.1基本操作:Working on and Submitting Programming Exercises 5.2移动数据:Basic Operations 5.3计算数据:Moving Data Around 5.4绘图数据:Computing on Data 5.5控制语句：for，while，if语句:Plotting Data 5.6向量化88:Control Statements 5.7工作和提交的编程练习:Vectorization 第六节：逻辑回归(Logistic Regression)课件：lecture6笔记：lecture6-note6视频： 6.1分类问题:Classification 6.2假说表示:Hypothesis Representation 6.3判定边界:Decision Boundary 6.4代价函数:Cost Function 6.5简化的成本函数和梯度下降:Simplified Cost Function and Gradient Descent 6.6高级优化:Advanced Optimization 6.7多类别分类：一对多:Multiclass Classification_ One-vs-all 作业 Week4：: 作业链接 逻辑回归 Logistic Regression 带有正则项的逻辑回归 Logistic Regression with Regularization Week 5第七节：正则化(Regularization)课件：lecture7笔记：lecture7-note7视频： 7.1过拟合的问题:The Problem of Overfitting 7.2代价函数:Cost Function 7.3正则化线性回归:Regularized Linear Regression 7.4正则化的逻辑回归模型:Regularized Logistic Regression 第八节：神经网络：表述(Neural Networks: Representation)课件：lecture8笔记：lecture8-note8视频： 8.1非线性假设:Non-linear Hypotheses 8.2神经元和大脑:Neurons and the Brain 8.3模型表示1:Model Representation I 8.4模型表示2:Model Representation II 8.5样本和直观理解1:Examples and Intuitions I 8.6样本和直观理解II:Examples and Intuitions II 8.7多类分类:Multiclass Classification作业 Week5：: 作业链接 多元分类 Multiclass Classification 神经网络预测函数 Neural Networks Prediction fuction Week 6第九节1：神经网络的学习(Neural Networks: Learning1)课件：lecture9笔记：lecture9-note9视频： 9.1代价函数:Cost Function 9.2反向传播算法:Backpropagation Algorithm 9.3反向传播算法的直观理解:Backpropagation Intuition 第九节2：神经网络的学习(Neural Networks: Learning2)课件：lecture9笔记：lecture9-note9视频： 9.4实现注意：展开参数:Implementation Note_ Unrolling Parameters 9.5梯度检验:Gradient Checking 9.6随机初始化:Random Initialization 9.7综合起来:Putting It Together 9.8自主驾驶:Autonomous Driving 作业 Week6：: 作业链接 神经网络实现 Neural Networks Learning Week 7第十节：应用机器学习的建议(Advice for Applying Machine Learning)课件：lecture10笔记：lecture10-note10视频： 10.1决定下一步做什么:Deciding What to Try Next 10.2评估一个假设:Evaluating a Hypothesis 10.3模型选择和交叉验证集:Model Selection and Train_Validation_Test Sets 10.4诊断偏差和方差:Diagnosing Bias vs. Variance 10.5正则化和偏差/方差:Regularization and Bias_Variance 10.6学习曲线:Learning Curves 10.7决定下一步做什么:Deciding What to Do Next Revisited第十一节： 机器学习系统的设计(Machine Learning System Design)课件：lecture11笔记：lecture11-note11视频： 11.1首先要做什么:Prioritizing What to Work On 11.2误差分析:Error Analysis 11.3类偏斜的误差度量:Error Metrics for Skewed Classes 11.4查准率和查全率之间的权衡:Trading Off Precision and Recall 11.5机器学习的数据:Data For Machine Learning作业 Week7：: 作业链接 正则线性回归 Regularized Linear Regression 偏移和方差 Bias vs. Variance Week 8第十二节：支持向量机(Support Vector Machines)课件：lecture12笔记：lecture12-note12视频： 12.1优化目标:Optimization Objective 12.2大边界的直观理解:Large Margin Intuition 12.3数学背后的大边界分类（选修）:Mathematics Behind Large Margin Classification (Optional) 12.4核函数1:Kernels I 12.5核函数2:Kernels II 12.6使用支持向量机:Using An SVM 第十三节：聚类(Clustering)课件：lecture13笔记：lecture13-note13视频： 13.1无监督学习：简介:Unsupervised Learning_ Introduction 13.2K-均值算法:K-Means Algorithm 13.3优化目标:Optimization Objective 13.4随机初始化:Random Initialization 13.5选择聚类数:Choosing the Number of Clusters作业 Week8：: 作业链接 SVM实现 垃圾邮件分类 Spam email Classifier Week 9第十四节：降维(Dimensionality Reduction)课件：lecture14笔记：lecture14-note14视频： 14.1动机一：数据压缩:Motivation I_ Data Compression 14.2动机二：数据可视化:Motivation II_ Visualization 14.3主成分分析问题:Principal Component Analysis Problem Formulation 14.4主成分分析算法:Principal Component Analysis Algorithm 14.5选择主成分的数量:Choosing the Number of Principal Components 14.6重建的压缩表示:Reconstruction from Compressed Representation 14.7主成分分析法的应用建议:Advice for Applying PCA 第十五节：异常检测(Anomaly Detection)课件：lecture15笔记：lecture15-note15视频： 15.1问题的动机:Problem Motivation 15.2高斯分布:Gaussian Distribution 15.3算法:Algorithm 15.4开发和评价一个异常检测系统:Developing and Evaluating an Anomaly Detection System 15.5异常检测与监督学习对比:Anomaly Detection vs. Supervised Learning 15.6选择特征:Choosing What Features to Use 15.7多元高斯分布（选修）:Multivariate Gaussian Distribution (Optional) 15.8使用多元高斯分布进行异常检测（选修）:Anomaly Detection using the Multivariate Gaussian Distribution (Optiona作业 Week9：: 作业链接 K-means 聚类算法 Clustering PCA 主成分析 Principal Component Analysis Week 10第十六节：推荐系统(Recommender Systems)课件：lecture16笔记：lecture16-note16视频： 16.1问题形式化:Problem Formulation 16.2基于内容的推荐系统:Content Based Recommendations 16.3协同过滤:Collaborative Filtering 16.4协同过滤算法:Collaborative Filtering Algorithm 16.5向量化：低秩矩阵分解:Vectorization_ Low Rank Matrix Factorization 16.6推行工作上的细节：均值归一化:Implementational Detail_ Mean Normalization 第十七节：大规模机器学习(Large Scale Machine Learning)课件：lecture17笔记：lecture17-note17)视频： 17.1大型数据集的学习:Learning With Large Datasets 17.2随机梯度下降法:Stochastic Gradient Descent 17.3小批量梯度下降:Mini-Batch Gradient Descent 17.4随机梯度下降收敛:Stochastic Gradient Descent Convergence 17.5在线学习:Online Learning 17.6映射化简和数据并行:Map Reduce and Data Parallelism 作业 Week10：: 作业链接 异常检测 Anomaly Detection Week 11第十八节1： 应用实例：图片文字识别(Application Example: Photo OCR)课件：lecture18笔记：lecture18-note18视频： 18.1问题描述和流程图:Problem Description and Pipeline 18.2滑动窗口:Sliding Windows第十八节2： 应用实例：图片文字识别(Application Example: Photo OCR)课件：lecture18笔记：lecture1-note18)视频： 18.3获取大量数据和人工数据:Getting Lots of Data and Artificial Data 18.4上限分析：哪部分管道的接下去做:Ceiling Analysis_ What Part of the Pipeline to Work on Next 作业 Week11：: 作业链接2.推荐系统实现 Recommender Systems*课程比赛：比赛介绍: * Week 12第十九节：总结(Conclusion)视频：19.1总结和致谢:Summary and Thank You*课程比赛：比赛: * Kaggle 比赛： 泰坦尼克 Titanic","link":"/AngelNI.github.io/Stanford-Machine-Learning-camp/"},{"title":"Ubutu系统文件结构","text":"可能我不是最优秀的，但我在努力做你眼中最棒的。 1.文件系统类型windows中常见的磁盘格式有fat16、fat32和ntfs。windows是一个封闭的系统。无法打开ext3或者mac 日志式。 在ubuntu中其文件系统广泛使用ext3(ext4是ext3的扩展)的文件格式，从而实现了将整个硬盘的写入动作完整的记录在磁盘的某个区域上。而且在ubuntu中可以实现主动挂载windows的文件系统，并以只读的方式访问磁盘中windows系统上的文件。 在ubuntu中磁盘文件系统、网络文件系统都可以非常方便的使用，而屏蔽了网络和本地之间的差异。在ubuntu中所有的文件都是基于目录的方式存储的。一切都是目录，一切都是文件。 2.文件系统结构/是一切目录的起点，如大树的主干。其它的所有目录都是基于树干的枝条或者枝叶。在ubuntu中硬件设备如光驱、软驱、usb设备都将挂载到这颗繁茂的枝干之下，作为文件来管理。 /bin: bin是Binary的缩写。存放系统中最常用的可执行文件（二进制）。 /boot: 这里存放的是linux内核和系统启动文件，包括Grub、lilo启动器程序。 /dev: dev是Device(设备)的缩写。该目录存放的是Linux的外部设备，如硬盘、分区、键盘、鼠标、usb等。 /etc: 这个目录用来存放所有的系统管理所需要的配置文件和子目录，如passwd、hostname等。 /home: 用户的主目录，在Linux中，每个用户都有一个自己的目录，一般该目录名是以用户的账号命名的。 /lib: 存放共享的库文件，包含许多被/bin和/sbin中程序使用的库文件。 /lost+found: 这个目录一般情况下是空的，当系统非法关机后，这里就存放了一些零散文件。 /media: ubuntu系统自动挂载的光驱、usb设备，存放临时读入的文件。 /mnt: 作为被挂载的文件系统得挂载点。 /opt: 作为可选文件和程序的存放目录，主要被第三方开发者用来简易安装和卸载他们的软件。 /proc: 这个目录是一个虚拟的目录，它是系统内存的映射，我们可以通过直接访问这个目录来获取系统信息。这里存放所有标志为文件的进程，比较cpuinfo存放cpu当前工作状态的数据。 /root: 该目录为系统管理员，也称作超级权限者的用户主目录。 /sbin: s就是Super User的意思，这里存放的是系统管理员使用的系统管理程序，如系统管理、目录查询等关键命令文件。 / srv: 存放系统所提供的服务数据。 /sys: 系统设备和文件层次结构，并向用户程序提供详细的内核数据信息。 /tmp: 这个目录是用来存放一些临时文件的，所有用户对此目录都有读写权限。 /usr: 存放与系统用户有关的文件和目录。 /usr /usr 目录具体来说： /usr/X11R6: 存放X-Windows的目录； /usr/games: 存放着XteamLinux自带的小游戏； /usr/bin: 用户和管理员的标准命令； /usr/sbin: 存放root超级用户使用的管理程序； /usr/doc: Linux技术文档； /usr/include: 用来存放Linux下开发和编译应用程序所需要的头文件，for c 或者c++； /usr/lib: 应用程序和程序包的连接库； /usr/local: 系统管理员安装的应用程序目录； /usr/man: 帮助文档所在的目录； /usr/src: Linux开放的源代码； /var: /var: 长度可变的文件，尤其是些记录数据，如日志文件和打印机文件。 /var/cache: 应用程序缓存目录； /var/crash: 系统错误信息； /var/games: 游戏数据； /var/log: 日志文件； /var/mail: 电子邮件； /var/tmp: 临时文件目录； 注: ubuntu严格区分大小写和空格，所以Sun和sun是两个不同的文件。 3.推荐一个好用的工具，查看文件的树状目录结构，而且不同类型的文件夹和文件都用不同的颜色标记： sudo apt-get install tree 好东西啊，多美的名字，就叫tree，哈哈，安装好了之后，只要从命令行执行tree命令就可以了： 效果很好： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980dr@dr-Vostro-270:~/workspace/HandlerTest$ tree.├── AndroidManifest.xml├── assets├── bin│ ├── AndroidManifest.xml│ ├── classes│ │ └── com│ │ └── example│ │ └── handlertest│ │ ├── BuildConfig.class│ │ ├── MainActivity$1.class│ │ ├── MainActivity$2.class│ │ ├── MainActivity.class│ │ ├── MainActivity$MyHandler.class│ │ ├── R$attr.class│ │ ├── R.class│ │ ├── R$dimen.class│ │ ├── R$drawable.class│ │ ├── R$id.class│ │ ├── R$layout.class│ │ ├── R$menu.class│ │ ├── R$string.class│ │ └── R$style.class│ ├── classes.dex│ ├── dexedLibs│ │ └── android-support-v4-2ab8acc90e083e9b9a1d83a94491612c.jar│ ├── HandlerTest.apk│ ├── res│ │ ├── drawable-hdpi│ │ │ └── ic_launcher.png│ │ ├── drawable-mdpi│ │ │ └── ic_launcher.png│ │ ├── drawable-xhdpi│ │ │ └── ic_launcher.png│ │ └── drawable-xxhdpi│ │ └── ic_launcher.png│ └── resources.ap_├── gen│ └── com│ └── example│ └── handlertest│ ├── BuildConfig.java│ └── R.java├── ic_launcher-web.png├── libs│ └── android-support-v4.jar├── proguard-project.txt├── project.properties├── res│ ├── drawable-hdpi│ │ └── ic_launcher.png│ ├── drawable-ldpi│ ├── drawable-mdpi│ │ └── ic_launcher.png│ ├── drawable-xhdpi│ │ └── ic_launcher.png│ ├── drawable-xxhdpi│ │ └── ic_launcher.png│ ├── layout│ │ └── activity_main.xml│ ├── menu│ │ └── main.xml│ ├── values│ │ ├── dimens.xml│ │ ├── strings.xml│ │ └── styles.xml│ ├── values-sw600dp│ │ └── dimens.xml│ ├── values-sw720dp-land│ │ └── dimens.xml│ ├── values-v11│ │ └── styles.xml│ └── values-v14│ └── styles.xml└── src └── com └── example └── handlertest └── MainActivity.java","link":"/AngelNI.github.io/Ubutu系统文件结构/"},{"title":"双栈实现计算器","text":"愿我们能与最好的自己相遇。 双栈实现计算器123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140#include&lt;iostream&gt;#include&lt;stack&gt;#include&lt;cstring&gt;using namespace std;stack&lt;int&gt; OPND;stack&lt;char&gt; OPRT;int precede(char x);void operate();int calculate(string s);int main(){ string str; printf(\"\\t\\t--------------------------------------------\\n\"); printf(\"\\t\\t--------------双栈实现简易计算器------------\\n\"); printf(\"\\t\\t------------------欢迎您使用----------------\\n\"); printf(\"\\t\\t| 计算器 |\\n\"); printf(\"\\t\\t| ---------------- |\\n\"); printf(\"\\t\\t| | | |\\n\"); printf(\"\\t\\t| ---------------- |\\n\"); printf(\"\\t\\t| 1 2 3 + |\\n\"); printf(\"\\t\\t| 4 5 6 - |\\n\"); printf(\"\\t\\t| 7 8 9 * |\\n\"); printf(\"\\t\\t| 0 （ ） / |\\n\"); printf(\"\\t\\t--------------------------------------------\\n\"); printf(\"\\t\\t 请输入一个用#开头和结尾的表达式：\\n\"); cin&gt;&gt;str; calculate(str); getchar(); getchar(); return 0;}//运算符优先级判断 int precede(char x){ if (x == '+' || x == '-') return 0; else if (x == '*' || x == '/') return 1; else if (x == '(' || x == ')') return -1; else if (x == '#') return -2; }//二元运算 inline void operate(char top) { int a = OPND.top(); OPND.pop(); int b = OPND.top(); OPND.pop(); int c; if (top == '+') { b += a; OPND.push(b); } else if (top == '-') { b -= a; OPND.push(b); } else if (top == '*') { b *= a; OPND.push(b); } else if (top == '/') { b /= a; OPND.push(b); } }//读取表达式 int calculate(string s){ int a,b; char top; for(int i = 0;i&lt;s.size();++i) { //判断是否为数字 if(isdigit(s[i])) { int num = 0; string number; number += s[i]; while(isdigit(s[++i])) { number += s[i]; } for( int j=0;j&lt;number.size();j++) { num = num*10 +number[j] - 48; } OPND.push(num); number.clear(); } //对操作符的操作 if(!isdigit(s[i])) { if(OPRT.empty()) { OPRT.push(s[i]); } else { top = OPRT.top(); if(precede(s[i])&gt;precede(top) || s[i] == '(') { OPRT.push(s[i]); } else { while(precede(s[i])&lt;=precede(top)) { if(top=='#'&amp;&amp;s[i]=='#') { OPRT.pop(); int ans = OPND.top(); cout&lt;&lt;\"The answer is :\"&lt;&lt;ans&lt;&lt;endl; OPND.pop(); return 0; } else if(top=='('&amp;&amp;s[i]==')') { ++i; } else { operate(top); } OPRT.pop(); top = OPRT.top(); } OPRT.push(s[i]); } } } }}","link":"/AngelNI.github.io/data-structure/"},{"title":"WordCloud——A Beautiful Cloud of Words","text":"I miss you。 词云图 Word nephogramWordcloud 是Python第三方库中用于制作简单分词云图的第三方库，可以根据自己喜欢的颜色，喜欢的形状制作出美丽的词云图。 所谓的词云图，也叫文字云，是对文本中出现频率较高的“关键词”予以视觉化的展现，词云图过滤掉大量的低频低质的文本信息，使得浏览者只要一眼扫过文本就可领略文本的主旨。可以在每次的报告中迅速的找到核心词汇，掌握接下来发展的目的，方向。 实现快速生成词云图建立一个file.txt的文本文件，把你要统计的文章保存的这个文件中，运行如下的代码就可以看到词云图啦 1234567891011121314from os import pathfrom wordcloud import WordCloudimport matplotlib.pyplot as plt# Read the whole text.text = open('file.txt').read()# Generate a word cloud imagewordcloud = WordCloud().generate(text)# Display the generated image:# the matplotlib way:plt.imshow(wordcloud, interpolation='bilinear')plt.axis(\"off\") 效果如图 自定义形状上面的词云图又丑有难看对不对，不要着急，这里可以自定义词云图的形状，自定义颜色。 在这里我的图片是一张心形 12345678910111213141516171819202122from os import pathfrom PIL import Imageimport numpy as npfrom wordcloud import WordCloudimport matplotlib.pyplot as pltd=path.dirname('E:\\\\study\\\\jupyter notebook')text=open(path.join(d,\"constitution.txt\")).read()alice_mask = np.array(Image.open(path.join(d, \"2.jpg\")))wordcloud=WordCloud(background_color=\"white\",max_words=2000,mask=alice_mask)wordcloud.generate(text)wordcloud.to_file(path.join(d,\"3.jpg\"))# 步骤4-1：创建一个图表画布plt.figure(10)# 步骤4-2：设置图片plt.imshow(wordcloud, interpolation=\"bilinear\")# 步骤4-3：取消图表x、y轴plt.axis(\"off\")# 显示图片plt.show() 是不是很有趣呀！ 还有很多有趣的东西等你发现呢","link":"/AngelNI.github.io/WordCloud——美丽的词云图/"},{"title":"Link list achieve Phone_Contacts","text":"你是我听过最美的童话。 最近，数据结构可上学习了链表线性表，并且用线性表实现了简单的手机通讯录，并用C语言和python语言都实现了，基本理论是一样的，贵在实践。记录一下~ Pyhthon 实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191class Node(): def __init__(self,name,old,telephone,email): self.name = name self.old = old self.telephone = telephone self.email = email self.next = Noneclass phone_list(): def __init__(self): self.head = Node(None,None,None,None) self.len = 0 ## 新建初始化 ## def new_(self): a = input(\"请输入姓名：\") while(len(a) &gt; 4): print(\"输入错误！请重新输入（姓名长度不得超过4）。\") a = input(\"请输入姓名：\") b = input(\"请输入年龄：\") while(1): if int(b)&gt;=1 and int(b)&lt;=100: break print(\"输入错误！请重新输入（年龄范围：1~100）。\") b = eval(input(\"请输入年龄：\")) c = input(\"请输入电话：\") while(len(c) != 11): print(\"输入错误！请重新输入:\") c = input(\"请输入电话：\") d = str(input(\"请输入邮箱：\")) while (1): flag = 0 for i in range(len(d)): if (d[-4:] ==\".com\") and (d[i] ==\"@\"): if d[i+1] != '.': flag = 1 if flag==1: break print(\"输入错误！请检查邮箱格式是否正确。\") d = input(\"请输入邮箱：\") return a,b,c,d def creat_people(self): p =self.head while 1: a,b,c,d= self.new_() new_peo = Node(a,b,c,d) self.len+=1 p.next = new_peo p = p.next b = eval(input(\"是否继续添加？\\n[1] 是[2] 否\\n\\n\")) if(b==1): continue elif(b==2): break ## 遍历 ## def scan_people(self): if (self.len==0): print(\"空无一人\") return p = self.head while(p.next): print(f\"姓名：{p.next.name},年龄：{p.next.old},电话：{p.next.telephone},邮件：{p.next.email}\") p = p.next ## 尾插法 插入新的节点 ## def new_people(self): p = self.head while(p.next): p = p.next a,b,c,d = self.new_() n_1 = Node(a,b,c,d) self.len+=1 p.next = n_1 p = p.next def find_people(self): if (self.len==0): print(\"空无一人\") return a = input(\"请输入你要查询人的名字：\") p = self.head while (p.next): if(p.next.name==a): break else: p = p.next print(\"已找到！！!\\n信息如下：\\n\") print(f\"姓名：{p.next.name},年龄：{p.next.old},电话：{p.next.telephone},邮箱：{p.next.email}\") def fix_people(self): if self.len ==0: print(\"空无一人\") return a = input(\"请输入你要修改人的名字：\") p = self.head while (p.next): if(p.next.name==a): break else: p = p.next b = eval(input(\"请输入您要修改选项\\n[1]姓名[2]年龄[3]电话[4]邮箱\\n\")) if(b==1): new_name = input(\"请输入修改后的姓名\\n\") p.next.name = new_name elif(b==2): new_old = input(\"请输入修改后的年龄\\n\") while(1): if int(new_old)&gt;=1 and int(new_old)&lt;=100: break print(\"输入错误！请重新输入（年龄范围：1~100）。\") new_old = eval(input(\"请重新输入年龄：\")) p.next.old = new_old elif(b==3): new_tele = input(\"请输入电话：\") while(len(new_tele) != 11): print(\"输入错误！请重新输入:\") new_tele = input(\"请输入电话：\") p.next.old = new_tele elif(b==4): new_email = str(input(\"请输入邮箱：\")) while (1): flag = 0 for i in range(len(d)): if (bew_email[-4:] ==\".com\") and (new_email[i] ==\"@\"): if d[i+1] != '.': flag = 1 if flag==1: break print(\"输入错误！请检查邮箱格式是否正确。\") new_email = input(\"请输入邮箱：\") p.next.old = new_email def del_people(self): if self.len == 0: print(\"空无一人\") return a = input(\"请输入您要删除人的姓名：\") if(self.head.name == a): self.head = self.head.next self.len-=1 p = self.head while(p.next): if(p.next.name == a): p.next = p.next.next self.len-=1 break else: p = p.next if(p.name == a): p=None self.len-=1 def length(self): print(f\"此通讯录共有{self.len}人\")def main(): PC = phone_list() while True : print(\"\\n\\n\") print('\\t\\t\\tHPU计算机18实验班通讯录管理程序') print('\\t\\t\\t*\\t python 类（ 链表）实现\\t *') print(\"\\t\\t\\t*\\t\\t\\t *\") print(\"\\t\\t\\t*\\t功能查询：\\t *\") print(\"\\t\\t\\t*\\t[1]：新建初始化\\t *\") print(\"\\t\\t\\t*\\t[2]：新建\\t *\") print(\"\\t\\t\\t*\\t[3]：查询\\t *\") print(\"\\t\\t\\t*\\t[4]：删除\\t *\") print(\"\\t\\t\\t*\\t[5]：显示组员\\t *\") print(\"\\t\\t\\t*\\t[6]：修改信息\\t *\") print(\"\\t\\t\\t*\\t[0]：退出\\t *\") print(\"\\t\\t\\t*** \\t\\t ***\") a =(input(\"请输入您的选择：\")) if a.isdigit(): a = int(a) if(a&gt;=0 and a&lt;=6): if (a==0): print(\"谢谢您的使用！！！\") break if (a==1): PC.creat_people() if (a==2): PC.new_people() if (a==3): PC.find_people() if (a==4): PC.del_people() if (a==5): PC.scan_people() if (a==6): PC.fix_people() x=eval(input(\"是否继续？\\n【1】继续【2】退出\")) if x == 1 : continue if x==2 : breakmain() C 语言实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402#include&lt;stdio.h&gt;#include&lt;stdlib.h&gt;#include&lt;string.h&gt;typedef struct stu_link{ int id; char name[10]; int age; char telephone[20]; char email[20]; int len; struct stu_link *next,*pre;}stu;//定义结构体内变量 stu *head,*tail,*head_1,*tail_1,*head_2,*tail_2;//定义3个链表的头指针和尾指针 stu * creat_stu(stu *tail)//新建联系人 { stu *p; p = (stu *)calloc(sizeof(stu),1); printf(\"请输入姓名:\\n\"); getchar(); gets(p-&gt;name); while(strlen(p-&gt;name)&gt;8) { printf(\"输入错误！\\n请重新输入(名字长度小于等于4):\"); gets(p-&gt;name); } printf(\"请输入年龄：\\n\"); scanf(\"%d\",&amp;p-&gt;age); while(p-&gt;age&gt;100||p-&gt;age&lt;1) { printf(\"输入错误！\\n请重新输入(1-100): \"); scanf(\"%d\",&amp;p-&gt;age); } printf(\"\\n电话号码：\"); getchar(); gets(p-&gt;telephone); while(strlen(p-&gt;telephone)!=11) { printf(\"输入错误！\\n请重新输入:\"); gets(p-&gt;telephone); } printf(\"\\n电子邮箱：\"); getchar(); gets(p-&gt;email); int i=0; while(1) { int flag = 0; int len; for( i=0;i&lt;20;i++) { len = strlen(p-&gt;email); if(p-&gt;email[i]=='@'&amp;&amp;p-&gt;email[len-1]=='m'&amp;&amp;p-&gt;email[len-2]=='o'&amp;&amp;p-&gt;email[len-3]=='c'&amp;&amp;p-&gt;email[len-4]=='.'&amp;&amp;p-&gt;email[len-5]!='@') flag=1; } if(flag==1) break; printf(\"输入错误!\\n请重新输入:\"); gets(p-&gt;email); } tail-&gt;next = p; tail = p; return tail;}stu * find_stu(stu *head,stu *tail,char a[10])//查找联系人并打印信息 { stu *p; p = head; if(strcmp(tail-&gt;name,a)==0) return tail; int flag=0; while(p-&gt;next != tail) { if(strcmp(p-&gt;name,a)==0) { flag = 1; return p; } else p = p-&gt;next; } if(!flag) return NULL; } void scan_stu(stu *head,stu *tail)//浏览联系人信息 { stu *p; p = head-&gt;next; while(p != tail) { printf(\"姓名: %s 年龄: %d 电话：%s 邮箱：%s\\n\",p-&gt;name,p-&gt;age,p-&gt;telephone,p-&gt;email); p = p-&gt;next; } printf(\"姓名:%s 年龄: %d 电话：%s 邮箱：%s\\n\",tail-&gt;name,tail-&gt;age,tail-&gt;telephone,p-&gt;email);}stu * del_stu(stu *head,stu *tail)//删除指定联系人 { stu *p,*q; p = head-&gt;next; printf(\"请输入要删除人的姓名\\n\"); char a[10]; scanf(\"%s\",&amp;a); if(strcmp(p-&gt;name,a)==0) { head-&gt;next = p-&gt;next; head-&gt;len--; } else if(strcmp(tail-&gt;name,a)==0) { while(p-&gt;next != tail) p = p-&gt;next; tail = p; free(tail-&gt;next); head-&gt;len--; return tail; } else { while(p!=tail) { if(strcmp(p-&gt;name,a)==0) break; p = p-&gt;next; } q =p-&gt;next; p-&gt;next = p-&gt;next-&gt;next; head-&gt;len--; free(q); } return tail;}void fix_stu(stu *head,stu *tail)//修改联系人信息 { char a[10],aa[10],telephone1[20],email1[20]; int old; stu *p; printf(\"请输入要修改的姓名：\\n\"); scanf(\"%s\",&amp;a); p = find_stu(head,tail,a); printf(\"请输入要修改的信息\\n[1]：姓名[2]：年龄[3]：电话[4]：邮箱\\n\"); int choice; scanf(\"%d\",&amp;choice); switch(choice) { case 1:{ printf(\"请输入修改后的姓名：\\n\"); getchar(); gets(aa); while(strlen(aa)&gt;8) { printf(\"输入错误！\\n请重新输入(名字长度小于等于4):\"); gets(aa); } strcpy(p-&gt;name,aa); break; } case 2:{ printf(\"请输入修改后的年龄：\\n\"); scanf(\"%d\",&amp;old); while(old&gt;100||old&lt;1) { printf(\"输入错误！\\n请重新输入(1-100): \"); scanf(\"%d\",&amp;old); } p-&gt;age = old; break; } case 3:{ printf(\"请输入修改后的电话：\\n\"); getchar(); gets(telephone1); while(strlen(telephone1)!=11) { printf(\"输入错误！\\n请重新输入:\"); gets(telephone1); } strcpy(p-&gt;telephone,telephone1); break; } case 4:{ printf(\"请输入修改后的邮箱：\\n\"); getchar(); gets(email1); int i=0; while(1) { int flag = 0; int len; for( i=0;i&lt;20;i++) { len = strlen(email1); if(email1[i]=='@'&amp;&amp;email1[len-1]=='m'&amp;&amp;email1[len-2]=='o'&amp;&amp;email1[len-3]=='c'&amp;&amp;email1[len-4]=='.'&amp;&amp;email1[len-5]!='@') flag=1; } if(flag==1) break; printf(\"输入错误!\\n请重新输入:\"); gets(email1); } strcpy(p-&gt;email,email1); break; } } printf(\"修改成功！！！\\n\"); }int main(){ stu *head,*tail,*s,*head_1,*tail_1,*head_2,*tail_2; head = (stu *)calloc(sizeof(stu),1); head-&gt;len=0; tail = head; head_1 = (stu *)calloc(sizeof(stu),1); head_1-&gt;len=0; tail_1 = head_1; head_2 = (stu *)calloc(sizeof(stu),1); head_2-&gt;len=0; tail_2 = head_2; int choice; while(1) { system(\"cls\"); printf(\"\\n\\n\\n\"); printf(\"\\t\\t\\t\\t\\t*****HPU计算机18实验班通讯录管理程序*****\\n\"); printf(\"\\t\\t\\t\\t\\t+\\t***C语言单向链表实现***\\t\\t+\\n\"); printf(\"\\t\\t\\t\\t\\t+\\t\\t\\t\\t\\t+\\n\"); printf(\"\\t\\t\\t\\t\\t+\\t\\t\\t\\t\\t+\\n\\t\\t\\t\\t\\t*\\t 功能列表:\\t\\t\\t+\\n\"); printf(\"\\t\\t\\t\\t\\t+\\t==========================\\t+\\n\"); printf(\"\\t\\t\\t\\t\\t+\\t\\t[1]:\\t新建\\t\\t+\\n\"); printf(\"\\t\\t\\t\\t\\t+\\t\\t[2]:\\t查询\\t\\t+\\n\"); printf(\"\\t\\t\\t\\t\\t+\\t\\t[3]:\\t删除\\t\\t+\\n\"); printf(\"\\t\\t\\t\\t\\t+\\t\\t[4]:\\t显示组员\\t+\\n\"); printf(\"\\t\\t\\t\\t\\t+\\t\\t[5]:\\t修改信息\\t+\\n\"); printf(\"\\t\\t\\t\\t\\t+\\t\\t[6]:\\t总人数\\t\\t+\\n\"); printf(\"\\t\\t\\t\\t\\t+\\t\\t[0]:\\t退出\\t\\t+\\n\"); printf(\"\\t\\t\\t\\t\\t+++\\t========================== +++\\n\"); printf(\"\\n选择你要的功能：\\n\"); scanf(\"%d\",&amp;choice); if(choice==0) { printf(\"谢谢您的使用！！！\\n\"); break; } switch(choice) { case 1: { int choice1; printf(\"是否进行分组?\\n[1]：分组[2]：不分组\\n\"); scanf(\"%d\",&amp;choice1); switch(choice1) { case 1:{ int choice2; printf(\"请选择分组：\\n[1]：家人[2]：朋友\\n\"); scanf(\"%d\",&amp;choice2); switch(choice2) { case 1:{ tail_1 = creat_stu(tail_1); head_1-&gt;len++; break; } case 2:{ tail_2 = creat_stu(tail_2); head_2-&gt;len++; break; } } break; } case 2:{ tail = creat_stu(tail); head-&gt;len++; break; } } break; } case 2: { if(head-&gt;len==0&amp;&amp;head_1-&gt;len==0&amp;&amp;head_2-&gt;len==0) { printf(\"空无一人\\n\"); break; } char a[10]; int b; printf(\"请输入要查找人的名字\\n\"); scanf(\"%s\",&amp;a); printf(\"请选择您要查找的人位于哪个分组：\\n[1]：家人[2]：朋友[3]：未分组\"); scanf(\"%d\",&amp;b); if(b==1) { s = find_stu(head_1,tail_1,a); } else if(b==2) { s = find_stu(head_2,tail_2,a); } else if(b==3) { s = find_stu(head,tail,a); } //s = find_stu(head,tail,a); if(s != NULL) printf(\"姓名：%s 年龄：%d 电话：%s 邮箱：%s\\n\",s-&gt;name,s-&gt;age,s-&gt;telephone,s-&gt;email); else if(s==NULL) printf(\"没有此人！\\n\"); break; } case 3: { if(head-&gt;len==0&amp;&amp;head_1-&gt;len==0&amp;&amp;head_2-&gt;len==0) { printf(\"空无一人\\n\"); break; } if(head-&gt;len==0) printf(\"未分组空无一人\\n\"); else if(head_1==0) printf(\"家人分组空无一人\\n\"); else if(head_2==0) printf(\"朋友分组空无一人\\n\"); int b; printf(\"请选择您要删除的人位于哪个分组：\\n[1]：家人[2]：朋友[3]：未分组\"); scanf(\"%d\",&amp;b); if(b==1) { del_stu(head_1,tail_1); head_1--; } else if(b==2) { del_stu(head_2,tail_2); head_2--; } else if(b==3) { del_stu(head,tail); head--; } break; } case 4:{ if(head-&gt;len==0&amp;&amp;head_1-&gt;len==0&amp;&amp;head_2-&gt;len==0) { printf(\"空无一人\\n\"); break; } if(head-&gt;len==0) printf(\"未分组空无一人\\n\"); else if(head_1==0) printf(\"家人分组空无一人\\n\"); else if(head_2==0) printf(\"朋友分组空无一人\\n\"); if(head-&gt;len!=0) scan_stu(head,tail); if(head_1-&gt;len!=0) scan_stu(head_1,tail_1); if(head_2-&gt;len!=0) scan_stu(head_2,tail_2); break; } case 5:{ if(head-&gt;len==0&amp;&amp;head_1-&gt;len==0&amp;&amp;head_2-&gt;len==0) { printf(\"空无一人\\n\"); break; } if(head-&gt;len==0) printf(\"未分组空无一人\\n\"); else if(head_1==0) printf(\"家人分组空无一人\\n\"); else if(head_2==0) printf(\"朋友分组空无一人\\n\"); int b; printf(\"请选择您要查找的人位于哪个分组：\\n[1]：家人[2]：朋友[3]：未分组\\n\"); scanf(\"%d\",&amp;b); if(b==1) fix_stu(head_1,tail_1); else if(b==2) fix_stu(head_2,tail_2); else if(b==3) fix_stu(head,tail); break; } case 6:{ printf(\"此通讯录共有%d人\\n\",head-&gt;len+head_2-&gt;len+head_1-&gt;len); break; } } printf(\"ENTER键继续（可能不止两次优~~）\"); getchar(); getchar(); } return 0; } 路漫漫其修远兮，代码还要一行一行敲！？！","link":"/AngelNI.github.io/datastruct-1/"},{"title":"python实现汉诺塔移动可视化","text":"想来一趟说走就走的旅行，没有手机，没有联系方式，独身一人，目标——你在的地方。 之前老师在课堂上展示了用C实现汉诺塔的可视化移动过程，觉得挺好玩的，下面就让你看看Python是如何实现的，放图。 好了，下面就是实现的代码了。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869import turtle class Stack: def __init__(self): self.items = [] def isEmpty(self): return len(self.items) == 0 def push(self, item): self.items.append(item) def pop(self): return self.items.pop() def peek(self): if not self.isEmpty(): return self.items[len(self.items) - 1] def size(self): return len(self.items)def drawpole_3():#画出汉诺塔的poles t = turtle.Turtle() t.hideturtle() def drawpole_1(k): t.up() t.pensize(10) t.speed(100) t.goto(400*(k-1), 100) t.down() t.goto(400*(k-1), -100) t.goto(400*(k-1)-20, -100) t.goto(400*(k-1)+20, -100) drawpole_1(0)#画出汉诺塔的poles[0] drawpole_1(1)#画出汉诺塔的poles[1] drawpole_1(2)#画出汉诺塔的poles[2]def creat_plates(n):#制造n个盘子 plates=[turtle.Turtle() for i in range(n)] for i in range(n): plates[i].up() plates[i].hideturtle() plates[i].shape(\"square\") plates[i].color(\"blue\") plates[i].shapesize(1,8-i) plates[i].goto(-400,-90+20*i) plates[i].showturtle() return plates def pole_stack():#制造poles的栈 poles=[Stack() for i in range(3)] return poles def moveDisk(plates,poles,fp,tp):#把poles[fp]顶端的盘子plates[mov]从poles[fp]移到poles[tp] mov=poles[fp].peek() plates[mov].goto((fp-1)*400,150) plates[mov].goto((tp-1)*400,150) l=poles[tp].size()#确定移动到底部的高度（恰好放在原来最上面的盘子上面） plates[mov].goto((tp-1)*400,-90+20*l)def moveTower(plates,poles,height,fromPole, toPole, withPole):#递归放盘子 if height &gt;= 1: moveTower(plates,poles,height-1,fromPole,withPole,toPole) moveDisk(plates,poles,fromPole,toPole) poles[toPole].push(poles[fromPole].pop()) moveTower(plates,poles,height-1,withPole,toPole,fromPole)myscreen=turtle.Screen()drawpole_3()n=int(input(\"请输入汉诺塔的层数并回车:\\n\"))plates=creat_plates(n)poles=pole_stack()for i in range(n): poles[0].push(i)moveTower(plates,poles,n,0,2,1)myscreen.exitonclick() 就是这样，因为对玩感兴趣，就去实现，明明很简单的目标，你却发现你创造了整个世界。","link":"/AngelNI.github.io/hanoi/"},{"title":"jsDelivr+Github建立免费CDN","text":"我喜欢你。 1.CDNCDN的全称是Content Delivery Network，即内容分发网络。CDN是构建在网络之上的内容分发网络，依靠部署在各地的边缘服务器，通过中心平台的负载均衡、内容分发、调度等功能模块，使用户就近获取所需内容，降低网络拥塞，提高用户访问响应速度和命中率。CDN的关键技术主要有内容存储和分发技术。——百度百科 放在Github的资源在国内加载速度比较慢，因此需要使用CDN加速来优化网站打开速度，jsDelivr + Github便是免费且好用的CDN，非常适合博客网站使用。 2.步骤方法1.新建github仓库 2.克隆Github仓库到本地点击 Clone or download，一键复制仓库地址 3.上传资源可参考这边博客https://angelni.github.io/AngelNI.github.io/untitled/ 4.发布仓库 自定义发布版本号 5、通过jsDelivr引用资源使用方法：https://cdn.jsdelivr.net/gh/你的用户名/你的仓库名@发布的版本号/文件路径 希望这篇博客对您有帮助~","link":"/AngelNI.github.io/jsDelivr-Github/"},{"title":"hexo+github","text":"博客搭建(自己总结)之前自己搭建博客，可以说废了很大的劲，这里总结了一下各位大佬们搭建博客的方法，供大家借鉴。 1.安装所需软件1.git安装Windows系统下安装git 可以直接到官网下载安装点击这里 由于访问的是外网，下载速度可能会慢（也可能非常慢） 下面提供百度云的下载地址 64-bit Git for Windows Setup : https://npm.taobao.org/mirrors/git-for-windows/v2.21.0.windows.1/Git-2.21.0-64-bit.exe 2.Node.js安装可以直接到官网下载安装点击这里 百度网盘资源： https://pan.baidu.com/s/1hKVcYfPorRX89hl7D4R1eA 提取码：wsti 下载完成后，安装时一定要点击 Add to PATH 安装完成后，打开cmd，输入 node -v 测试安装是否成功 下面来解决npm卡顿问题 1.打开cmd，换成阿里源 11.npm config set registry https://registry.npm.taobao.org 2.验证命令 12.npm config get registry //返回https://registry.npm.taobao.org，说明镜像配置成功 3.安装cnpm 13.npm install -g cnpm --registry=https://registry.npm.taobao.org 3.hexo安装打开git目录下的git-bash.exe，输入下面代码 npm install -g hexo-cli 安装hexo完成后执行下列命令 123hexo init &lt;文件夹名&gt; cd &lt;文件夹名&gt;npm install hexo 理论上安装在git文件夹下 4.在github上注册账号并同时建立仓库gitHub是一个面向开源及私有软件项目的托管平台，因为只支持git 作为唯一的版本库格式进行托管，故名gitHub。（来源百度百科） github官网点击这里 这个是github基础设置和使用详解点击这里 5.ssh授权获取私钥先配置SSH,在git-bash下输入 12git config --global user.name &quot;github注册名&quot;git config --global user.email &quot;github注册邮箱&quot; 打开git bash，输入ssh-kengen -t rsa，停顿时，敲击回车 最后会在C盘目录下生成id_ras和id_rsa.pub两个文件夹，用记事本打开id_rsa.pub，复制打开的文件内容到 github-&gt;setting-&gt;SSH and GPG key 下 添加后，在git-bash进行测试，输入 ssh -T git@github.com 如果返回Hi username ！You’ve successfully ……，说明配置成功 6.配置_config.yml打开你的hexo目录下的_config.yml文档（我用的是notepad++打开的） 修改最下面的deploy下的内容 12345type: gitrepository : //这里是你的仓库下，点击Clone ordownload（绿色的）点击Use SSH复制框框内的内容到这里。branch：//这里是你的bransh名称，默认为master 下面来修改 url和 root 123url ：// 是你的github 分配的地址root：// 是你的仓库的名字 一定要注意每一项冒号后有一个英文空格 7.本地测试打开git bash进入博客的根目录（cd + 文件夹名） 输入 12345hexo cleanhexo ghexo s hexo s是开启本地预览服务，打开浏览器访问 http://localhost:4000 即可看到内容。 显示的主题是 hexo 默认的 hexo 操作指令点击这里 8.上传到github仓库首先先安装hexo拓展库，打开git bash输入 12npm install hexo-deployer-git --savenpm install 然后输入 1234hexo clean//清除缓存hexo g//生成静态文件hexo d/上传打开github分配的网站，就可以看到你的blog了 后记自己搭建博客可能不是一帆风顺的，可能遇到各种不同的错误，一定要耐得住性子，一步一步来搭建。 记得，一定要善用搜索，遇到不懂得问题去百度上搜索。 最后，度娘，可真帅哪！！！","link":"/AngelNI.github.io/hexo-github/"},{"title":"暑假（补）-2","text":"围在城里的人想逃出来，城外的人想冲进去。–《围城》 有时候多学一点总没错，在你生活中一个不经意间就用上了。 VECTORvector类为内置数组提供了一种替代的表示，通常建议使用vector。（但仍有许多程序环境必须使用内置数组），vector 是C++中的一个容器类型，vector类是随标准C++引入的标准库的一部分。 使用vector必须包含相关的头文件 #include vector初始化 1234567891011121314151. vector&lt;int&gt; ve(10); //定义已知长度的Vector，初始值默认为02. vector&lt;int&gt; ve(10,2); //定义已知长度，并且初值为2的数组3. int a[4] = {1,2,3,4}; vector&lt; int &gt; ve( a , a+4); //将静态数组拷贝至不定数组4. vector&lt;int&gt; ve(&amp;a[1] , &amp;a[3] ) //将a[1],a[2]拷贝到不定数组，其实是一个地址的传递5. vector &lt;int&gt; a(10,2); vector&lt;int &gt; b(a); //vector 被另一个vector初始化 vector&lt;int &gt; c; c = b; //vector 被赋值给另一个vector、 vector操作12345678910111213#include&lt;vector&gt;vector&lt;int&gt; ve;ve.erase(ve.begin()+2) //删除第二个元素ve.insert(ve.begin()+2 , 1 ) //在第二个位置插入1ve.erase(ve.begin()+1,ve.begin()+4) //删除第1,2,3位置上的元素ve.size() //返回数组的大小ve.clear() //清空数组ve.back() //返回最后一个元素ve.front() //返回第一个元素ve[i] //返回第i个素ve.empty() //判断不定数组是否为空，空：true，非空：falseve.pop_back() //删除最后一个元素ve.push_back() //在最后插入一个元素 vector二维数组（输入，输出）123456789101112131415161718192021222324252627282930#include&lt;vector&gt;#include&lt;iostream&gt;#include&lt;cstring&gt;using namespace std;int main(){ vector&lt;vector&lt;int&gt; &gt; a; vector&lt;int&gt; b; int temp; int i,j; for(i =0;i&lt;5;i++) { b.clear(); for(j =0;j&lt;5;j++) { cin&gt;&gt;temp; b.push_back(temp); } a.push_back(b); } for(i=0;i&lt;5;i++) { for(j=0;j&lt;5;j++) { cout&lt;&lt;a[i][j]&lt;&lt;\" \"; } cout&lt;&lt;\"\\n\"; } return 0; } vector字符串数组123456789101112vector&lt;string&gt; text; string word; int a=5; while((a--)&amp;&amp;cin&gt;&gt;word )//// &amp;&amp; 短路问题 { text.push_back(word); } for(int i=0;i&lt;text.size();i++) { cout&lt;&lt;text[i]&lt;&lt;\" \"; } 动态空间申请malloc12345678910111213141516171819#include&lt;iostream&gt;#include&lt;stdlib.h&gt;#include&lt;stdio.h&gt;using namespace std;int main(){ int *p; int i; p = (int *)malloc(sizeof(int)*5); for(i=0;i&lt;5;i++) { cin&gt;&gt;p[i]; } for(i=0;i&lt;5;i++) cout&lt;&lt;p[i]&lt;&lt;endl; free(p); return 0; } calloc12345678910111213141516171819#include&lt;iostream&gt;#include&lt;stdlib.h&gt;#include&lt;stdio.h&gt;using namespace std;int main(){ int *p; int i; p = (int *)calloc(sizeof(int),5); for(i=0;i&lt;5;i++) { cin&gt;&gt;p[i]; } for(i=0;i&lt;5;i++) cout&lt;&lt;p[i]&lt;&lt;endl; free(p); return 0; } malloc 与 calloc 在使用方法上基本上是差不多的。malloc它允许从空间内存池中分配内存,malloc()的参数是一个指定所需字节数的整数。colloc与malloc类似,但是主要的区别是存储在已分配的内存空间中的值默认为0,使用malloc时,已分配的内存中可以是任意的值. colloc需要两个参数,第一个是需要分配内存的变量的个数,第二个是每个变量的大小. 二维空间申请12345678910111213141516171819202122232425262728#include&lt;iostream&gt;#include&lt;stdlib.h&gt;#include&lt;stdio.h&gt;using namespace std;int main(){ int ** p; int i,j; p = (int **)calloc(sizeof(int*),5); for(i =0;i&lt;5;i++) { p[i] = (int *)calloc(sizeof(int),5); } for(i=0;i&lt;5;i++) for(j =0;j&lt;5;j++) cin&gt;&gt;p[i][j]; for(i=0;i&lt;5;i++) for(j=0;j&lt;5;j++) cout&lt;&lt;p[i][j]&lt;&lt;endl; for (int i= 0; i &lt; 5; i++) { free(p[i]); } free(p); return 0; } 二维空间与一维空间主要的不同是：二维数组由一维数组组成，申请的空间要分别对每个一维空间申请。释放空间时也是如此，先释放每个一维空间，最后在释放二维空间。 C++ 动态空间申请12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152#include&lt;iostream&gt;#include&lt;iomanip&gt;using namespace std;int main(){ //一维空间申请 int m=9; int *p= new int[m]; for(int i=0;i&lt;9;i++) { cin&gt;&gt;p[i]; } for(int i=0;i&lt;9;i++) cout&lt;&lt;p[i]&lt;&lt;endl; delete []p; //二维空间申请方法一 int n=4,m=4; int tem =0; int **p = new int*[m]; for(int i=0;i&lt;m;i++) { p[i] = new int[n]; } for(int i=0;i&lt;m;i++) { for(int j=0;j&lt;n;j++) { p[i][j]=tem; tem++; } } for(int i=0;i&lt;m;i++) for(int j=0;j&lt;n;j++) cout&lt;&lt;p[i][j]&lt;&lt;endl; for(int i=0;i&lt;m;i++) delete []p[i]; delete []p; //二维空间申请方法二 int (*q)[3] = new int[3][3]; for(int i=0;i&lt;3;i++) for(int j=0;j&lt;3;j++) cin&gt;&gt;q[i][j]; for(int i=0;i&lt;3;i++) for(int j=0;j&lt;3;j++) cout&lt;&lt;q[i][j]&lt;&lt;setw(3); delete []q; return 0;}","link":"/AngelNI.github.io/learn-2/"},{"title":"暑假（补）-1","text":"乱花渐欲迷人眼，浅草才能建马蹄。最爱湖东行不足，绿杨阴里白沙堤。自己领会去吧！！！ 我是打酱油的啊，记住，打酱油的。 写个板子，过个水题，好让我签个到。 1.sort()（1） 数组1234567891011121314#include&lt;algorithm&gt;#include&lt;iostream&gt;using namespace std;bool cmp(stu a,stu b){ return a &lt; b ; //从小到大； return a &gt; b ;//从大到小； }int main(){ int a[10]={1,5,6,8,10,22,-5,99,100,-5} sort(a,a+10); return 0; } （2）结构体1234567891011121314151617181920212223242526272829#include&lt;stdio.h&gt;#include&lt;algorithm&gt;#include&lt;iostream&gt;using namespace std;struct stu{ int id; char name[20]; char sex[10];}student[10];bool cmp(stu a,stu b){ return a.id &lt; b.id ; //从小到大； return a.id &gt; b.id ;//从大到小； }int main(){ student[0].id = 10; student[1].id = 8; student[2].id = 1; student[3].id = 9; sort(student,student+4,cmp); for(int i=0;i&lt;4;i++) { printf(\"%d\\n\",student[i].id); } printf(\"%d\",student[0].id); return 0; } （3）数据类型排序123456789101112131415161718#include&lt;stdio.h&gt;#include&lt;iostream&gt;#include&lt;algorithm&gt;//#include&lt;functional&gt; using namespace std;int main(){ int a[10]={1,10,8,11,20,0,-9,85,21,3}; char b[10] = {'b','a','z','e','t','s','p','f','o','h'}; sort(a,a+10,less&lt;int&gt;()); sort(a,a+10,greater&lt;int&gt;()); sort(b,b+10,greater&lt;char&gt;()); for(int i=0;i&lt;10;i++) cout&lt;&lt;a[i]&lt;&lt;endl; for(int i=0;i&lt;10;i++) cout&lt;&lt;b[i]&lt;&lt;endl; return 0; } 2.GCDGCD是求最大公约数，有两种方法：1.自己构建函数。2.头文件中的__gcd()函数. 1234567891011121314151617#include&lt;stdio.h&gt;#include&lt;iostream&gt;#include&lt;algorithm&gt; using namespace std;/*int gcd(int a,int b){ return b ? gcd(b,a%b) : a;}*/int main(){ int a,b; cin&gt;&gt;a&gt;&gt;b; cout&lt;&lt;__gcd(a,b)&lt;&lt;endl; return 0; } 3.LCMLCM求最小公倍数，其实掌握了GCD，就简单的多了。 12345678910111213141516#include&lt;stdio.h&gt;#include&lt;iostream&gt;#include&lt;algorithm&gt;using namespace std;int gcd(int a,int b){ return b ? gcd(b,a%b) : a ; } int main(){ int a,b; cin&gt;&gt;a&gt;&gt;b; cout&lt;&lt;(a*b)/gcd(a,b)&lt;&lt;endl; cout&lt;&lt;(a*b)/__gcd(a,b)&lt;&lt;endl; return 0; } 4.素数打表素数打表根据比埃拉托斯特尼筛法，如果感兴趣，可以去找度娘。 123456789101112131415161718192021222324252627282930#include&lt;stdio.h&gt;#include&lt;iostream&gt;#include&lt;algorithm&gt;//#include&lt;cstring&gt;//#include&lt;string.h&gt;using namespace std;int main(){ int prim[1016]; memset(prim,0,sizeof(int)*1016); prim[1]=1; for(int i=2;i*i&lt;1016;i++) { if(!prim[i]) for(int j=i*i;j&lt;1016;j+=i) prim[j]=1; } for(int i=1;i&lt;1016;i++) { cout&lt;&lt;i&lt;&lt;'\\t'; cout&lt;&lt;prim[i]&lt;&lt;endl; } int count = 0; for(int i=1;i&lt;1016;i++) { if(prim[i]==0) count++; } cout&lt;&lt;count&lt;&lt;endl; return 0;} 5.快速幂取模快速幂取模，为了解决大数取模问题吧。 123456789101112131415161718192021#include&lt;stdio.h&gt;typedef long long ll;#define MOD 1000000007ll pow_mod(ll a,ll n){ ll res =1; while(n) { if(n&amp;1) res =res* a%MOD; a=a*a%MOD; n&gt;&gt;=1; } return res;}int main(){ int a = 4; int b = 6; printf(\"%d\",pow_mod(a,b)); return 0; }","link":"/AngelNI.github.io/learn-1/"},{"title":"暑假（补）-4","text":"想和你一起聊我的秘密，可发现你就是我的秘密。 DP（动态规划）动态规划算法是通过拆分问题，定义问题状态和状态之间的关系，使得问题能够以递推（或者说分治）的方式去解决。动态规划算法的基本思想与分治法类似，也是将待求解的问题分解为若干个子问题（阶段），按顺序求解子阶段，前一子问题的解，为后一子问题的求解提供了有用的信息。在求解任一子问题时，列出各种可能的局部解，通过决策保留那些有可能达到最优的局部解，丢弃其他局部解。依次解决各子问题，最后一个子问题就是初始问题的解。 题的类型不同，但都是在基础上的动态规划的模板上进行改进。那么接下来就从几道简单的动态规划题型入手吧。 1.矩阵取数原题链接 一个N*N矩阵中有不同的正整数，经过这个格子，就能获得相应价值的奖励，从左上走到右下，只能向下向右走，求能够获得的最大价值。 例如：3 * 3的方格。 1 3 3 2 1 3 2 2 1 输入 12第1行：N，N为矩阵的大小。(2 &lt;= N &lt;= 500)第2 - N + 1行：每行N个数，中间用空格隔开，对应格子中奖励的价值。（1 &lt;= N[i] &lt;= 10000) 输出 1输出能够获得的最大价值。 输入样例 123431 3 32 1 32 2 1 输出样例 111 我们来用DP的思想来解决这个问题x 设矩阵是 . 假设我们已经知道了最大路径，并且经过（x, y）这个位置，为了从起点到终点得到的和最大，那 么从起点到 (x , y) 经过的数的和也一定要最大。这几乎是显然的。这是理解这一题的重点。走到 (x, y) 的上一步，可能是 （x-1, y） 或者（x, y-1）. 按照我门上面得出的结论，我们可以这样说： 如果从起点达到(x,y)的最优路径要经过(x – 1,y)或者(x,y – 1)则，从起点到达(x – 1,y)或者(x,y – 1)的 路径一定也必须是最优的。所以只需要比较 到达(x – 1,y)或者(x,y – 1)的最优路径哪一个更加优。为了方便表示，我们用： 来表示起点到 （x，y）的最优路径长度。 所以,起点到 （x，y）的最优路径可以表示成： f（x,y） = max( f(x-1,y) , f(x,y-1) )+ A [ x ] [ y ]到了这里肯定会有疑问了，这怎么感觉和上面的贪心策略差不多？？其实不，这里是理解DP的重点。根据上面的这个递推公式，我门可以准确的推导出从起点到所有点 的最优解。是整体的最优。而贪心策略只是在局部做选择，是局部的最优。 AC12345678910111213141516171819202122#include&lt;iostream&gt;#include&lt;algorithm&gt;using namespace std;int a[600][600]; int main(){ int n ; cin&gt;&gt;n; for(int i =0;i&lt;n;i++) for(int j =0;j&lt;n;j++) cin&gt;&gt;a[i][j]; for(int i =1;i&lt;n;i++) { a[i][0]+=a[i-1][0]; a[0][i]+=a[0][i-1]; } for(int i =1;i&lt;n;i++) for(int j =1;j&lt;n;j++) a[i][j]+=max(a[i-1][j],a[i][j-1]); cout&lt;&lt;a[n-1][n-1]&lt;&lt;endl; return 0; } 2.数字三角形原题链接 Description 7 3 8 8 1 0 2 7 4 4 4 5 2 6 5 Figure 1 shows a number triangle. Write a program that calculates the highest sum of numbers passed on a route that starts at the top and ends somewhere on the base. Each step can go either diagonally down to the left or diagonally down to the right. Input Your program is to read from standard input. The first line contains one integer N: the number of rows in the triangle. The following N lines describe the data of the triangle. The number of rows in the triangle is &gt; 1 but &lt;= 100. The numbers in the triangle, all integers, are between 0 and 99. Output Your program is to write to standard output. The highest sum is written as an integer. Sample Input 123456573 88 1 0 2 7 4 44 5 2 6 5 Sample Output 130 DP12345678910111213141516171819202122232425262728293031#include&lt;iostream&gt;#include&lt;algorithm&gt;using namespace std;#include&lt;stdio.h&gt; int n;int a[200][200];int DP(int i,int j){ if(i==n) return a[i][j]; else { int x = DP(i+1,j); int y = DP(i+1,j+1); return max(x,y)+a[i][j]; } } int main(){ while(cin&gt;&gt;n) { scanf(\"%d\",&amp;n); for(int i =1;i&lt;=n;i++) for(int j =1;j&lt;=i;j++) scanf(\"%d\",&amp;a[i][j]); printf(\"%d\",DP(1,1)); } return 0; } 非递归解决方案12345678910111213141516171819202122#include&lt;iostream&gt;#include&lt;algorithm&gt;using namespace std;int a[600][600]; int main(){ int n ; cin&gt;&gt;n; for(int i =0;i&lt;n;i++) for(int j =0;j&lt;n;j++) cin&gt;&gt;a[i][j]; for(int i =1;i&lt;n;i++) { a[i][0]+=a[i-1][0]; a[0][i]+=a[0][i-1]; } for(int i =1;i&lt;n;i++) for(int j =1;j&lt;n;j++) a[i][j]+=max(a[i-1][j],a[i][j-1]); cout&lt;&lt;a[n-1][n-1]&lt;&lt;endl; return 0; } 这个DP思想是对的，并且答案也是对的，但当你submit时，TE了。因为有节点重复相加了，可以用记忆化搜索，解决重复相加问题。 记忆化搜索123456789101112131415161718192021222324#include&lt;iostream&gt;#include&lt;algorithm&gt;using namespace std;int t;int a[101][101],ans[101][101];int dfs(int i ,int j){ if(i==t) return a[i][j]; if(ans[i][j]) return ans[i][j]; int x =dfs(i+1,j); int y = dfs(i+1,j+1); return ans[i][j]= max(x,y)+a[i][j];}int main(){ cin&gt;&gt;t; for(int i=1;i&lt;=t;i++) for(int j =1;j&lt;=i;j++) cin&gt;&gt;a[i][j]; cout&lt;&lt;dfs(1,1); return 0;} 3.最大序列和原题链接 Problem Description Given a sequence a[1],a[2],a[3]……a[n], your job is to calculate the max sum of a sub-sequence. For example, given (6,-1,5,4,-7), the max sum in this sequence is 6 + (-1) + 5 + 4 = 14. Input The first line of the input contains an integer T(1&lt;=T&lt;=20) which means the number of test cases. Then T lines follow, each line starts with a number N(1&lt;=N&lt;=100000), then N integers followed(all the integers are between -1000 and 1000). Output For each test case, you should output two lines. The first line is “Case #:”, # means the number of the test case. The second line contains three integers, the Max Sum in the sequence, the start position of the sub-sequence, the end position of the sub-sequence. If there are more than one result, output the first one. Output a blank line between two cases. Sample Input 12325 6 -1 5 4 -77 0 6 -1 1 -6 7 -5 Sample Output 12345Case 1:14 1 4Case 2:7 1 6 AC1234567891011121314151617181920212223242526272829303132333435363738#include&lt;iostream&gt;#include&lt;cstdio&gt;using namespace std;int a[100100];int main(){ int t; cin&gt;&gt;t; int l =0; while(t--) { int n ; cin&gt;&gt;n; for(int i=1;i&lt;=n;i++) cin&gt;&gt;a[i]; int p=1,start=1,end=1; int maxsum=a[1]; for(int i=2;i&lt;=n;i++) { if(a[i-1]+a[i]&gt;=a[i]) { a[i] = a[i]+a[i-1]; } else p =i; if(a[i]&gt;maxsum) { maxsum=a[i]; start=p; end=i; } } printf(\"Case %d:\\n%d %d %d\\n\",++l,maxsum,start,end); if(t) cout&lt;&lt;\"\\n\"; } return 0;} 4.最长递增子序列原题链接 给出长度为N的数组，找出这个数组的最长递增子序列。(递增子序列是指，子序列的元素是递增的） 例如：5 1 6 8 2 4 5 10，最长递增子序列是1 2 4 5 10。 输入 12第1行：1个数N，N为序列的长度(2 &lt;= N &lt;= 50000)第2 - N + 1行：每行1个数，对应序列的元素(-10^9 &lt;= S[i] &lt;= 10^9) 输出 1输出最长递增子序列的长度。 输入样例 1234567898516824510 输出样例 15 AC1234567891011121314151617181920212223#include&lt;iostream&gt;#include&lt;algorithm&gt;using namespace std;int a[50001],dp[50001];int main(){ int n,ans=0; cin&gt;&gt;n; for(int i=0;i&lt;n;i++) cin&gt;&gt;a[i]; for(int i=0;i&lt;n;i++) { dp[i]=1; for(int j=0;j&lt;i;j++) { if(a[i]&gt;a[j]) dp[i]=max(dp[i],dp[j]+1); } ans=max(ans,dp[i]); } cout&lt;&lt;ans&lt;&lt;endl; return 0;} 提交后发现TE了，这是一个时间复杂度为O(n**2)的程序。 下面是一个时间复杂度为O(nlogn) 123456789101112131415161718192021222324#include&lt;iostream&gt;#include&lt;algorithm&gt;#include&lt;cstring&gt;using namespace std;int a[50001];int f[50001];int main(){ int n,maxn; cin&gt;&gt;n; for(int i=0;i&lt;n;i++) cin&gt;&gt;a[i]; int len=1; memset(f,0,sizeof(f));//创建一个新数组存放最长上升序列 f[0]=a[0]; for(int i=1;i&lt;n;i++) { int pos=lower_bound(f,f+len,a[i])-f;//二分查找i+1个数中最长上升序列，a[i]的位置 f[pos]=a[i]; len=max(len,pos+1);//最长上升序列的数量 } cout&lt;&lt;len&lt;&lt;endl; return 0;}","link":"/AngelNI.github.io/learn-4/"},{"title":"map函数的简单用法","text":"你要开心，你要快乐，因为你是大哥，不可以难过。","link":"/AngelNI.github.io/map函数的简单用法/"},{"title":"暑假（补）-5","text":"遇见你我花光了所有的运气，以至于现在厄运连连。 深度优先搜索（DFS）DFS全称Deep First Search，是一种遍历或搜索树或图的算法。在解决问题上，利用递归调用自身函数（这种说法好像不正确，领悟思想就好了）来实现搜索的目的。把一个事情拆解成若干个小事，来实现最终的问题。 学好DFS，一定要领悟递归函数之美。下面就直接上题来理解了。 1.放苹果POJ1664 Description把M个同样的苹果放在N个同样的盘子里，允许有的盘子空着不放，问共有多少种不同的分法？（用K表示）5，1，1和1，5，1 是同一种分法。 Input 第一行是测试数据的数目t（0 &lt;= t &lt;= 20）。以下每行均包含二个整数M和N，以空格分开。1&lt;=M，N&lt;=10。 Output 对输入的每组数据M和N，用一行输出相应的K。 Sample Input 1217 3 Sample Output 18 1.有空盘子：举个栗子吧。3个苹果放到5个盘子的方法总数和3个苹果放到3个盘子的方法总数是相等的。 2.没有空盘子：没有空盘子，我们可以看成先给每一个盘子放一个苹果，还剩下m-n个苹果。然后问题就变成了把m-n个苹果放到n个盘子里的问题了，也许有人会问，m-n个苹果放到n个盘子也会出现空盘子的情况啊，不是和前面的有空盘子重复了？的确，会出现空盘子的情况，但是，他们并不是真的空盘子，因为他们最开始已经放了一个，他们在这里的空代表着这个盘子只有最开始放的一个苹果。 因此： ​ f(m,n)=f(m,n-1)+f(m-n,n) m&gt;=n ​ f(m,n)=f(m,m) m&lt;n 递归结束条件：结束条件并不是很难发现，当只有一个盘子时明显只有一种方法，另外没有苹果和只有一个苹果的时候也只有一种放法。即f(m,n)=1 n=1,m=0 综上所述： f(m,n)=1 n=1,m=0 f(m,n)=f(m,m) m&lt;n f(m,n)=f(m,n-1)+f(m-n,n) m&gt;=n AC1234567891011121314151617181920212223#include&lt;iostream&gt;using namespace std;int dfs(int m,int n){ if(n==1||m==0) return 1; if(n&gt;m) return dfs(m,m); else return dfs(m,n-1)+dfs(m-n,n);}int main(){ int t; cin&gt;&gt;t; while(t--) { int m,n; cin&gt;&gt;m&gt;&gt;n; cout&lt;&lt;dfs(m,n)&lt;&lt;endl; } return 0;} 2.N皇后问题N皇后 Problem Description在N*N的方格棋盘放置了N个皇后，使得它们不相互攻击（即任意2个皇后不允许处在同一排，同一列，也不允许处在与棋盘边框成45角的斜线上。你的任务是，对于给定的N，求出有多少种合法的放置方法。 Input 共有若干行，每行一个正整数N≤10，表示棋盘和皇后的数量；如果N=0，表示结束。 Output 共有若干行，每行一个正整数，表示对应输入行的皇后的不同放置数量。 Sample Input 12341850 Sample Output 12319210 N皇后，比较经典的DFS的题。对每一个位置搜索，并判断位置是否合法，合法则继续向下进行。 因为时间限制，这道题用了打表的方法，记录每种可能下的结果值。具体请看代码。 AC1123456789101112131415161718192021222324252627282930313233343536373839404142434445464748//#include&lt;bits/stdc++.h&gt;#include&lt;iostream&gt;#include&lt;algorithm&gt;using namespace std;int ans[20],pos[20];int num,N;void dfs(int n){ int flag;//判断标志 if(n == N+1)//结束标志 { num++; return ; } for(int i = 1;i &lt;= N;i++) { pos[n] = i;//将第n行第i列的位置下上旗子，保存位置 flag = 1;//此位置以有棋子 /*判断棋子是否合法*/ for(int j =1;j&lt;n;j++)//只需判断已下过棋子的位置 { if(pos[j] == i || (abs(n-j)) == abs(pos[j] - i))//判断同一列、对角线上是否有 { flag = 0; break; } } //合法则继续下一个 if(flag) dfs(n+1); }}int main(){ for(N =1;N&lt;=11;N++) { num = 0; dfs(1); ans[N] = num;//记录结果值 } int t; while(cin&gt;&gt;t&amp;&amp;t!=0) { cout&lt;&lt;ans[t]&lt;&lt;endl; } return 0;} AC2这是另外一个，相比于上一个，代码理解起来就容易多了。分为两个函数，一个是dfs函数，另一个是条件判断函数。 1234567891011121314151617181920212223242526272829303132333435363738394041424344#include&lt;stdio.h&gt;#include&lt;iostream&gt;using namespace std;int n,m,ans=0;int a[20][20],ans[20],o;int check(int x,int y){ for(int i=0;i&lt;x;i++) if(a[i][y]==1) return 0; for(int i=x-1,j=y-1;i&gt;=0&amp;&amp;j&gt;=0;i--,j--) if(a[i][j]==1) return 0; for(int i=x-1,j=y+1;i&gt;=0&amp;&amp;j&lt;o;i--,j++) if(a[i][j]==1) return 0; return 1;}void dfs(int x){ if(x==o) { ans[o]++; return; } for(int i=0;i&lt;o;i++) { if(check(x,i)) { a[x][i]=1; dfs(x+1); a[x][i]=0; } }}int main(){ for(o=1;o&lt;=10;o++) { dfs(0); } while(cin&gt;&gt;n&amp;&amp;n!=0) { cout&lt;&lt;ans[n]&lt;&lt;endl; } return 0; } 3.红与黑HDU1312 Problem DescriptionThere is a rectangular room, covered with square tiles. Each tile is colored either red or black. A man is standing on a black tile. From a tile, he can move to one of four adjacent tiles. But he can’t move on red tiles, he can move only on black tiles. Write a program to count the number of black tiles which he can reach by repeating the moves described above. Input The input consists of multiple data sets. A data set starts with a line containing two positive integers W and H; W and H are the numbers of tiles in the x- and y- directions, respectively. W and H are not more than 20. There are H more lines in the data set, each of which includes W characters. Each character represents the color of a tile as follows. ‘.’ - a black tile‘#’ - a red tile‘@’ - a man on a black tile(appears exactly once in a data set) Output For each data set, your program should output a line which contains the number of tiles he can reach from the initial tile (including itself). Sample Input 1234567891011121314151617181920212223242526272829303132333435366 9....#......#..............................#@...#.#..#.11 9.#..........#.#######..#.#.....#..#.#.###.#..#.#..@#.#..#.#####.#..#.......#..#########............11 6..#..#..#....#..#..#....#..#..###..#..#..#@...#..#..#....#..#..#..7 7..#.#....#.#..###.###...@...###.###..#.#....#.#..0 0 Sample Output 12344559613 这是一个搜图的问题，用DFS，恰到好处，只需判断是否满足条件就可以ans++，比较简单的一道，要注意输入哦（因为这wa了好久） AC12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849#include&lt;stdio.h&gt;#include&lt;string.h&gt;#include&lt;iostream&gt;#include&lt;bits/stdc++.h&gt;using namespace std;char a[25][25];int vis[25][25];int w[4][2]={1,0,-1,0,0,1,0,-1};int x,y,xx,yy,xx1,yy1;int ans;void dfs(int x,int y){ vis[x][y] = 1; if(x&lt;0||y&lt;0||x&gt;=xx||y&gt;=yy) return ; for(int i =0;i&lt;4;i++) { int dx = x+w[i][0]; int dy = y+w[i][1]; if(dx&gt;=0&amp;&amp;dy&gt;=0&amp;&amp;dx&lt;xx&amp;&amp;dy&lt;yy&amp;&amp;a[dx][dy]!='#'&amp;&amp;vis[dx][dy]==0) { ans++; dfs(dx,dy); } }}int main(){ while(~scanf(\"%d %d\",&amp;yy,&amp;xx)&amp;&amp;xx&amp;&amp;yy) { memset(vis,0,sizeof(vis)); ans = 1; for(int i =0;i&lt;xx;i++) { for(int j =0;j&lt;yy;j++) { cin&gt;&gt;a[i][j]; if(a[i][j]=='@') { xx1 = i; yy1 = j; } } } dfs(xx1,yy1); cout&lt;&lt;ans&lt;&lt;endl; } return 0;} 未完待续……","link":"/AngelNI.github.io/learn-5/"},{"title":"sort() function","text":"C++中的sort（）函数我在之前的博客中提到，解决排序问题的一个好用的函数就是C++的sort（）函数啦。sort（）函数是C++内置的函数，只需要加入头文件，掌握正确的使用方法，你就可以在排序中驰骋疆场了（自吹自擂）。好啦，下面就请主角登场吧 sort()1.介绍c++语言中 STL 库中的sort函数可以用来对数组进行排序。对于c++语言来说由于其自带的sort()函数更容易被编译器编译，其排序速度比基于快速排序的qsort要快上不少，且用法简单。(百度知道) 2.准备sort（）函数的使用需要添加头文件 123#include&lt;algorithm&gt;或者万能头文件#include&lt;bits/stdc++.h&gt; 3.使用方法sort（star,end,cmp）* sort函数有三个参数： 1.第一个是要排序的数组的起始地址 2.第二个是结束地址（最后一位的地址的下一地址） 3.第三个参数是排序的方法。sort函数默认是按从小到大排序。可以修改cmp实现从大到小排序 123sort（begin，end，less&lt;data-type&gt;)——升序sort（begin，end，greater&lt;data-type&gt;)——降序 以上是比较简单常用的对数组的排序方法，sort（）类函数中还有其他的排序功能。 4.sort()类函数 函数名 功能描述 sort 对给定区间所有元素进行排序 stable_sort 对给定区间所有元素进行稳定排序 partial_sort 对给定区间所有元素进行稳定排序 partial_sort 对给定区间所有元素部分排序 partial_sort_copy 对给定区间复制并排序 nth_element 找出给定区间的某个位置对应的元素 is_sorted 判断一个区间是否已经排好序 partition 使得符合某个条件的元素放在前面 stable_partition 相对稳定的使得符合某个条件的元素放在前面 5.sort（）函数练习1.有序序列合并链接： https://ac.nowcoder.com/acm/contest/827/J 来源：牛客网 题目描述 输入两个升序排列的序列，将两个序列合并为一个有序序列并输出。 输入描述: 1234567输入包含三行，第一行包含两个正整数n, m（1 ≤ n,m ≤ 100），用空格分隔。n表示第二行第一个升序序列中数字的个数，m表示第三行第二个升序序列中数字的个数。第二行包含n个整数（范围1~5000），用空格分隔。第三行包含m个整数（范围1~5000），用空格分隔。 输出描述: 输出为一行，输出长度为n+m的升序序列，即长度为n的升序序列和长度为m的升序序列中的元素重新进行升序序列排列合并。 示例1 输入5 61 3 7 9 222 8 10 17 33 44输出1 2 3 7 8 9 10 17 22 33 44 1234567891011121314151617181920212223242526272829#include&lt;cstdio&gt;#include&lt;iostream&gt;#include&lt;algorithm&gt;using namespace std;int n,m,t;int a[100],b[100],c[200];int main(){ cin&gt;&gt;n&gt;&gt;m; t=n; for(int i=0;i&lt;n;i++) { cin&gt;&gt;a[i]; c[i]=a[i]; } for(int i=0;i&lt;m;i++) { cin&gt;&gt;b[i]; c[t++]=b[i]; } sort(c,c+m+n); for(int i=0;i&lt;m+n;i++) { cout&lt;&lt;c[i]; putchar(' '); } return 0; } 2.最高最低分差链接： https://ac.nowcoder.com/acm/contest/827/E 来源：牛客网 题目描述 输入n个成绩，换行输出n个成绩中最高分数和最低分数的差。 输入描述: 123两行，第一行为n，表示n个成绩，不会大于10000。第二行为n个成绩（整数表示，范围0~100），以空格隔开。 输出描述: 1一行，输出n个成绩中最高分数和最低分数的差。 示例1 输入 121098 100 99 97 95 99 98 97 96 100 输出 5 12345678910111213141516#include&lt;stdio.h&gt;#include&lt;algorithm&gt;#include&lt;iostream&gt;using namespace std;int main(){ int n,a[10000],sum=0; scanf(\"%d\",&amp;n); for(int i=0;i&lt;n;i++) scanf(\"%d\",&amp;a[i]); sort(a,a+n); sum=a[n-1]-a[0]; printf(\"%d\",sum); return 0; }","link":"/AngelNI.github.io/sort-函数/"},{"title":"matplotlib 常用图绘制","text":"我的冷漠里藏着一半的害羞，一半的自卑。 通过做图表来分析数据实在是一个非常棒的方法，由于我偶尔忘记语法，还得翻之前的笔记，难受。下面就画了些常用的图，记一记，记一记。 1.折线图12345678910111213141516171819202122import matplotlibimport matplotlib.pyplot as plt%matplotlib inlinex1 = [1,2,3] y1 = [5,7,4]x2 = [1,2,3] y2 =[10,14,12]matplotlib.rcParams['font.sans-serif'] = ['SimHei']#中文显示问题f=plt.figure(figsize=(12,10))#调整图像大小plt.plot(x1,y1,label='First Line')plt.plot(x2, y2, label='Second Line')plt.xlabel(\"Plot Number\",fontsize = 20)#x轴 标签及调整字体大小plt.ylabel(\"Important var\",fontsize = 20)#y轴 标签及调整字体大小plt.title(\"标题\", fontsize = 20)#标题plt.legend()#显示图例plt.xlim(0,4)#调整x轴大小plt.ylim(0,15)#调整y轴大小plt.grid()#添加格线plt.show() 2.柱状图1234567891011121314151617181920212223matplotlib.rcParams['font.sans-serif'] = ['SimHei']label_list = [\"AUC\",\"MAP\",\"MRR\",\"Prec\",\"Rec\",\"F1\",\"NDGC\",\"Call\"]num_list_1 = [ 0.8395789534863245,0.03947255032401116,0.4421931735657211,0.18845315904139434,0.061183509516103594, 0.07578339296217934, 0.20391161229968288, 0.5533769063180828]num_list_2 = [0.8099706571182651, 0.07124258816665524,0.5007884899720522,0.29520697167755994,0.051690038913594256,0.07702843749844428, 0.30278346199328815,0.664488017429194]x = range(len(num_list_1))#f=plt.figure(figsize=(12,10))rects_1 = plt.bar( x,height = num_list_1,width = 0.4,alpha = 0.8,color = \"red\",label = \"MBPR\")rects_2 = plt.bar([i+0.4 for i in x],height = num_list_2,width = 0.4,alpha = 0.8,color = \"blue\",label = \"BPR\")#柱状图对比plt.ylim(0,1)plt.ylabel(\"指标\")plt.xticks([index + 0.2 for index in x], label_list)#自定义x 轴含义plt.xlabel(\"模型\")plt.title(\"MBPR、BPR对比图\")plt.legend()plt.show() 3.散点图1234x = [1,2,3,4,5,6]y = [1,2,3,4,5,6]#f = plt.figure(figsize=(12,10))plt.scatter(x,y,color=\"r\") 4.饼图123456#f=plt.figure(figsize=(12,10))slices = [7,2,2,13]activities = ['sleeping','eating','working','playing'] cols = ['c','m','r','b']plt.pie( slices,labels=activities,colors=cols,startangle=90,shadow= True ,explode=(0,0.3,0,0),autopct='%1.1f%%')# autopct='%1.1f%%' 百分比 5.箱式图12345import seaborn as sns#f=plt.figure(figsize=(12,10))sns.set_style(\"whitegrid\")data = np.random.normal(size=(20, 6)) + np.arange(6) / 2sns.boxplot(data=data) 6.热度图12345678910%matplotlib inlineimport matplotlib.pyplot as pltimport numpy as np; np.random.seed(0)import seaborn as sns;sns.set()uniform_data = np.random.rand(3, 3)#print (uniform_data)heatmap = sns.heatmap(uniform_data) 7.子图123456789101112131415161718192021222324252627import matplotlib.pyplot as pltimport numpy as npx = np.linspace(-10, 10, 100)y =2*np.cos(x)**5 + 3*np.sin(x)**3#定义画布和子图数量fig,axes=plt.subplots(2,3,figsize=(20,18),facecolor='#ccddef')#添加整个画布的标题fig.suptitle('我是最大的标题',fontsize=20)#利用text属性添加副标题fig.text(0.45,0.9,'这是副标题')#折线图axes[0][0].plot(x,y)#柱状图axes[0][1].bar(x,y)#直方图axes[0][2].hist(y,bins=30)#散点图axes[1][0].scatter(x,y)#条形图axes[1][1].barh(x,y)#饼图axes[1][2].pie([1,2,3,4,5],labels=['A级','B级','C级','D级','E级'])#axes[1,2].boxplot() 需要合适的数据，就不画了#设置子图的xy轴范围，子图标题，标签背景颜色等，也可单独使用ax1.set_xlim()进行设置。部分属性不能直接使用set设置ax1.set(xlim=[-10,12],ylim=[-6,4],title='This is TU1',xlabel='xlabel',ylabel='ylabel',facecolor='#ffeedd')","link":"/AngelNI.github.io/matplotlib/"},{"title":"termux","text":"快到我的碗里来，不，是怀里。 termux分享一个超好用的手机命令行高级终端软件termux，强大的安卓手机渗透工具，没有之一。 termux是一个Android下一个高级的终端模拟器,开源且不需要root,支持apt管理软件包，十分方便安装软件包,完美支持Python,PHP,Ruby,Go,Nodejs,MySQL等。随着智能设备的普及和性能的不断提升，如今的手机、平板等的硬件标准已达到了初级桌面计算机的硬件标准,用心去打造完全可以把手机变成一个强大的工具. 官网 Github项目地址 Google Play下载地址 如果想你学习linux基本操作指令，不想通过费事的虚拟机，那就请选择termux； 如果你想简单而快速链接服务器，轻巧的使用openssh，请毫不犹豫的选择termux； 如果你想成为一个黑客，正愁缺少工具，那就立刻马上选择termux，为您提供nmap端口扫描，hydra密码暴力破解，SQLmap漏洞检测及注入等必备的工具。 在当今智能手机快速发展的今天，手机已经逐渐实现了电脑的许多功能，有没有想过在手机上搭建hexo博客，发表博文，有没有想过用手机去运行AI程序，是不是更不敢想利用手机网络渗透了。这一切都已经在手机上已经实现，你没有听错。在我看来，一个更便捷的世界即将到来，到那时也许连拿笔记本电脑都觉得费事，所有的一切通过手机和ipad就可以实现你想要的效果。 否恩和艾派德的完美组合值得期待。 最后在这里推荐一篇非常好的博文减少termux 的使用教程及我的一些操作截图。 termux使用教程","link":"/AngelNI.github.io/termux/"},{"title":"Ubuntu_基础应用篇","text":"【转载】分享给那些喜欢Linux ，喜欢Ubuntu的小伙伴。 此文章为转载文章，转载请著名出处 @http://blog.csdn.net/gatieme非常感谢原作者的分享和AderStep对这些美味食物的整理。 链接 链接 安装Ubuntu后必须要做的几件事(一)–基础应用篇 安装Ubuntu后必须要做的几件事（二）–开发工具篇 终端的乐趣–Linux下有趣的终端命令或者工具 Ubuntu使用apt-file解决库或者文件缺失依赖 Ubuntu切换默认sh为bash或者dash Linux下几款C++程序中的内存泄露检查工具 解决ubuntu无法调整和保存屏幕亮度的问题 Ubuntu安装Microsoft Windows Fonts微软字体库 解决Windows与Ubuntu双系统时间同步问题 Ubuntu安装图片处理工具GIMP及其插件 21款最佳Linux命令行终端工具 两台Linux系统之间传输文件的几种方法 使用gdb调试程序完全教程 linux下man手册的安装和使用 Linux下查看并下载命令源码包（根据命令/应用程序逆向获取并且安装其所属源码包） 如何参与linux内核开发 linux 如何显示一个文件的某几行(中间几行) Git中的AutoCRLF与SafeCRLF换行符问题 linux环境中英文切换配置以及乱码问题 linux下使用ccat让你的cat高亮显示 怎么判断你的linux系统是不是运行在虚拟机器上面 Linux下管理用户的命令大全 Linux软连接和硬链接 Linux性能测试工具-UnixBench–安装以及结果分析 CodeBlocks最全官方配色方案 C/C++log日志库比较 Centos5.x/Linux下升级python到python2.7版本教程 几款xshell绝佳配色方案 VS2012插件推荐 linux下的终端利器—-tmux Ubuntu下Sublime Text 3解决无法输入中文的方法 使用trash-cli避免误删文件–为rm增加回收站功能 Ubuntu安装Python的包管理工具Pip Ubuntu安装配置串口通讯工具minicom&amp;&amp;cutecom Ubuntu编译安装llvm-clang 搜索引擎收录大全 Ubuntu安装深度音乐&amp;&amp;深度影音 Vimium-Geek是这样上网的[Chrome–插件] 几款好的markdown编辑器 Windows&amp;&amp;Linux双系统引导项修复问题汇总 安装CentOS时误将将引导项写入U盘后的修复 Linux操作系统中，.zip、.tar、.tar.gz、.tar.bz2、.tar.xz、.jar、*.7z等格式的压缩与解压 Chrome浏览器护眼插件 Google搜索技巧终极收集 世界上最神奇的网站收录–不是最无聊就是最有意思 Python模块之命令行解析工具-argparse GNOME下设置应用程序图标 git 删除右键菜单项 个性化您的Ubuntu Linux终端 Python判断当前操作系统类型以及os/sys/platform模块简介 Python实现设置终端显示颜色、粗体、下划线等效果 Python程序在Windows终端乱码解决方法 发现的更强大的vim配置信息 Ubuntu禁止mysql开机启动 Ubuntu下使用sysv-rc-conf管理服务 使用Vundle管理Vim插件 Vim的安装与配置 push到github时，每次都要输入用户名和密码的问题 Ubuntu安装配置mysql 盘点Linux下的开源云平台&amp;&amp;云存储服务 Ubuntu下安装GTK库 Linux下查看系统信息命令 Ubuntu更新软件源 linux命令行界面（CLI）浏览器 Linux下使用unzip解压缩中文乱码问题 Linux下的下载工具介绍—-aria2 vim 树形目录插件NERDTree安装 urllib2模块之异常处理 Python第三方库 Sublime text 3设置用用空格替换tab键 几款好的C/C++编译器（编译器而非IDE） Sublime Text 3配置Windows下C/C++编译环境 Sublime Text[崇高文本]—-最性感的编辑器（程序员必备） WingIDE安装和破解（Python开发利器） Linux设置nfs共享目录 让你的python程序开机自启动 Linux环境设置 喜欢linux的小伙伴快来，加入这个有趣的生态圈。","link":"/AngelNI.github.io/ubuntu-beauty/"},{"title":"git远程操作仓库","text":"如果我在勇敢点，结果会不会比想象中的要好。 Git是一个开源的分布式版本控制系统，分布式相比集中式的最大区别是Git没有“中央服务器”，每位开发者都可以通过克隆（git clone）远程库，在本地机器上存储一个完整的Git仓库，还可以把代码的修改提交到本地库。当然了，本地库修改完成后也可以上传到远程仓库，操作方便。 在学习git的操作方法，总是偶然的上传成功。这次不一样了，向大家介绍每一步的操作流程和成功案例。 git clone + “要克隆的仓库地址链接” 克隆之后对仓库文件进行处理，添加或删除，修改或重写。 进入以克隆的文件夹，并执行 git init初始化 git add * 将所有文件添加到缓存 git pull + “文件储存的绝对路径” git commit -m +”备注” git remote add “备注” +”仓库链接（也是克隆的链接地址）” 最后，git push 静静等待，操作成功。 如果你顺利完成了以上步骤，那么就要恭喜你了，已经成功上传到github仓库。其他储存仓库操作步骤类似。","link":"/AngelNI.github.io/untitled/"},{"title":"Gobang？","text":"时间带着明显的恶意，缓缓在我的身上流逝 向大家介绍一款游戏，就是五子棋。 什么，五子棋？？？ 没错，就是高大上的五子棋，这是一个基于神经网络用Python写的小游戏五子棋，经过大量的训练，已经很优秀了呢！！！不知道你敢不敢与他战斗啊. Introduce to you a game, that is gobang.What, Gobang???Yes, it’s Gobang in Gaoda. It’s a small game written by Python based on neural network. After a lot of training, it’s already excellent!!! I wonder if you dare to fight him. Github项目地址","link":"/AngelNI.github.io/五子棋？/"},{"title":"二分法查找","text":"二分法查找二分法查找，二分搜所，也称折半搜索，每次查找区间减半，适用于数据量较大，对一个有序的数组中查找某一元素。 例如：给一有序的数组a[9]={1,2,3,4,5,6,7,8,9,}，想要确定 3 的位置。 实现：123(a[0]+a[8])/2=5 大于 3 则只需要查找a[0]~a[4]就可以(a[0]+a[4])/2=3 此时刚好等于3，则此时3的位置就是（0+4）/2=2则可知 a[2]=3 至此查找结束 下面通过一个例子来具体体验下二分法的妙处 Trailing Zeroesn的阶乘尾部有q个连续的0，现在给你q，请你算出满足条件的n，如果有多个n满足条件，输出最小的那个即可。 Input123输入一个T(T &lt;= 10000),表示样例数量。每个样例输入一个q。(1 &lt;= q &lt;= 100,000,000) output对于每个样例，输出满足条件的最小的n，如果没有满足条件的则输出”impossible”。. Sample Input12345673125 Sample Output12345Case 1: 5Case 2: 10Case 3: impossible 思路这是一个判断阶乘后面有多少个零，输出满足条件下的最小解。 首先判断0的个数，我们可以通过判断5的个数来判断0`的个数（10可以分成2*5） 1例如：5！=1*2*3*4*5=120 代码实现12345678910long long fn(long long n) //求n阶乘的末尾0个数 { long long a = 0; while(n) { a += n/5; n = n/5; } return a;} 例如：判断25！末尾有几个0 a=25/5 –&gt; a=5 a+=5/5 –&gt; a=6 由此可以判断25的阶乘末尾有6个零（拿计算器验证） 整个题解（这是大佬写的，我偷偷拿来哈~） 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950##### #include&lt;iostream&gt; //cin，cout数据流输入输出的头文件#include&lt;cstdio&gt;using namespace std;typedef long long ll; //声明定义long long 的别名 llconst ll maxn = 1e17; //题目中0的个数 1~1e9ll fn(ll n)//求n阶乘的末尾0个数 { ll a = 0; while(n) { a += n/5; n = n/5; } return a;}int main(){ int n, q; ll ans;//定义所要求的答案 int Case = 0; cin&gt;&gt;n; //输入测试组数 while(n--) { Case++;//判断测试第几个 cin&gt;&gt;q;//输入0的个数 int l, r;//定义左值，和右值 l =1; r = maxn; ans = 0; while(r&gt;=l) { ll mid = (l+r)&gt;&gt;1; //直接平均可能溢出，所以用这个 注： &gt;&gt; 值的二进制形式右移一位，相当于十进制除2 if(fn(mid)==q) { ans = mid;//如果中间的那个数零的个数恰好等于q，则为答案 r = mid-1; } else if(fn(mid)&lt;q) l = mid+1;//如果中间的值0的个数小于q，则左值++ else r = mid-1;// 否则 右值—— } if(ans) printf(\"Case %d: %lld\", Case, ans);//如果结果不为零，按输出格式打印 else printf(\"Case %d: impossible\", Case);//否则，则输出impossile cout&lt;&lt;endl; } return 0;}","link":"/AngelNI.github.io/二分法查找/"},{"title":"俄罗斯方块","text":"嘿！小伙伴们，还记得俄罗斯方块吗？想必每个人都玩过这个简单刺激的小游戏吧！ 在这里分享给大家一个在线的俄罗斯方块——&gt;&gt; 大爷！来玩呦 github项目地址 点我呦 百度云源代码下载 点我呦 提取码：wb6q","link":"/AngelNI.github.io/俄罗斯方块/"},{"title":"大数取模","text":"THIS A SAD STORY…… 頑張って 介绍取模想必大家都知道，比如7%5=2，10%3=1，当然了，这还只是简单的取模，适用于不超过计算机整数范围。如果超过了该怎么办呢？ 今天，这里介绍的就是大数取模。 一般取模大数储存对一个相当大的数，C语言里的整形是无法储存的，在这里，我们用字符串储存。 取模方法模仿我们曾学过的竖式乘除法。 对于一个大数 A ，他从高到低的每一位乘以10再对mod取余，最后的结果就是取模的结果。 ` 12345678910111213141516171819202122232425#include&lt;iostream&gt;#include&lt;cstring&gt;using namespace std;#define MOD 100000007long divmod(char *ch,int a){ long s = 0; for(int i=0;ch[i]!='\\0';i++) { s=(s*10+ch[i]-'0')%MOD; } return s;}int main(){ long a,b; char num[100000]; gets(num); a = strlen(num); b = divmod(num,a); printf(\"%ld\",b); return 0; } ` 快速幂取模对于一般的大数取模，时间复杂度太大，可能会TE了。对于指数型的大数取模问题，，快速幂取模就简单方便多了，在空间和时间上相对于一般取模都做了优化。 方法快速幂取模的方法基于离散数学或数论的一条公式推导引理。 积的取余等于取余的积的取余 在这个定义的基础上对指数型数据进行拆分以及合并，从而实现快速幂取模。 举个栗子求（3^40）mod 6。 (3^40)–&gt;(9^20)–&gt;(18^10) ……这样依次类推 这里指数幂是偶数，如果是奇数先乘在重复上述工作。 再这里有一个简单判断奇偶数的方法。附上代码 123456789101112#include&lt;stdio.h&gt;int main(){ int n; while(~scanf(\"%d\",&amp;n)){ if(n&amp;1) printf(\"奇数\"); else printf(\"偶数\");} return 0;} 这里简单的运用了位运算。这比一般奇偶的判断高大上多了。活到老学到老。。。 实现12345678910111213long powermode(long a, long b, long mod){ long ans = 1; while (b) { if (b &amp; 1) { ans = (ans * a) % mod; b--; } b /= 2; a = a * a % mod; } return ans;} 补充对于大数取模还有欧拉函数（费马小定理），技巧去摸，这里不多介绍，后续会补上","link":"/AngelNI.github.io/大数取模/"},{"title":"天生棋局(指针)","text":"上次用数组写的天生棋局题，这里补上指针版的。 题目描述中国传统文化源远流长，博大精深，包含着华夏先哲的无穷智慧，也是历朝历代炎黄子孙生活的缩影。围棋作为中华民族流传已久的一种策略性棋牌游戏，蕴含着丰富的汉民族文化内涵，是中国文明与中华文化的体现。本案例要求创建一个棋盘，在棋盘生成的同时初始化棋盘，根据初始化后棋盘中棋子的位置来判断此时的棋局是否是一局好棋。具体要求如下：** 1）棋盘的大小根据用户的指令确定； 2）棋盘中棋子的数量也由用户设定； 3）棋子的位置由随机数函数随机确定，若生成的棋盘中有两颗棋子落在同一行或同一列，则判定为“好棋”，否则判定为“不是好棋”。 #注释天生棋局指针类型的和上次数组类型的大体思路是一样的，在这里主要不同的，在于用calloc（）函数申请一个动态的存储空间，因为calloc（）函数成功生成动态存储空间会返回储存空间的首地址，所以在这里用指针类型的变量来实现对动态存储空间的操作。 这里主要用二维指针，二维指针储存一维指针的地址，二维指针可以看做二维数组，而二维数组可以看做由一维数组组生成，这样理解起来比较简单些 附上关键自定义生成动态存储函数 123456789 int ** board(int n){ int ** p = (int **)calloc(sizeof(int*), n);//calloc在内存中分配n*size大小的动态存储空间，返回一个起始地址的一个指针 for (int i = 0; i &lt; n; i++) { p[i] = (int *)calloc(sizeof(int), n); } return p;} 代码实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109#include&lt;stdio.h&gt;#include&lt;stdlib.h&gt;#include&lt;time.h&gt;int ** board(int n); //申请动态存储空间 void inkey(int **p,int n,int m);//用随机数下棋 void printboard(int **p,int n);//打印棋格 int check(int **p,int n);//检查好/坏棋 void freespace(int **p,int n);//释放动态空间 int main(){ int n,m,con; printf(\"请输入棋盘大小:\\n\"); scanf(\"%d\",&amp;n); printf(\"请输入棋子数量:\\n\"); scanf(\"%d\",&amp;m); int **p=board(n); inkey( p ,n, m ); printboard(p,n); con=check(p,n); freespace(p,n); if(con) printf(\"好棋！\"); else printf(\"不是好棋！\"); return 0; } int ** board(int n){ int ** p = (int **)calloc(sizeof(int*), n);//calloc在内存中分配n*size大小的动态存储空间，返回一个起始地址的一个指针 for (int i = 0; i &lt; n; i++) { p[i] = (int *)calloc(sizeof(int), n); } return p;}void inkey(int **p,int n,int m){ srand((unsigned int)time(NULL)); //随机数种子 生成伪随机数，每次的随机数都不一样 while(m--) { int a=rand()%n,b=rand()%n; p[a][b]=1; }}void printboard(int **p,int n){ for(int i=0;i&lt;n;i++) // 生 成 棋 盘 { for(int j =0;j&lt;n;j++) // ┏ ┓┗ ┛┠ ┷ ┨ ┯ ┼ ● { if(p[i][j]==1) printf(\"●\"); else { if (i == 0 &amp;&amp; j == 0) printf(\"┏\"); else if (i == 0 &amp;&amp; j == n - 1) printf(\"┓\"); else if (i == n - 1 &amp;&amp; j == 0) printf(\"┗\"); else if (i == n - 1 &amp;&amp; j == n - 1) printf(\"┛\"); else if (j == 0) printf(\"┠\"); else if (i == n - 1) printf(\"┷\"); else if (j == n - 1) printf(\"┨\"); else if (i == 0) printf(\"┯\"); else printf(\"┼\"); } } putchar('\\n'); } }int check(int **p,int n){ int flag = 0; // 默认不是好棋。 for(int i=0;i&lt;n;i++) // 判断 好棋 坏棋 { for(int j=0;j&lt;n;j++) { if (p[i][j] == 1) { if (j&gt;0 &amp;&amp; p[i][j-1] == 1) //判断同一行有无相邻棋子 { flag = 1; } if (i &gt;0 &amp;&amp; p[i-1][j] == 1) //判断同一列有无相邻棋子 { flag = 1; } } } } return flag;}void freespace(int **p,int n){ for (int i= 0; i &lt; n; i++) { free(p[i]); //释放一级指针指向的空间 } free(p); //释放二级指针指向的空间}","link":"/AngelNI.github.io/天生棋局-指针/"},{"title":"天生棋局","text":"天生棋局问题，是C语言老师留的一个课外练习题。要求有用指针来写，因为指针学的不扎实，也因为第一次看到这道题时，第一个想法就是要用数组来写，所以以下是用数组对天生棋局代码。(指针的会后续补上) 题目描述中国传统文化源远流长，博大精深，包含着华夏先哲的无穷智慧，也是历朝历代炎黄子孙生活的缩影。围棋作为中华民族流传已久的一种策略性棋牌游戏，蕴含着丰富的汉民族文化内涵，是中国文明与中华文化的体现。本案例要求创建一个棋盘，在棋盘生成的同时初始化棋盘，根据初始化后棋盘中棋子的位置来判断此时的棋局是否是一局好棋。具体要求如下：** 1）棋盘的大小根据用户的指令确定； 2）棋盘中棋子的数量也由用户设定； 3）棋子的位置由随机数函数随机确定，若生成的棋盘中有两颗棋子落在同一行或同一列，则判定为“好棋”，否则判定为“不是好棋”。 题前注释1.随机数头文件： 1#include&lt;stdlib.h&gt; And #include&lt;time.h&gt; 函数： 1.rand()函数生成伪随机数。 2.随机发生器的初始化函数`srand(unsigned seed) 目的： rand（）函数是按指定的顺序来产生整数，但可能两次的随机数相同并不是真正的随机，叫做伪随机数。而随机发生器的初始化函数`srand(unsigned seed)（也位于stdlib.h）进行伪随机数列初始化，通过用时间函数time（NULL）作为seed，使每一次产生的随机数都不一样。 2.棋盘，棋子这是一个下棋的游戏，如果把随机的产生的棋子赤果果地展现在棋盘上，效果会很明显，并且题目说要生成棋盘，所以首先要打印一个棋盘 打印棋盘，首先要有边框和棋子，这些是从word上copy来的,然后用双层循环就可以了。 3.判断好/坏棋根据题意即可 疑惑根据题意，他说若生成的棋盘中有两颗棋子落在同一行或同一列，则判定为“好棋”，否则判定为“不是好棋”。但与查的资料不同，说是两颗棋子相邻是好棋。 代码实现12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576#include&lt;stdio.h&gt;#include&lt;stdlib.h&gt;#include&lt;time.h&gt; int main(){ srand((unsigned int)time(NULL)); // 生成伪随机数，每次的随机数都不一样 int n,m; unsigned long kb[700][700]; //默认最大棋盘大小 printf(\"请输入棋盘大小： \"); scanf(\"%d\",&amp;n); printf(\"请输入棋子数量： \"); scanf(\"%d\",&amp;m); while(m--) //生成 0 ~ n-1 的随机数 并赋值为 1 { int a=rand()%n,b=rand()%n; kb[a][b]=1; } for(int i=0;i&lt;n;i++) // 生 成 棋 盘 { for(int j =0;j&lt;n;j++) // ┏┓┗┛┠┷┨┯┼● { if(kb[i][j]==1) printf(\"●\"); else { if (i == 0 &amp;&amp; j == 0) printf(\"┏ \"); else if (i == 0 &amp;&amp; j == n - 1) printf(\"┓ \"); else if (i == n - 1 &amp;&amp; j == 0) printf(\"┗ \"); else if (i == n - 1 &amp;&amp; j == n - 1) printf(\"┛ \"); else if (j == 0) printf(\"┠ \"); else if (i == n - 1) printf(\"┷ \"); else if (j == n - 1) printf(\"┨ \"); else if (i == 0) printf(\"┯ \"); else printf(\"┼ \"); } } putchar('\\n'); } int flag = 0; // 默认不是好棋。 for(int i=0;i&lt;n;i++) // 判断 好棋 坏棋 { for(int j=0;j&lt;n;j++) { if (kb[i][j] == 1) { if (j&gt;0 &amp;&amp; kb[i][j-1] == 1) //判断同一行有无相邻棋子 { printf(\"好棋！\\n\"); flag = 1; break; } if (i &gt;0 &amp;&amp; kb[i-1][j] == 1) //判断同一列有无相邻棋子 { printf(\"好棋！\\n\"); flag = 1; break; } } } } if(flag == 0) printf(\"不是好棋\"); return 0; }","link":"/AngelNI.github.io/天生棋局/"},{"title":"My First Neural Network Construction","text":"啊啊啊Ｏ(≧口≦)Ｏ！！！我的第一个神经网络竟然是算出来的。 学习了简单的神经网络模型，今天出于兴趣，自己搭个神经网络的巨简单的模型，不不不，是算出来的。 这篇代码是根据我的上一篇博客点我吧根据推导公式写的，小白技能有限，大佬不要嘲笑啊。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596import numpy as npimport matplotlib.pyplot as plt%matplotlib inline#激活函数及导数def sigmoid(x): return 1 / (1 + np.exp(-x))def d_sigmoid(x): return x * (1 - x) def tanh(x): return np.tanh(x)def d_tanh(x): return 1.0 - np.tanh(x) * np.tanh(x)##参数设置alph = 0.5esp = 0.01step = 5000#前向传播def qianxiangchuanbo(init,weight,b): #输入层——&gt;隐含层 neth=[]#神经元输入加权和 outh=[]#神经元输出 #隐含层---&gt;输出层 neto=[]#输出神经元 outo=[]#神经元输出 neth.append(weight[0]*init[0]+weight[1]*init[1]+b[0]) neth.append(weight[2]*init[0]+weight[3]*init[1]+b[0]) outh.append(sigmoid(neth[0])) outh.append(sigmoid(neth[1])) neto.append(weight[4]*outh[0]+weight[5]*outh[1]+b[1]) neto.append(weight[6]*outh[0]+weight[7]*outh[1]+b[1]) outo.append(sigmoid(neto[0])) outo.append(sigmoid(neto[1])) return neth,outh,neto,outodef fanxiangchuanbo(out,outo,outh): new_weight=[] q=[] #输如层——&gt;隐藏层 a1=(-(init[0]-outo[0])*outo[0]*(1-outo[0])) a2=(-(init[1]-outo[1])*outo[1]*(1-outo[1])) q.append(a1) q.append(a2) w1 = q[0]*weight[4]+q[1]*weight[6]*outh[0]*(1-outh[0])*init[0] w2 = q[0]*weight[4]+q[1]*weight[6]*outh[0]*(1-outh[0])*init[1] w3 = q[0]*weight[5]+q[1]*weight[7]*outh[1]*(1-outh[1])*init[0] w4 = q[0]*weight[5]+q[1]*weight[7]*outh[1]*(1-outh[1])*init[1] new_weight.append(w1) new_weight.append(w2) new_weight.append(w3) new_weight.append(w4) #输出层——&gt;隐藏层 w5 = -(out[0]-outo[0])*outo[0]*(1-outo[0])*outh[0] w6 = -(out[0]-outo[0])*outo[0]*(1-outo[0])*outh[1] w7 = -(out[1]-outo[1])*outo[1]*(1-outo[1])*outh[0] w8 = -(out[1]-outo[1])*outo[1]*(1-outo[1])*outh[1] new_weight.append(w5) new_weight.append(w6) new_weight.append(w7) new_weight.append(w8) return new_weight#输入集init = [0.05,0.10]#真实输出集out = [0.01,0.99]#权重weight = [0.15,0.20,0.25,0.30,0.40,0.45,0.50,0.55]#偏置项b=[0.35,0.60]count=0result = []while True: count=count+1 neth,outh,neto,outo = qianxiangchuanbo(init,weight,b) e=(abs(out[0]-outo[0])+abs(out[1]-outo[1])) result.append(e) gd_weight = fanxiangchuanbo(out,outo,outh) for i in range(len(weight)): weight[i]=weight[i]-alph*gd_weight[i] # if e&lt;esp: # break if count &gt; step: breakfor k in range(len(result)): plt.scatter(k,result[k])plt.show()print(weight)print(out)print(outo) 最后的运行结果如图 由于此代码只运行了5000次，可以看出与实际的差距还是很大的，如果感兴趣，你可以试试增大迭代次数，或者控制精度。","link":"/AngelNI.github.io/我的第一个神经网络搭建/"},{"title":"Artificial Neural Networks","text":"现在终于理解我们高中数学老师说的话了，计算不行，说明数学不行，数学不行能力不行，数学好才是真正的好！！！哈哈哈。 这是典型的三层神经网络的基本构成，Layer L1是输入层，Layer L2是隐含层，Layer L3是隐含层，我们现在手里有一堆数据{x1,x2,x3,…,xn},输出也是一堆数据{y1,y2,y3,…,yn},现在要他们在隐含层做某种变换，让你把数据灌进去后得到你期望的输出。 在这里，通过对上图简单的案例进行数学推导,激活函数默认为sigmoid函数（注：神经网络的基础知识可以参考Poll的笔记：[Mechine Learning &amp; Algorithm] 神经网络基础） 一、前向传播1.输入层—-&gt;隐含层计算神经元的输入加权和 计算神经元 h1、h2 的输出 2.隐含层—-&gt;输出层计算输出神经元o1、o2的值 至此，前向传导传播结束。 二、反向传播1.计算总误差 2.隐藏层—–&gt;输出层权值更新 同理可求 权值跟新 3.隐藏层—-&gt;输出层权值更新 权值跟新 权值更新后测试数据，会发现数据误差变小许多 三、栗子12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182import numpy as np#激励函数与其偏导数def tanh(x): return np.tanh(x)def tanh_derivative(x): return 1.0 - np.tanh(x) * np.tanh(x)def logistic(x): return 1 / (1 + np.exp(-x))def logistic_derivative(x): return logistic(x) * (1 - logistic(x) )#神经网络模型class NeuralNetwork: def __init__(self, layers, activation='tanh'): if activation == 'Logistic': self.activation = logistic self.activation_deriv = logistic_derivative elif activation == 'tanh': self.activation = tanh self.activation_deriv = tanh_derivative self.weights = [] for i in range(1, len(layers)-1): # [0,1) * 2 - 1 =&gt; [-1,1) =&gt; * 0.25 =&gt; [-0.25,0.25) 随机权值 self.weights.append( (2*np.random.random((layers[i-1] + 1, layers[i] + 1 ))-1 ) * 0.25 ) self.weights.append( (2*np.random.random((layers[i] + 1, layers[i+1] ))-1 ) * 0.25 ) # for i in range(0, len(layers)-1): # m = layers[i] # 第i层节点数 # n = layers[i+1] # 第i+1层节点数 # wm = m + 1 # wn = n + 1 # if i == len(layers)-2: # wn = n # weight = np.random.random((wm, wn)) * 2 - 1 # self.weights.append(0.25 * weight) #类比梯度下降 def fit(self, X, y, learning_rate=0.2, epochs = 10000): X = np.atleast_2d(X) # temp = np.ones([X.shape[0], X.shape[1]+1]) # temp[:,0:-1] = X # X = temp X = np.column_stack((X, np.ones(len(X)))) y = np.array(y) for k in range(epochs): i = np.random.randint(X.shape[0]) a = [X[i]] # 正向计算 for l in range(len(self.weights)): a.append(self.activation( np.dot(a[l], self.weights[l])) ) # 反向传播 error = y[i] - a[-1] deltas = [error * self.activation_deriv(a[-1])] # starting backprobagation layerNum = len(a) - 2 for j in range(layerNum, 0, -1): # 倒数第二层开始 deltas.append(deltas[-1].dot(self.weights[j].T) * self.activation_deriv(a[j])) # deltas.append(deltas[-(layerNum+1-j)].dot(self.weights[j].T) * self.activation_deriv(a[j])) deltas.reverse() for i in range(len(self.weights)): layer = np.atleast_2d(a[i]) delta = np.atleast_2d(deltas[i]) self.weights[i] += learning_rate * layer.T.dot(delta) def predict(self, x): x = np.array(x) temp = np.ones(x.shape[0] + 1) temp[0:-1] = x a = temp for l in range(0, len(self.weights)): a = self.activation(np.dot(a, self.weights[l])) return ann = NeuralNetwork([2, 2, 1], 'tanh')x = np.array([[0,0],[0,1],[1,0],[1,1]])y = np.array([0,1,1,0])nn.fit(x, y)for i in [[0,0],[0,1],[1,0],[1,1]]: print (i, nn.predict(i)) 这是我的运行结果","link":"/AngelNI.github.io/神经网络——案例简单推导/"},{"title":"Artificial Neural Networks——Activation Funcation","text":"有时候不敢去拥有，因为害怕失去，所以非常努力地去奋斗，让自己累，让自己不去想。 激活函数定义 所谓激活函数（Activation Function），就是在人工神经网络的神经元上运行的函数，负责将神经元的输入映射到输出端。 判定每个神经元的输出 通俗来说，激活函数一般是非线性函数，其作用是能够给神经网络加入一些非线性因素，使得神经网络可以更好地解决较为复杂的问题。 常见的激活函数 1.sigmoid 2.tanh 3.ReLu 4.ELU 5.PReLU 这里简单的对前三个进行介绍 1.sigmoid Sigmoid 函数的取值范围在 (0,1) 之间，单调连续，求导容易，一般用于二分类神经网络的输出层。 sigmoid函数图像如图 sigmoid函数求导 缺点： 123451.Sigmoid 函数饱和区范围广，容易造成梯度消失2.参数矩阵 W 的每个元素都会朝着同一个方向变化，同为正或同为负。这对于神经网络训练是不利的，所有的 W 都朝着同一符号方向变化会减小训练速度，增加模型训练时间。3.Sigmoid 函数包含 exp 指数运算，运算成本也比较大 2.tanh 图像如图 tanh 函数的取值范围在 (-1,1) 之间，单调连续，求导容易。 相比于 Sigmoid 函数，tanh 函数的优点主要有两个： 121.其一，收敛速度更快，如下图所示，tanh 函数线性区斜率较 Sigmoid 更大一些。在此区域内训练速度会更快。2.其二，tanh 函数输出均值为零，也就不存在 Sigmoid 函数中 dW 恒为正或者恒为负，从而影响训练速度的问题。 缺点： 1tanh 函数与 Sigmoid 函数一样，也存在饱和区梯度消失问题。其饱和区甚至比 Sigmoid 还要大一些，但不明显。 3.ReLu 优点： 12345671.没有饱和区，不存在梯度消失问题。2.没有复杂的指数运算，计算简单、效率提高。3.实际收敛速度较快，大约是 Sigmoid/tanh 的 6 倍。4.比 Sigmoid 更符合生物学神经激活机制。 缺点： 121. ReLU 的输出仍然是非零对称的，可能出现 dW 恒为正或者恒为负，从而影响训练速度。2. 当 x&lt;0 时，ReLU 输出总为零。该神经元输出为零，则反向传播时，权重、参数的梯度横为零，造成权重、参数永远不会更新，即造成神经元失效，形成了“死神经元”。 如何选择激活函数1234567891.首选 ReLU，速度快，但是要注意学习速率的调整，2.如果 ReLU 效果欠佳,尝试使用 Leaky ReLU、ELU 或 Maxout 等变种。3.可以尝试使用 tanh。4.Sigmoid 和 tanh 在 RNN（LSTM、注意力机制等）结构中有所应用，作为门控或者概率值。其它情况下，减少 Sigmoid 的使用。5.在浅层神经网络中，选择使用哪种激励函数影响不大。","link":"/AngelNI.github.io/神经网络之激活函数/"},{"title":"约数个数定理","text":"自从那时起，它就有了特别的含义，既是与她的一种约定，也是自己出海航行的方向。one piece 是我的，我可是要成为海贼王的男人哈哈哈。 引言今天遇到了一个有意思的题，让你求一个范围内的约数的个数的最大值，求约数个，哈哈，这真是简单，1,2,3,4从头数不就行了吗，你看我说的对不对哈哈。 还有一种办法是通过约数个数定理，好，废话说得不少，那就进入正题~ 定理百度百科 对于一个大于1正整数n可以分解质因数 ： 约数个数定理——来自百度百科 内容对于一个大于1正整数n可以分解质因数： 则n的正约数的个数就是 。 其中a1、a2、a3…ak是p1、p2、p3，…pk的指数。 证明首先同上，n可以分解质因数：n=p1^a1×p2^a2×p3^a3…pk^ak, 由约数定义可知p1^a1的约数有:p1^0, p1^1, p1^2……p1^a1 ，共（a1+1）个;同理p2^a2的约数有（a2+1）个……pk^ak的约数有（ak+1）个。 故根据乘法原理：n的约数的个数就是(a1+1)(a2+1)(a3+1)…(ak+1)。","link":"/AngelNI.github.io/约数个数定理/"}],"tags":[{"name":"Life essay","slug":"Life-essay","link":"/AngelNI.github.io/tags/Life-essay/"},{"name":"literature","slug":"literature","link":"/AngelNI.github.io/tags/literature/"},{"name":"Algorithm","slug":"Algorithm","link":"/AngelNI.github.io/tags/Algorithm/"},{"name":"C++","slug":"C","link":"/AngelNI.github.io/tags/C/"},{"name":"AI","slug":"AI","link":"/AngelNI.github.io/tags/AI/"},{"name":"Gradient Descent","slug":"Gradient-Descent","link":"/AngelNI.github.io/tags/Gradient-Descent/"},{"name":"Learing","slug":"Learing","link":"/AngelNI.github.io/tags/Learing/"},{"name":"KNN","slug":"KNN","link":"/AngelNI.github.io/tags/KNN/"},{"name":"K-means","slug":"K-means","link":"/AngelNI.github.io/tags/K-means/"},{"name":"Keras-note","slug":"Keras-note","link":"/AngelNI.github.io/tags/Keras-note/"},{"name":"sharing","slug":"sharing","link":"/AngelNI.github.io/tags/sharing/"},{"name":"Makedown","slug":"Makedown","link":"/AngelNI.github.io/tags/Makedown/"},{"name":"Game","slug":"Game","link":"/AngelNI.github.io/tags/Game/"},{"name":"MC","slug":"MC","link":"/AngelNI.github.io/tags/MC/"},{"name":"python command","slug":"python-command","link":"/AngelNI.github.io/tags/python-command/"},{"name":"recommend","slug":"recommend","link":"/AngelNI.github.io/tags/recommend/"},{"name":"python","slug":"python","link":"/AngelNI.github.io/tags/python/"},{"name":"MF","slug":"MF","link":"/AngelNI.github.io/tags/MF/"},{"name":"Machine-learn","slug":"Machine-learn","link":"/AngelNI.github.io/tags/Machine-learn/"},{"name":"Ubutu","slug":"Ubutu","link":"/AngelNI.github.io/tags/Ubutu/"},{"name":"stack","slug":"stack","link":"/AngelNI.github.io/tags/stack/"},{"name":"Linked list","slug":"Linked-list","link":"/AngelNI.github.io/tags/Linked-list/"},{"name":"CDN","slug":"CDN","link":"/AngelNI.github.io/tags/CDN/"},{"name":"hexo+github","slug":"hexo-github","link":"/AngelNI.github.io/tags/hexo-github/"},{"name":"matplotlib","slug":"matplotlib","link":"/AngelNI.github.io/tags/matplotlib/"},{"name":"termux","slug":"termux","link":"/AngelNI.github.io/tags/termux/"},{"name":"ubuntu","slug":"ubuntu","link":"/AngelNI.github.io/tags/ubuntu/"},{"name":"Git","slug":"Git","link":"/AngelNI.github.io/tags/Git/"},{"name":"NN","slug":"NN","link":"/AngelNI.github.io/tags/NN/"}],"categories":[{"name":"Life essay","slug":"Life-essay","link":"/AngelNI.github.io/categories/Life-essay/"},{"name":"literature","slug":"literature","link":"/AngelNI.github.io/categories/literature/"},{"name":"Algorithm","slug":"Algorithm","link":"/AngelNI.github.io/categories/Algorithm/"},{"name":"C++","slug":"C","link":"/AngelNI.github.io/categories/C/"},{"name":"AI","slug":"AI","link":"/AngelNI.github.io/categories/AI/"},{"name":"Learning","slug":"Learning","link":"/AngelNI.github.io/categories/Learning/"},{"name":"Keras-note","slug":"Keras-note","link":"/AngelNI.github.io/categories/Keras-note/"},{"name":"sharing","slug":"sharing","link":"/AngelNI.github.io/categories/sharing/"},{"name":"Makedown","slug":"Makedown","link":"/AngelNI.github.io/categories/Makedown/"},{"name":"Game","slug":"Game","link":"/AngelNI.github.io/categories/Game/"},{"name":"python","slug":"python","link":"/AngelNI.github.io/categories/python/"},{"name":"Machine-learn","slug":"Machine-learn","link":"/AngelNI.github.io/categories/Machine-learn/"},{"name":"Ubutu","slug":"Ubutu","link":"/AngelNI.github.io/categories/Ubutu/"},{"name":"Data-Structure","slug":"Data-Structure","link":"/AngelNI.github.io/categories/Data-Structure/"},{"name":"jsDelivr+Github","slug":"jsDelivr-Github","link":"/AngelNI.github.io/categories/jsDelivr-Github/"},{"name":"hexo+github","slug":"hexo-github","link":"/AngelNI.github.io/categories/hexo-github/"},{"name":"Ubuntu","slug":"Ubuntu","link":"/AngelNI.github.io/categories/Ubuntu/"},{"name":"Git","slug":"Git","link":"/AngelNI.github.io/categories/Git/"}]}